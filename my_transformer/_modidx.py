# Autogenerated by nbdev

d = { 'settings': { 'doc_baseurl': '/transformer_implementations',
                'doc_host': 'https://jean-kunz.github.io',
                'git_url': 'https://github.com/jean-kunz/transformer_implementations',
                'lib_path': 'my_transformer'},
  'syms': { 'my_transformer.components': { 'my_transformer.components.DecoderLayer': ( 'components.html#decoderlayer',
                                                                                       'my_transformer/components.py'),
                                           'my_transformer.components.DecoderLayer.__init__': ( 'components.html#decoderlayer.__init__',
                                                                                                'my_transformer/components.py'),
                                           'my_transformer.components.DecoderLayer.forward': ( 'components.html#decoderlayer.forward',
                                                                                               'my_transformer/components.py'),
                                           'my_transformer.components.DecoderTransformer': ( 'components.html#decodertransformer',
                                                                                             'my_transformer/components.py'),
                                           'my_transformer.components.DecoderTransformer.__init__': ( 'components.html#decodertransformer.__init__',
                                                                                                      'my_transformer/components.py'),
                                           'my_transformer.components.DecoderTransformer.forward': ( 'components.html#decodertransformer.forward',
                                                                                                     'my_transformer/components.py'),
                                           'my_transformer.components.LayerNormalization': ( 'components.html#layernormalization',
                                                                                             'my_transformer/components.py'),
                                           'my_transformer.components.LayerNormalization.__init__': ( 'components.html#layernormalization.__init__',
                                                                                                      'my_transformer/components.py'),
                                           'my_transformer.components.LayerNormalization.forward': ( 'components.html#layernormalization.forward',
                                                                                                     'my_transformer/components.py'),
                                           'my_transformer.components.MultiHeadAttention': ( 'components.html#multiheadattention',
                                                                                             'my_transformer/components.py'),
                                           'my_transformer.components.MultiHeadAttention.__init__': ( 'components.html#multiheadattention.__init__',
                                                                                                      'my_transformer/components.py'),
                                           'my_transformer.components.MultiHeadAttention.forward': ( 'components.html#multiheadattention.forward',
                                                                                                     'my_transformer/components.py'),
                                           'my_transformer.components.PositionalEncoder': ( 'components.html#positionalencoder',
                                                                                            'my_transformer/components.py'),
                                           'my_transformer.components.PositionalEncoder.__init__': ( 'components.html#positionalencoder.__init__',
                                                                                                     'my_transformer/components.py'),
                                           'my_transformer.components.PositionalEncoder.forward': ( 'components.html#positionalencoder.forward',
                                                                                                    'my_transformer/components.py'),
                                           'my_transformer.components.PositionalEncoder.positional_encoding': ( 'components.html#positionalencoder.positional_encoding',
                                                                                                                'my_transformer/components.py'),
                                           'my_transformer.components.TokenEmbeddings': ( 'components.html#tokenembeddings',
                                                                                          'my_transformer/components.py'),
                                           'my_transformer.components.TokenEmbeddings.__init__': ( 'components.html#tokenembeddings.__init__',
                                                                                                   'my_transformer/components.py'),
                                           'my_transformer.components.TokenEmbeddings.forward': ( 'components.html#tokenembeddings.forward',
                                                                                                  'my_transformer/components.py'),
                                           'my_transformer.components.attention': ( 'components.html#attention',
                                                                                    'my_transformer/components.py'),
                                           'my_transformer.components.unidirectional_mask': ( 'components.html#unidirectional_mask',
                                                                                              'my_transformer/components.py')}}}
