{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b1b971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18391974",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 503\u001b[39m\n\u001b[32m    501\u001b[39m \u001b[38;5;66;03m# Test forward process\u001b[39;00m\n\u001b[32m    502\u001b[39m t = torch.randint(\u001b[32m0\u001b[39m, \u001b[32m100\u001b[39m, (batch_size,), device=device)\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m xt = \u001b[43md3pm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mq_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOriginal shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_start.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Noisy shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxt.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    506\u001b[39m \u001b[38;5;66;03m# Test loss computation\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 198\u001b[39m, in \u001b[36mD3PM.q_sample\u001b[39m\u001b[34m(self, x_start, t)\u001b[39m\n\u001b[32m    191\u001b[39m x_flat = x_start_onehot.view(batch_size, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.num_classes)\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# Batch matrix multiplication\u001b[39;00m\n\u001b[32m    194\u001b[39m probs = torch.bmm(\n\u001b[32m    195\u001b[39m     x_flat,\n\u001b[32m    196\u001b[39m     \u001b[43mQt_bar_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_flat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_flat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    199\u001b[39m )\n\u001b[32m    200\u001b[39m probs = probs.view(batch_size, x_flat.shape[\u001b[32m1\u001b[39m], \u001b[38;5;28mself\u001b[39m.num_classes)\n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# Sample from categorical distribution\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from typing import Optional, Union, Tuple, Dict\n",
    "from enum import Enum\n",
    "import math\n",
    "\n",
    "\n",
    "class TransitionType(Enum):\n",
    "    UNIFORM = \"uniform\"\n",
    "    ABSORBING = \"absorbing\"\n",
    "    GAUSSIAN = \"gaussian\"\n",
    "    EMBEDDING = \"embedding\"\n",
    "\n",
    "\n",
    "class NoiseSchedule(Enum):\n",
    "    LINEAR = \"linear\"\n",
    "    COSINE = \"cosine\"\n",
    "    MUTUAL_INFO = \"mutual_info\"\n",
    "\n",
    "\n",
    "class D3PM(nn.Module):\n",
    "    \"\"\"\n",
    "    Discrete Denoising Diffusion Probabilistic Model (D3PM)\n",
    "\n",
    "    Based on \"Structured Denoising Diffusion Models in Discrete State-Spaces\"\n",
    "    by Austin et al. (2021)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int,\n",
    "        timesteps: int = 1000,\n",
    "        transition_type: TransitionType = TransitionType.UNIFORM,\n",
    "        noise_schedule: NoiseSchedule = NoiseSchedule.COSINE,\n",
    "        hybrid_loss_coeff: float = 0.001,\n",
    "        mask_token_id: Optional[int] = None,\n",
    "        embedding_dim: Optional[int] = None,\n",
    "        device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.timesteps = timesteps\n",
    "        self.transition_type = transition_type\n",
    "        self.noise_schedule = noise_schedule\n",
    "        self.hybrid_loss_coeff = hybrid_loss_coeff\n",
    "        self.device = device\n",
    "\n",
    "        # Set mask token (for absorbing diffusion)\n",
    "        if mask_token_id is None:\n",
    "            self.mask_token_id = num_classes - 1  # Default to last token\n",
    "        else:\n",
    "            self.mask_token_id = mask_token_id\n",
    "\n",
    "        # Initialize transition matrices and noise schedule\n",
    "        self._setup_noise_schedule()\n",
    "        self._setup_transition_matrices()\n",
    "\n",
    "        # For embedding-based transitions\n",
    "        if transition_type == TransitionType.EMBEDDING:\n",
    "            if embedding_dim is None:\n",
    "                raise ValueError(\"embedding_dim must be specified for embedding transition type\")\n",
    "            self.token_embeddings = nn.Embedding(num_classes, embedding_dim)\n",
    "\n",
    "    def _setup_noise_schedule(self):\n",
    "        \"\"\"Setup the noise schedule βt for each timestep\"\"\"\n",
    "        if self.noise_schedule == NoiseSchedule.LINEAR:\n",
    "            self.betas = torch.linspace(1e-4, 0.02, self.timesteps, device=self.device)\n",
    "        elif self.noise_schedule == NoiseSchedule.COSINE:\n",
    "            self.betas = self._cosine_schedule()\n",
    "        elif self.noise_schedule == NoiseSchedule.MUTUAL_INFO:\n",
    "            # Simplified mutual information schedule\n",
    "            self.betas = 1.0 / torch.arange(self.timesteps, 0, -1, device=self.device, dtype=torch.float32)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown noise schedule: {self.noise_schedule}\")\n",
    "\n",
    "    def _cosine_schedule(self, s: float = 0.008) -> torch.Tensor:\n",
    "        \"\"\"Cosine noise schedule from Improved DDPM\"\"\"\n",
    "        steps = self.timesteps + 1\n",
    "        x = torch.linspace(0, self.timesteps, steps, device=self.device)\n",
    "        alphas_cumprod = torch.cos(((x / self.timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
    "        alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "        betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "        return torch.clip(betas, 0, 0.999)\n",
    "\n",
    "    def _setup_transition_matrices(self):\n",
    "        \"\"\"Setup transition matrices Qt for each timestep\"\"\"\n",
    "        self.Qt = []\n",
    "        self.Qt_bar = []  # Cumulative products\n",
    "\n",
    "        for t in range(self.timesteps):\n",
    "            if self.transition_type == TransitionType.UNIFORM:\n",
    "                Qt = self._uniform_transition_matrix(self.betas[t])\n",
    "            elif self.transition_type == TransitionType.ABSORBING:\n",
    "                Qt = self._absorbing_transition_matrix(self.betas[t])\n",
    "            elif self.transition_type == TransitionType.GAUSSIAN:\n",
    "                Qt = self._gaussian_transition_matrix(self.betas[t])\n",
    "            else:\n",
    "                # For embedding-based, we'll compute dynamically\n",
    "                Qt = torch.eye(self.num_classes, device=self.device)\n",
    "\n",
    "            self.Qt.append(Qt)\n",
    "\n",
    "            # Compute cumulative product\n",
    "            if t == 0:\n",
    "                Qt_bar = Qt\n",
    "            else:\n",
    "                Qt_bar = torch.matmul(self.Qt_bar[-1], Qt)\n",
    "            self.Qt_bar.append(Qt_bar)\n",
    "\n",
    "    def _uniform_transition_matrix(self, beta_t: float) -> torch.Tensor:\n",
    "        \"\"\"Uniform transition matrix: Qt = (1-βt)I + βt/K * 11^T\"\"\"\n",
    "        K = self.num_classes\n",
    "        Qt = (1 - beta_t) * torch.eye(K, device=self.device)\n",
    "        Qt += beta_t / K * torch.ones(K, K, device=self.device)\n",
    "        return Qt\n",
    "\n",
    "    def _absorbing_transition_matrix(self, beta_t: float) -> torch.Tensor:\n",
    "        \"\"\"Absorbing state transition matrix\"\"\"\n",
    "        K = self.num_classes\n",
    "        Qt = (1 - beta_t) * torch.eye(K, device=self.device)\n",
    "\n",
    "        # Transitions to mask token\n",
    "        Qt[:, self.mask_token_id] += beta_t\n",
    "        Qt[self.mask_token_id, self.mask_token_id] = 1.0  # Absorbing state\n",
    "\n",
    "        return Qt\n",
    "\n",
    "    def _gaussian_transition_matrix(self, beta_t: float) -> torch.Tensor:\n",
    "        \"\"\"Discretized Gaussian transition matrix\"\"\"\n",
    "        K = self.num_classes\n",
    "        Qt = torch.zeros(K, K, device=self.device)\n",
    "\n",
    "        for i in range(K):\n",
    "            for j in range(K):\n",
    "                if i != j:\n",
    "                    # Gaussian-like transitions based on distance\n",
    "                    distance = abs(i - j)\n",
    "                    prob = torch.exp(-4 * distance**2 / ((K - 1) ** 2 * beta_t))\n",
    "                    Qt[i, j] = prob\n",
    "\n",
    "        # Normalize rows and set diagonal\n",
    "        row_sums = Qt.sum(dim=1, keepdim=True)\n",
    "        Qt = Qt / (row_sums + 1e-8)  # Avoid division by zero\n",
    "\n",
    "        # Set diagonal to ensure row sums = 1\n",
    "        diag_vals = 1.0 - Qt.sum(dim=1) + torch.diag(Qt)\n",
    "        Qt.fill_diagonal_(0)\n",
    "        Qt += torch.diag(diag_vals)\n",
    "\n",
    "        return Qt\n",
    "\n",
    "    def _embedding_transition_matrix(self, beta_t: float, embeddings: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Transition matrix based on embedding similarity\"\"\"\n",
    "        # Compute pairwise similarities\n",
    "        similarities = torch.matmul(embeddings, embeddings.T)\n",
    "        similarities = F.softmax(similarities / 0.1, dim=-1)  # Temperature scaling\n",
    "\n",
    "        # Create transition matrix\n",
    "        Qt = (1 - beta_t) * torch.eye(self.num_classes, device=self.device)\n",
    "        Qt += beta_t * similarities\n",
    "\n",
    "        return Qt\n",
    "\n",
    "    def q_sample(self, x_start: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Sample from q(xt | x0) using the cumulative transition matrix\n",
    "\n",
    "        Args:\n",
    "            x_start: Initial data [batch_size, ...]\n",
    "            t: Timestep [batch_size]\n",
    "\n",
    "        Returns:\n",
    "            xt: Noisy data at timestep t\n",
    "        \"\"\"\n",
    "        batch_size = x_start.shape[0]\n",
    "\n",
    "        # Get cumulative transition matrices for each batch element\n",
    "        Qt_bar_batch = torch.stack([self.Qt_bar[t_i] for t_i in t])\n",
    "\n",
    "        # Convert to one-hot if needed\n",
    "        if x_start.dtype == torch.long:\n",
    "            x_start_onehot = F.one_hot(x_start, self.num_classes).float()\n",
    "        else:\n",
    "            x_start_onehot = x_start\n",
    "\n",
    "        # Apply transition: p = x_start @ Qt_bar\n",
    "        original_shape = x_start_onehot.shape\n",
    "        x_flat = x_start_onehot.view(batch_size, -1, self.num_classes)\n",
    "\n",
    "        # Batch matrix multiplication\n",
    "        probs = torch.bmm(\n",
    "            x_flat,\n",
    "            Qt_bar_batch.unsqueeze(1)\n",
    "            .expand(-1, x_flat.shape[1], -1, -1)\n",
    "            .view(batch_size * x_flat.shape[1], self.num_classes, self.num_classes),\n",
    "        )\n",
    "        probs = probs.view(batch_size, x_flat.shape[1], self.num_classes)\n",
    "\n",
    "        # Sample from categorical distribution\n",
    "        xt = torch.multinomial(probs.view(-1, self.num_classes), 1).view(batch_size, -1)\n",
    "\n",
    "        return xt.view(x_start.shape)\n",
    "\n",
    "    def q_posterior(self, x_start: torch.Tensor, xt: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute q(xt-1 | xt, x0)\n",
    "\n",
    "        Returns:\n",
    "            Log probabilities of q(xt-1 | xt, x0)\n",
    "        \"\"\"\n",
    "        batch_size = x_start.shape[0]\n",
    "\n",
    "        # Get transition matrices\n",
    "        if t[0] == 0:\n",
    "            return F.one_hot(x_start, self.num_classes).float().log()\n",
    "\n",
    "        Qt = torch.stack([self.Qt[t_i] for t_i in t])\n",
    "        Qt_bar_prev = torch.stack([self.Qt_bar[t_i - 1] for t_i in t])\n",
    "\n",
    "        # Convert to one-hot\n",
    "        x_start_onehot = F.one_hot(x_start, self.num_classes).float()\n",
    "        xt_onehot = F.one_hot(xt, self.num_classes).float()\n",
    "\n",
    "        # Compute posterior: q(xt-1|xt,x0) ∝ q(xt|xt-1) * q(xt-1|x0)\n",
    "        # This is equation (3) from the paper\n",
    "\n",
    "        # For numerical stability, work in log space\n",
    "        log_Qt = torch.log(Qt + 1e-8)\n",
    "        log_Qt_bar_prev = torch.log(Qt_bar_prev + 1e-8)\n",
    "\n",
    "        # Compute unnormalized log probabilities\n",
    "        log_probs = []\n",
    "        for k in range(self.num_classes):\n",
    "            k_onehot = torch.zeros_like(x_start_onehot)\n",
    "            k_onehot[..., k] = 1.0\n",
    "\n",
    "            # q(xt|xt-1=k) * q(xt-1=k|x0)\n",
    "            term1 = torch.sum(xt_onehot * torch.matmul(k_onehot, Qt), dim=-1)\n",
    "            term2 = torch.sum(k_onehot * torch.matmul(x_start_onehot, Qt_bar_prev), dim=-1)\n",
    "\n",
    "            log_prob_k = torch.log(term1 + 1e-8) + torch.log(term2 + 1e-8)\n",
    "            log_probs.append(log_prob_k.unsqueeze(-1))\n",
    "\n",
    "        log_probs = torch.cat(log_probs, dim=-1)\n",
    "\n",
    "        # Normalize\n",
    "        log_probs = log_probs - torch.logsumexp(log_probs, dim=-1, keepdim=True)\n",
    "\n",
    "        return log_probs\n",
    "\n",
    "    def compute_loss(\n",
    "        self, model: nn.Module, x_start: torch.Tensor, t: Optional[torch.Tensor] = None\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Compute the D3PM loss\n",
    "\n",
    "        Args:\n",
    "            model: Neural network that predicts x0 given xt and t\n",
    "            x_start: Clean data [batch_size, ...]\n",
    "            t: Timesteps [batch_size]. If None, sample randomly\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with loss components\n",
    "        \"\"\"\n",
    "        batch_size = x_start.shape[0]\n",
    "        device = x_start.device\n",
    "\n",
    "        if t is None:\n",
    "            t = torch.randint(0, self.timesteps, (batch_size,), device=device)\n",
    "\n",
    "        # Sample xt ~ q(xt | x0)\n",
    "        xt = self.q_sample(x_start, t)\n",
    "\n",
    "        # Predict x0\n",
    "        x0_pred_logits = model(xt, t)\n",
    "\n",
    "        # Convert predictions to probabilities\n",
    "        x0_pred_probs = F.softmax(x0_pred_logits, dim=-1)\n",
    "\n",
    "        # Compute reverse process probabilities using x0 parameterization\n",
    "        # p_theta(xt-1 | xt) = sum_x0 q(xt-1 | xt, x0) * p_theta(x0 | xt)\n",
    "\n",
    "        # VLB loss components\n",
    "        losses = {}\n",
    "\n",
    "        # L0: Direct reconstruction loss at t=1\n",
    "        mask_t1 = (t == 1).float()\n",
    "        if mask_t1.sum() > 0:\n",
    "            x_start_onehot = F.one_hot(x_start, self.num_classes).float()\n",
    "            l0 = -torch.sum(x_start_onehot * torch.log(x0_pred_probs + 1e-8), dim=-1)\n",
    "            losses[\"l0\"] = (mask_t1 * l0.mean(dim=tuple(range(1, len(l0.shape))))).sum() / (mask_t1.sum() + 1e-8)\n",
    "        else:\n",
    "            losses[\"l0\"] = torch.tensor(0.0, device=device)\n",
    "\n",
    "        # Lt-1: KL divergence terms for t > 1\n",
    "        mask_t_gt1 = (t > 1).float()\n",
    "        if mask_t_gt1.sum() > 0:\n",
    "            # Compute q(xt-1 | xt, x0)\n",
    "            q_posterior_probs = torch.exp(self.q_posterior(x_start, xt, t))\n",
    "\n",
    "            # Compute p_theta(xt-1 | xt) using x0 parameterization\n",
    "            p_theta_probs = self._compute_reverse_probs(xt, x0_pred_probs, t)\n",
    "\n",
    "            # KL divergence\n",
    "            kl = torch.sum(q_posterior_probs * torch.log(q_posterior_probs / (p_theta_probs + 1e-8) + 1e-8), dim=-1)\n",
    "            losses[\"lt\"] = (mask_t_gt1 * kl.mean(dim=tuple(range(1, len(kl.shape))))).sum() / (mask_t_gt1.sum() + 1e-8)\n",
    "        else:\n",
    "            losses[\"lt\"] = torch.tensor(0.0, device=device)\n",
    "\n",
    "        # LT: Prior matching (should be small if T is large enough)\n",
    "        mask_tT = (t == self.timesteps - 1).float()\n",
    "        if mask_tT.sum() > 0:\n",
    "            # Assuming uniform prior\n",
    "            uniform_prior = torch.ones_like(x0_pred_probs) / self.num_classes\n",
    "            xt_onehot = F.one_hot(xt, self.num_classes).float()\n",
    "            prior_kl = torch.sum(xt_onehot * torch.log(xt_onehot / uniform_prior + 1e-8), dim=-1)\n",
    "            losses[\"lT\"] = (mask_tT * prior_kl.mean(dim=tuple(range(1, len(prior_kl.shape))))).sum() / (\n",
    "                mask_tT.sum() + 1e-8\n",
    "            )\n",
    "        else:\n",
    "            losses[\"lT\"] = torch.tensor(0.0, device=device)\n",
    "\n",
    "        # Auxiliary loss: direct x0 prediction\n",
    "        x_start_onehot = F.one_hot(x_start, self.num_classes).float()\n",
    "        aux_loss = -torch.sum(x_start_onehot * torch.log(x0_pred_probs + 1e-8), dim=-1)\n",
    "        losses[\"aux\"] = aux_loss.mean()\n",
    "\n",
    "        # Total VLB loss\n",
    "        losses[\"vlb\"] = losses[\"l0\"] + losses[\"lt\"] + losses[\"lT\"]\n",
    "\n",
    "        # Hybrid loss (L_lambda from paper)\n",
    "        losses[\"total\"] = losses[\"vlb\"] + self.hybrid_loss_coeff * losses[\"aux\"]\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def _compute_reverse_probs(self, xt: torch.Tensor, x0_pred_probs: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute p_theta(xt-1 | xt) using x0 parameterization\n",
    "        \"\"\"\n",
    "        batch_size = xt.shape[0]\n",
    "\n",
    "        # Sum over all possible x0 values\n",
    "        reverse_probs = torch.zeros(xt.shape + (self.num_classes,), device=xt.device)\n",
    "\n",
    "        for x0_val in range(self.num_classes):\n",
    "            # Create x0 with value x0_val everywhere\n",
    "            x0_candidate = torch.full_like(xt, x0_val)\n",
    "\n",
    "            # Get q(xt-1 | xt, x0_candidate)\n",
    "            if t[0] > 0:\n",
    "                q_prob = torch.exp(self.q_posterior(x0_candidate, xt, t))\n",
    "\n",
    "                # Weight by p_theta(x0_candidate | xt)\n",
    "                x0_prob = x0_pred_probs[..., x0_val : x0_val + 1]\n",
    "\n",
    "                reverse_probs += q_prob * x0_prob\n",
    "\n",
    "        return reverse_probs\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, model: nn.Module, xt: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Sample from p_theta(xt-1 | xt)\n",
    "        \"\"\"\n",
    "        # Predict x0\n",
    "        x0_pred_logits = model(xt, t)\n",
    "        x0_pred_probs = F.softmax(x0_pred_logits, dim=-1)\n",
    "\n",
    "        if t[0] == 0:\n",
    "            # At t=0, return the predicted x0\n",
    "            return torch.multinomial(x0_pred_probs.view(-1, self.num_classes), 1).view(xt.shape)\n",
    "\n",
    "        # Compute reverse probabilities\n",
    "        reverse_probs = self._compute_reverse_probs(xt, x0_pred_probs, t)\n",
    "\n",
    "        # Sample from the reverse distribution\n",
    "        xt_prev = torch.multinomial(reverse_probs.view(-1, self.num_classes), 1).view(xt.shape)\n",
    "\n",
    "        return xt_prev\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self, model: nn.Module, shape: Tuple[int, ...], device: str = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Generate samples by running the reverse diffusion process\n",
    "        \"\"\"\n",
    "        if device is None:\n",
    "            device = self.device\n",
    "\n",
    "        batch_size = shape[0]\n",
    "\n",
    "        # Start from noise (uniform random or mask tokens)\n",
    "        if self.transition_type == TransitionType.ABSORBING:\n",
    "            xt = torch.full(shape, self.mask_token_id, device=device, dtype=torch.long)\n",
    "        else:\n",
    "            xt = torch.randint(0, self.num_classes, shape, device=device, dtype=torch.long)\n",
    "\n",
    "        # Reverse diffusion\n",
    "        for i in reversed(range(self.timesteps)):\n",
    "            t = torch.full((batch_size,), i, device=device, dtype=torch.long)\n",
    "            xt = self.p_sample(model, xt, t)\n",
    "\n",
    "        return xt\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def ddim_sample(\n",
    "        self, model: nn.Module, shape: Tuple[int, ...], eta: float = 0.0, ddim_steps: int = 50, device: str = None\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        DDIM-style deterministic sampling (adapted for discrete case)\n",
    "        \"\"\"\n",
    "        if device is None:\n",
    "            device = self.device\n",
    "\n",
    "        batch_size = shape[0]\n",
    "\n",
    "        # Create subsequence of timesteps\n",
    "        step_size = self.timesteps // ddim_steps\n",
    "        timesteps = list(range(0, self.timesteps, step_size))\n",
    "\n",
    "        # Start from noise\n",
    "        if self.transition_type == TransitionType.ABSORBING:\n",
    "            xt = torch.full(shape, self.mask_token_id, device=device, dtype=torch.long)\n",
    "        else:\n",
    "            xt = torch.randint(0, self.num_classes, shape, device=device, dtype=torch.long)\n",
    "\n",
    "        # Reverse diffusion with larger steps\n",
    "        for i, t_cur in enumerate(reversed(timesteps)):\n",
    "            t = torch.full((batch_size,), t_cur, device=device, dtype=torch.long)\n",
    "\n",
    "            # Predict x0\n",
    "            x0_pred_logits = model(xt, t)\n",
    "            x0_pred_probs = F.softmax(x0_pred_logits, dim=-1)\n",
    "\n",
    "            if i == len(timesteps) - 1:\n",
    "                # Last step: return predicted x0\n",
    "                xt = torch.multinomial(x0_pred_probs.view(-1, self.num_classes), 1).view(xt.shape)\n",
    "            else:\n",
    "                # Intermediate step: use DDIM-like update\n",
    "                t_prev = timesteps[len(timesteps) - i - 2] if i < len(timesteps) - 1 else 0\n",
    "\n",
    "                # For simplicity, use probabilistic sampling\n",
    "                # A more sophisticated DDIM adaptation could be implemented\n",
    "                reverse_probs = self._compute_reverse_probs(xt, x0_pred_probs, t)\n",
    "                xt = torch.multinomial(reverse_probs.view(-1, self.num_classes), 1).view(xt.shape)\n",
    "\n",
    "        return xt\n",
    "\n",
    "\n",
    "# Example usage and testing\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a simple model for testing\n",
    "    class SimpleModel(nn.Module):\n",
    "        def __init__(self, num_classes: int, hidden_dim: int = 256):\n",
    "            super().__init__()\n",
    "            self.time_embed = nn.Embedding(1000, hidden_dim)\n",
    "            self.input_embed = nn.Embedding(num_classes, hidden_dim)\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, num_classes),\n",
    "            )\n",
    "\n",
    "        def forward(self, x, t):\n",
    "            # x: [batch_size, seq_len], t: [batch_size]\n",
    "            x_embed = self.input_embed(x)  # [batch_size, seq_len, hidden_dim]\n",
    "            t_embed = self.time_embed(t).unsqueeze(1)  # [batch_size, 1, hidden_dim]\n",
    "\n",
    "            # Broadcast time embedding\n",
    "            t_embed = t_embed.expand(-1, x.shape[1], -1)\n",
    "\n",
    "            # Concatenate and predict\n",
    "            combined = torch.cat([x_embed, t_embed], dim=-1)\n",
    "            logits = self.net(combined)\n",
    "\n",
    "            return logits\n",
    "\n",
    "    # Test the D3PM implementation\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Initialize D3PM with absorbing diffusion\n",
    "    d3pm = D3PM(\n",
    "        num_classes=1000,\n",
    "        timesteps=100,\n",
    "        transition_type=TransitionType.ABSORBING,\n",
    "        noise_schedule=NoiseSchedule.COSINE,\n",
    "        device=device,\n",
    "    ).to(device)\n",
    "\n",
    "    # Create a simple model\n",
    "    model = SimpleModel(num_classes=1000).to(device)\n",
    "\n",
    "    # Test data\n",
    "    batch_size, seq_len = 4, 32\n",
    "    x_start = torch.randint(0, 1000, (batch_size, seq_len), device=device)\n",
    "\n",
    "    # Test forward process\n",
    "    t = torch.randint(0, 100, (batch_size,), device=device)\n",
    "    xt = d3pm.q_sample(x_start, t)\n",
    "    print(f\"Original shape: {x_start.shape}, Noisy shape: {xt.shape}\")\n",
    "\n",
    "    # Test loss computation\n",
    "    losses = d3pm.compute_loss(model, x_start, t)\n",
    "    print(f\"Losses: {[(k, v.item()) for k, v in losses.items()]}\")\n",
    "\n",
    "    # Test sampling\n",
    "    samples = d3pm.p_sample_loop(model, (2, seq_len), device=device)\n",
    "    print(f\"Generated samples shape: {samples.shape}\")\n",
    "\n",
    "    # Test DDIM sampling\n",
    "    ddim_samples = d3pm.ddim_sample(model, (2, seq_len), ddim_steps=10, device=device)\n",
    "    print(f\"DDIM samples shape: {ddim_samples.shape}\")\n",
    "\n",
    "    print(\"D3PM implementation test completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba95d71a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-implementations (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
