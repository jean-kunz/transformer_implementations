{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e60c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n",
      "env: PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0\n"
     ]
    }
   ],
   "source": [
    "# | default_exp attention\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "%env PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4404c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "from icecream import ic\n",
    "import math\n",
    "from my_transformer.utils import save_model, load_model\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, normalizers\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "import json\n",
    "import os\n",
    "\n",
    "# from rich import print\n",
    "from rich.pretty import pprint\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b82294f",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7edbbc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Hard Times In New York Town',\n",
       "  'Come you ladies and you gentlemen, a-listen to my song',\n",
       "  'Sing it to you right, but you might think it’s wrong',\n",
       "  'Just a little glimpse of a story I’ll tell',\n",
       "  '’Bout an East Coast city that you all know well',\n",
       "  'It’s hard times in the city',\n",
       "  'Livin’ down in New York town',\n",
       "  'Old New York City is a friendly old town',\n",
       "  'From Washington Heights to Harlem on down',\n",
       "  'There’s a-mighty many people all millin’ all around'],\n",
       " 14318)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset/bob_dylan_lyrics.csv\")\n",
    "lines = []\n",
    "nb_rows = 999999\n",
    "row_id = 0\n",
    "for r in df.iterrows():\n",
    "    # todo: one line is one sentence.\n",
    "    lines.append(r[1][\"title\"])\n",
    "    # sentences.append(r[1][\"title\"] + \"\\n\" + r[1][\"lyrics\"])\n",
    "    lyrics = r[1][\"lyrics\"].split(\"\\n\")\n",
    "    for line in lyrics:\n",
    "        if len(line.strip()) > 0:\n",
    "            lines.append(line.strip())\n",
    "        row_id += 1\n",
    "\n",
    "lines[:10], len(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6bab58",
   "metadata": {},
   "source": [
    "### Simple Custom Tokenizer for Bob Dylan Lyrics\n",
    "\n",
    "Create a simple BPE (Byte-Pair Encoding) tokenizer trained specifically on Dylan's lyrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92266e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDylanTokenizer:\n",
    "    def __init__(self, vocab_size=3000):\n",
    "        vocab_size = vocab_size\n",
    "        tokenizer = None\n",
    "\n",
    "    def train_tokenizer(self, corpus: list[str], save_path: str = \"./simple_dylan_tokenizer\"):\n",
    "        # Initialize simple BPE tokenizer\n",
    "        tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "\n",
    "        # Simple whitespace pre-tokenization\n",
    "        tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "        # Simple trainer\n",
    "        trainer = BpeTrainer(\n",
    "            vocab_size=self.vocab_size, special_tokens=[\"[PAD]\", \"[UNK]\", \"[MASK]\"], min_frequency=2, show_progress=True\n",
    "        )\n",
    "\n",
    "        # Train the tokenizer\n",
    "        tokenizer.train_from_iterator(corpus, trainer)\n",
    "\n",
    "        # Save tokenizer\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        tokenizer.save(f\"{save_path}/tokenizer.json\")\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        print(f\"Tokenizer trained and saved to {save_path}\")\n",
    "\n",
    "        return tokenizer\n",
    "\n",
    "    def load_tokenizer(self, save_path=\"./simple_dylan_tokenizer\"):\n",
    "        \"\"\"Load the trained tokenizer\"\"\"\n",
    "        tokenizer_path = f\"{save_path}/tokenizer.json\"\n",
    "        if os.path.exists(tokenizer_path):\n",
    "            self.tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "            return self.tokenizer\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Tokenizer not found at {tokenizer_path}\")\n",
    "\n",
    "    def get_transformers_tokenizer(self):\n",
    "        \"\"\"Convert to HuggingFace tokenizer for compatibility\"\"\"\n",
    "        if self.tokenizer is None:\n",
    "            raise ValueError(\"Tokenizer not trained or loaded\")\n",
    "\n",
    "        # Create fast tokenizer wrapper\n",
    "        fast_tokenizer = PreTrainedTokenizerFast(\n",
    "            tokenizer_object=self.tokenizer, pad_token=\"[PAD]\", unk_token=\"[UNK]\", mask_token=\"[MASK]\"\n",
    "        )\n",
    "\n",
    "        return fast_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76920799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(tokenizer): 3000\n",
      "ic| tokenizer.special_tokens_map: {'mask_token': '[MASK]', 'pad_token': '[PAD]', 'unk_token': '[UNK]'}\n",
      "| len(tokenizer): 3000\n",
      "ic| tokenizer.special_tokens_map: {'mask_token': '[MASK]', 'pad_token': '[PAD]', 'unk_token': '[UNK]'}\n",
      "ic| phrase: \"The answer my friend is blowin' in the wind\"\n",
      "ic| decoded:ic| phrase: \"The answer my friend is blowin' in the wind\"\n",
      "ic| decoded:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Tokenizer trained and saved to ./simple_dylan_tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \"The answer my friend is blowin ' in the wind\"\n",
      "ic| token_strs: ['The', 'answer',\"The answer my friend is blowin ' in the wind\"\n",
      "ic| token_strs: ['The', 'answer', 'my', 'friend', 'is', 'blowin', \"'\", 'in', 'the', 'wind']\n",
      " 'my', 'friend', 'is', 'blowin', \"'\", 'in', 'the', 'wind']\n"
     ]
    }
   ],
   "source": [
    "# Initialize simple Dylan tokenizer\n",
    "dylan_tokenizer = SimpleDylanTokenizer(vocab_size=3000)\n",
    "\n",
    "# Train the tokenizer on Dylan lyrics\n",
    "dylan_tokenizer.train_tokenizer(corpus=lines, save_path=\"./simple_dylan_tokenizer\")\n",
    "\n",
    "# Convert to HuggingFace format for compatibility\n",
    "tokenizer = dylan_tokenizer.get_transformers_tokenizer()\n",
    "\n",
    "ic(len(tokenizer))\n",
    "ic(tokenizer.special_tokens_map)\n",
    "\n",
    "\n",
    "phrase = \"The answer my friend is blowin' in the wind\"\n",
    "\n",
    "tokens = tokenizer.encode(phrase, add_special_tokens=False)\n",
    "decoded = tokenizer.decode(tokens, skip_special_tokens=False)\n",
    "token_strs = tokenizer.convert_ids_to_tokens(tokens)\n",
    "ic(phrase)\n",
    "ic(decoded)\n",
    "ic(token_strs);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a50552a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(dataset): 14318\n",
      "ic| seq_len: 20\n",
      "ic| len(tokenizer): 3000\n",
      "ic| len(dataset): 14318\n",
      "ic| seq_len: 20\n",
      "ic| len(tokenizer): 3000\n",
      "ic| sample_batch.shape: torch.Size([8, 20])\n",
      "ic| tokenizer.decode(sample_batch[0].tolist(), skip_special_tokens=False): ('He ’ s eat in ’ ch it lin s [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "| sample_batch.shape: torch.Size([8, 20])\n",
      "ic| tokenizer.decode(sample_batch[0].tolist(), skip_special_tokens=False): ('He ’ s eat in ’ ch it lin s [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                                                                            '[PAD] [PAD]')                                                                            '[PAD] [PAD]')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length in dataset: 41\n"
     ]
    }
   ],
   "source": [
    "class SimpleDylanDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, seq_len=128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "        self.examples = []\n",
    "        max_seq_len = 0\n",
    "\n",
    "        for line in texts:\n",
    "            # Simple tokenization - no structure tokens\n",
    "            tokens = tokenizer.encode(line.strip(), add_special_tokens=False)\n",
    "            token_nb = len(tokens)\n",
    "            max_seq_len = max(max_seq_len, token_nb)\n",
    "            # Truncate if too long\n",
    "\n",
    "            if token_nb > seq_len:\n",
    "                tokens = tokens[:seq_len]\n",
    "\n",
    "            if token_nb > 0:  # Skip empty sequences\n",
    "                self.examples.append(tokens)\n",
    "        print(f\"Max sequence length in dataset: {max_seq_len}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.examples[idx]\n",
    "        pad_id = self.tokenizer.pad_token_id if hasattr(self.tokenizer, \"pad_token_id\") else 0\n",
    "\n",
    "        # Pad to sequence length\n",
    "        padded = tokens + [pad_id] * (self.seq_len - len(tokens))\n",
    "        return torch.tensor(padded[: self.seq_len], dtype=torch.long)\n",
    "\n",
    "\n",
    "seq_len = 20  # Keep shorter sequences for memory efficiency\n",
    "batch_size = 8\n",
    "\n",
    "# Create dataset with selected tokenizer\n",
    "dataset = SimpleDylanDataset(lines, tokenizer, seq_len=seq_len)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "ic(len(dataset))\n",
    "ic(seq_len)\n",
    "ic(len(tokenizer))\n",
    "\n",
    "# Test the dataset\n",
    "sample_batch = next(iter(dataloader))\n",
    "ic(sample_batch.shape)\n",
    "ic(tokenizer.decode(sample_batch[0].tolist(), skip_special_tokens=False));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af94d38b",
   "metadata": {},
   "source": [
    "## Diffusion model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "54f5a9a5",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Timeline:  x₀ ────→ x₁ ────→ x₂ ────→ x₃\n",
    "          clean   noisy   noisier  noisiest\n",
    "           ↑        ↑        ↑        ↑\n",
    "         \"hello\"  \"h[M]lo\" \"[M][M]o\" \"[M][M][M]\"\n",
    "\n",
    "Forward process q(x_t | x_{t-1}):\n",
    "- q(x₁|x₀): \"hello\" → \"h[M]lo\" (add some noise)\n",
    "- q(x₂|x₁): \"h[M]lo\" → \"[M][M]o\" (add more noise)\n",
    "\n",
    "Posterior q(x_{t-1} | x_t, x₀):\n",
    "- q(x₁|x₂, x₀): Given \"[M][M]o\" and knowing original was \"hello\", \n",
    "                 what was x₁? Answer: probably \"h[M]lo\"\n",
    "- q(x₀|x₁, x₀): Given \"h[M]lo\" and knowing original was \"hello\",\n",
    "                 what was x₀? Answer: definitely \"hello\"\n",
    "\n",
    "\n",
    "# The KL loss compares:\n",
    "KL[q(x_{t-1}|x_t,x_0) || p_θ(x_{t-1}|x_t)]\n",
    "   ↑                    ↑\n",
    "   True denoising       Model's denoising\n",
    "   (uses ground truth) (learned)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beb72e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformScheduler(nn.Module):\n",
    "    \"\"\"Simple uniform transition scheduler with linear noise schedule.\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int, num_timesteps: int, beta_start: float = 0.0001, beta_end: float = 0.02):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "\n",
    "        # Create schedule and transition matrices\n",
    "        betas = self._create_linear_schedule()\n",
    "        # so they are put to device automatically\n",
    "        self.register_buffer(\"betas\", betas)\n",
    "        Q_t = self._create_transition_matrices()\n",
    "        self.register_buffer(\"Q_t\", Q_t)\n",
    "        Q_bar_t = self._create_cumulative_matrices()\n",
    "        self.register_buffer(\"Q_bar_t\", Q_bar_t)\n",
    "\n",
    "    def _create_linear_schedule(self) -> torch.Tensor:\n",
    "        \"\"\"Create linear beta schedule: β_t increases linearly from beta_start to beta_end.\"\"\"\n",
    "        return torch.linspace(self.beta_start, self.beta_end, self.num_timesteps)\n",
    "\n",
    "    def _create_transition_matrices(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Create uniform transition matrices: Q_t = (1-β_t)I + β_t/K * 11^T\n",
    "\n",
    "        This means:\n",
    "        - Stay in same state with probability (1-β_t)\n",
    "        - Transition to any state (including same) with probability β_t/K each\n",
    "        \"\"\"\n",
    "        Q_matrices = torch.zeros(self.num_timesteps, self.num_classes, self.num_classes)\n",
    "\n",
    "        for t in range(self.num_timesteps):\n",
    "            beta_t = self.betas[t].item()\n",
    "\n",
    "            # Diagonal: probability of staying in same state\n",
    "            Q_t = (1 - beta_t) * torch.eye(self.num_classes)\n",
    "\n",
    "            # Off-diagonal: uniform probability of transitioning to any state\n",
    "            Q_t += beta_t / self.num_classes * torch.ones(self.num_classes, self.num_classes)\n",
    "\n",
    "            Q_matrices[t] = Q_t\n",
    "\n",
    "        return Q_matrices\n",
    "\n",
    "    def _create_cumulative_matrices(self) -> torch.Tensor:\n",
    "        \"\"\"Create cumulative matrices: Q̄_t = Q_1 * Q_2 * ... * Q_t\"\"\"\n",
    "        Q_bar_matrices = torch.zeros(self.num_timesteps, self.num_classes, self.num_classes)\n",
    "        Q_bar_matrices[0] = self.Q_t[0]\n",
    "\n",
    "        for t in range(1, self.num_timesteps):\n",
    "            Q_bar_matrices[t] = torch.matmul(Q_bar_matrices[t - 1], self.Q_t[t])\n",
    "\n",
    "        return Q_bar_matrices\n",
    "\n",
    "    def add_noise(self, x_0: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply forward diffusion: sample from q(x_t | x_0).\n",
    "\n",
    "        For uniform transitions, this uses the cumulative matrix Q̄_t.\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x_0.shape\n",
    "        device = x_0.device\n",
    "\n",
    "        # Clamp x_0 to valid token range to prevent out-of-bounds errors\n",
    "        x_0_clamped = torch.clamp(x_0, 0, self.num_classes - 1)\n",
    "\n",
    "        # Convert to one-hot encoding\n",
    "        x_0_onehot = F.one_hot(x_0_clamped, self.num_classes).to(device).float()  # [B, L, K]\n",
    "\n",
    "        x_t = torch.zeros_like(x_0).to(device)  # [B, L]\n",
    "        self.Q_bar_t = self.Q_bar_t.to(device)  # Ensure matrices are on the correct device\n",
    "        for i in range(batch_size):\n",
    "            # Get cumulative transition matrix for this timestep\n",
    "            t_val = t[i].item()\n",
    "\n",
    "            # Add bounds checking to prevent IndexError\n",
    "            t_val = max(0, min(t_val, self.num_timesteps - 1))\n",
    "\n",
    "            Q_bar = self.Q_bar_t[t_val].to(device)  # [K, K]\n",
    "\n",
    "            # Compute transition probabilities: x_0 @ Q̄_t\n",
    "            # This gives probability distribution over x_t for each position\n",
    "            probs = torch.matmul(x_0_onehot[i], Q_bar)  # [L, K]\n",
    "\n",
    "            # Add numerical stability: ensure probabilities are non-negative and sum to 1\n",
    "            probs = torch.clamp(probs, min=1e-8)  # Ensure non-negative\n",
    "            probs = probs / probs.sum(dim=-1, keepdim=True)  # Normalize\n",
    "\n",
    "            # Sample from categorical distribution\n",
    "            flat_probs = probs.view(-1, self.num_classes)  # [L, K]\n",
    "\n",
    "            # Additional safety check for multinomial\n",
    "            prob_sums = flat_probs.sum(dim=-1)\n",
    "            if (prob_sums <= 0).any():\n",
    "                print(f\"Warning: Invalid probability distribution detected\")\n",
    "                print(f\"prob_sums: {prob_sums}\")\n",
    "                print(f\"flat_probs sample: {flat_probs[0]}\")\n",
    "                # Fallback to uniform distribution\n",
    "                flat_probs = torch.ones_like(flat_probs) / self.num_classes\n",
    "\n",
    "            flat_samples = torch.multinomial(flat_probs, 1).squeeze(-1)  # [L]\n",
    "            x_t[i] = flat_samples\n",
    "\n",
    "        return x_t\n",
    "\n",
    "    def get_posterior_params(self, x_t: torch.Tensor, x_0: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute true posterior q(x_{t-1} | x_t, x_0) using Equation 3.\n",
    "\n",
    "        From the paper: q(x_{t-1}|x_t,x_0) = Cat(x_{t-1}; p = x_t Q_t^T ⊙ x_0 Q̄_{t-1} / (x_0 Q̄_t x_t^T))\n",
    "\n",
    "        This tells us: given we observe x_t at time t and know the original was x_0,\n",
    "        what's the probability distribution over what x_{t-1} could have been?\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x_t.shape\n",
    "        device = x_t.device\n",
    "\n",
    "        # Clamp token indices to valid range\n",
    "        x_t_clamped = torch.clamp(x_t, 0, self.num_classes - 1)\n",
    "        x_0_clamped = torch.clamp(x_0, 0, self.num_classes - 1)\n",
    "\n",
    "        posteriors = torch.zeros(batch_size, seq_len, self.num_classes, device=device)\n",
    "\n",
    "        for i, t_val in enumerate(t):\n",
    "            # Add bounds checking here too\n",
    "            t_val = max(0, min(t_val.item(), self.num_timesteps - 1))\n",
    "\n",
    "            if t_val == 0:\n",
    "                # Special case: t=0 means we're asking for q(x_{-1}|x_0, x_0)\n",
    "                # This doesn't make physical sense, so return uniform or x_0\n",
    "                # In practice, this case shouldn't occur in training\n",
    "                posteriors[i] = F.one_hot(x_0_clamped[i], self.num_classes).float()\n",
    "                continue\n",
    "\n",
    "            # Get transition matrices\n",
    "            Q_t = self.Q_t[t_val].to(device)  # [K, K] - single step t\n",
    "            Q_bar_t_minus_1 = self.Q_bar_t[t_val - 1].to(device)  # [K, K] - cumulative to t-1\n",
    "            Q_bar_t = self.Q_bar_t[t_val].to(device)  # [K, K] - cumulative to t\n",
    "\n",
    "            # For each position in sequence\n",
    "            for pos in range(seq_len):\n",
    "                x_0_idx = x_0_clamped[i, pos].item()  # Original token index (clamped)\n",
    "                x_t_idx = x_t_clamped[i, pos].item()  # Current token index (clamped)\n",
    "\n",
    "                # Compute posterior using Bayes rule:\n",
    "                # q(x_{t-1}|x_t,x_0) ∝ q(x_t|x_{t-1},x_0) * q(x_{t-1}|x_0)\n",
    "                #                    = q(x_t|x_{t-1}) * q(x_{t-1}|x_0)  [Markov property]\n",
    "\n",
    "                posterior = torch.zeros(self.num_classes, device=device)\n",
    "\n",
    "                # For each possible value of x_{t-1}\n",
    "                for x_prev_idx in range(self.num_classes):\n",
    "                    # q(x_{t-1}|x_0): probability that x_{t-1} = x_prev_idx given x_0\n",
    "                    q_prev_given_x0 = Q_bar_t_minus_1[x_0_idx, x_prev_idx]\n",
    "\n",
    "                    # q(x_t|x_{t-1}): probability that x_t = x_t_idx given x_{t-1} = x_prev_idx\n",
    "                    q_curr_given_prev = Q_t[x_prev_idx, x_t_idx]\n",
    "\n",
    "                    # Joint probability\n",
    "                    posterior[x_prev_idx] = q_curr_given_prev * q_prev_given_x0\n",
    "\n",
    "                # Normalize to get proper probability distribution\n",
    "                posterior_sum = posterior.sum()\n",
    "                if posterior_sum > 1e-8:\n",
    "                    posterior = posterior / posterior_sum\n",
    "                else:\n",
    "                    # Fallback to uniform if numerical issues\n",
    "                    posterior = torch.ones(self.num_classes, device=device) / self.num_classes\n",
    "\n",
    "                posteriors[i, pos] = posterior\n",
    "\n",
    "        return posteriors\n",
    "\n",
    "    def compute_kl_divergence(self, true_posterior: torch.Tensor, pred_posterior: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute KL[q(x_{t-1}|x_t,x_0) || p_θ(x_{t-1}|x_t)]\"\"\"\n",
    "        kl = torch.sum(true_posterior * (torch.log(true_posterior + 1e-8) - torch.log(pred_posterior + 1e-8)), dim=-1)\n",
    "        return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d24517b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=1: x_0: [42, 15, 73], x_t: [42, 15, 73], true x_{t-1}: [42, 15, 73],\n",
      "equals x_0: True\n",
      "t=10: x_0: [42, 15, 73], x_t: [42, 15, 73], true x_{t-1}: [42, 15, 73],\n",
      "equals x_0: True\n",
      "t=50: x_0: [42, 15, 73], x_t: [42, 15, 73], true x_{t-1}: [42, 15, 73],\n",
      "equals x_0: True\n",
      "t=100: x_0: [42, 15, 73], x_t: [42, 15, 73], true x_{t-1}: [42, 15, 73],\n",
      "equals x_0: True\n",
      "t=500: x_0: [42, 15, 73], x_t: [37, 94, 41], true x_{t-1}: [37, 94, 41],\n",
      "equals x_0: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler = UniformScheduler(num_classes=100, num_timesteps=1000).to(device)\n",
    "\n",
    "x_0 = torch.tensor([[42, 15, 73]])  # Original tokens\n",
    "\n",
    "# Check at different timesteps\n",
    "for t_val in [1, 10, 50, 100, 500]:\n",
    "    t = torch.tensor([t_val])\n",
    "    x_t = scheduler.add_noise(x_0, t)\n",
    "\n",
    "    true_posterior = scheduler.get_posterior_params(x_t, x_0, t)\n",
    "    true_prev = true_posterior.argmax(dim=-1)\n",
    "\n",
    "    print(\n",
    "        f\"t={t_val}: x_0: {x_0[0].tolist()}, x_t: {x_t[0].tolist()}, true x_{{t-1}}: {true_prev[0].tolist()},\\nequals x_0: {true_prev[0].equal(x_0[0])}\"\n",
    "    )\n",
    "scheduler.Q_t.device, scheduler.Q_bar_t.device\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac5fd249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing posterior evolution...\n",
      "Evolution of posterior q(x_{t-1} | x_t, x_0) as t increases:\n",
      "(Shows probability of each token being x_{t-1})\n",
      "\n",
      "t=1, x_0=1, x_t=1,  P(x_{t-1} = k): ['0.001', '0.996', '0.001', '0.001', '0.001'],Most likely x_{t-1}: 1\n",
      "t=2, x_0=1, x_t=2,  P(x_{t-1} = k): ['0.032', '0.461', '0.444', '0.032', '0.032'],Most likely x_{t-1}: 1\n",
      "t=3, x_0=1, x_t=1,  P(x_{t-1} = k): ['0.015', '0.941', '0.015', '0.015', '0.015'],Most likely x_{t-1}: 1\n",
      "t=4, x_0=1, x_t=0,  P(x_{t-1} = k): ['0.517', '0.260', '0.074', '0.074', '0.074'],Most likely x_{t-1}: 0\n",
      "t=5, x_0=1, x_t=4,  P(x_{t-1} = k): ['0.097', '0.205', '0.097', '0.097', '0.504'],Most likely x_{t-1}: 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test that posterior evolves correctly as we move through timesteps.\"\"\"\n",
    "print(\"Testing posterior evolution...\")\n",
    "\n",
    "vocab_size = 5  # Very small for clear visualization\n",
    "scheduler = UniformScheduler(num_classes=vocab_size, num_timesteps=10, beta_start=0.1, beta_end=0.9).to(device)\n",
    "\n",
    "x_0 = torch.tensor([[1]])  # Single token, original = 1\n",
    "\n",
    "print(\"Evolution of posterior q(x_{t-1} | x_t, x_0) as t increases:\")\n",
    "print(\"(Shows probability of each token being x_{t-1})\")\n",
    "print()\n",
    "\n",
    "for t_val in range(1, 6):\n",
    "    t = torch.tensor([t_val])\n",
    "    x_t = scheduler.add_noise(x_0, t)\n",
    "    posterior = scheduler.get_posterior_params(x_t, x_0, t)\n",
    "    true_prev = posterior.argmax(dim=-1)\n",
    "\n",
    "    print(\n",
    "        f\"t={t_val}, x_0=1, x_t={x_t[0, 0].item()},  P(x_{{t-1}} = k): {[f'{p:.3f}' for p in posterior[0, 0].tolist()]},Most likely x_{{t-1}}: {posterior[0, 0].argmax().item()}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f727c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| inp.shape: torch.Size([8, 20])\n",
      "| inp.shape: torch.Size([8, 20])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes , here ’ s the story of the H ur rican e [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Yes , here ’ s the story of the H ur rican e [PAD] [PAD] [PAD] rag [PAD] [PAD] [PAD]\n",
      "Yes Seen here vent s the story Mu the H desert rican such [PAD] [PAD] feels [PAD] [PAD] [PAD] wherever\n",
      "Yes , walls ’ s ft story of the H ur rican e [PAD] rs [PAD] [PAD] [PAD] [PAD] carry\n"
     ]
    }
   ],
   "source": [
    "# Generate some noisy sentences\n",
    "inp = next(iter(dataloader)).to(device)\n",
    "ic(inp.shape)\n",
    "\n",
    "ds_scheduler = UniformScheduler(num_classes=len(tokenizer), num_timesteps=30)\n",
    "\n",
    "\n",
    "def demo_noise(inp, line_nb, step):\n",
    "    src_line = tokenizer.decode(inp[line_nb].cpu().numpy())\n",
    "    noisy_inp = ds_scheduler.add_noise(inp[line_nb : line_nb + 1], torch.tensor([step]).to(device))\n",
    "    noisy_line = tokenizer.decode(noisy_inp[0].cpu().numpy())\n",
    "    return src_line, noisy_line\n",
    "\n",
    "\n",
    "ic.disable()\n",
    "ic.enable()\n",
    "sent_nb = 4\n",
    "print(demo_noise(inp, sent_nb, 0)[1])\n",
    "print(demo_noise(inp, sent_nb, 12)[1])\n",
    "print(demo_noise(inp, sent_nb, 20)[1])\n",
    "print(demo_noise(inp, sent_nb, 29)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4de9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleD3PMModel(nn.Module):\n",
    "    \"\"\"Simple transformer model for D3PM.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        max_seq_len: int,\n",
    "        d_model: int = 256,\n",
    "        num_heads: int = 8,\n",
    "        num_layers: int = 4,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Embeddings\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_embedding = nn.Embedding(max_seq_len, d_model)\n",
    "\n",
    "        # Time embedding for diffusion timestep\n",
    "        self.time_embedding = nn.Sequential(nn.Linear(d_model, d_model), nn.GELU(), nn.Linear(d_model, d_model))\n",
    "\n",
    "        # Transformer layers\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=4 * d_model,\n",
    "            dropout=dropout,\n",
    "            activation=\"gelu\",\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "\n",
    "        # Output head to predict x₀\n",
    "        self.output_head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, vocab_size))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def _get_time_embedding(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Create sinusoidal time embeddings like in original Transformer.\"\"\"\n",
    "        half_dim = self.d_model // 2\n",
    "\n",
    "        # Create the frequency ratios\n",
    "        freqs = torch.exp(\n",
    "            -math.log(10000.0) * torch.arange(0, half_dim, dtype=torch.float32, device=t.device) / half_dim\n",
    "        )\n",
    "\n",
    "        # Expand dims to enable broadcasting: t is [batch_size], freqs is [half_dim]\n",
    "        time_freqs = t.float()[:, None] * freqs[None, :]  # [batch_size, half_dim]\n",
    "\n",
    "        # Create sin and cos components\n",
    "        emb = torch.cat([torch.sin(time_freqs), torch.cos(time_freqs)], dim=1)  # [batch_size, d_model]\n",
    "\n",
    "        if self.d_model % 2 == 1:  # Handle odd d_model\n",
    "            emb = torch.cat([emb, torch.zeros_like(emb[:, :1])], dim=1)\n",
    "\n",
    "        return self.time_embedding(emb)\n",
    "\n",
    "    def forward(self, x_t: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass: predict x₀ from x_t.\n",
    "\n",
    "        Args:\n",
    "            x_t: Noisy tokens, shape [batch_size, seq_len]\n",
    "            t: Timesteps, shape [batch_size]\n",
    "\n",
    "        Returns:\n",
    "            x0_logits: Predicted x₀ logits, shape [batch_size, seq_len, vocab_size]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x_t.shape\n",
    "        device = x_t.device\n",
    "\n",
    "        # Token embeddings\n",
    "        token_emb = self.token_embedding(x_t)  # [B, L, D]\n",
    "\n",
    "        # Position embeddings\n",
    "        positions = torch.arange(seq_len, device=device).unsqueeze(0).expand(batch_size, -1)\n",
    "        pos_emb = self.position_embedding(positions)  # [B, L, D]\n",
    "\n",
    "        # Time embeddings\n",
    "        time_emb = self._get_time_embedding(t)  # [B, D]\n",
    "        time_emb = time_emb.unsqueeze(1).expand(-1, seq_len, -1)  # [B, L, D]\n",
    "\n",
    "        # Combine all embeddings\n",
    "        x = self.dropout(token_emb + pos_emb + time_emb)  # [B, L, D]\n",
    "\n",
    "        # Transformer processing\n",
    "        x = self.transformer(x)  # [B, L, D]\n",
    "\n",
    "        # Predict x₀ logits\n",
    "        x0_logits = self.output_head(x)  # [B, L, vocab_size]\n",
    "\n",
    "        return x0_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0a19a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x_t.shape: torch.Size([8, 20])\n",
      "    x0_logits.shape: torch.Size([8, 20, 1000])\n",
      "    t.shape: torch.Size([8])\n",
      "| x_t.shape: torch.Size([8, 20])\n",
      "    x0_logits.shape: torch.Size([8, 20, 1000])\n",
      "    t.shape: torch.Size([8])\n",
      "ic| scheduler.Q_t.shape: torch.Size([50, 1000, 1000])\n",
      "    scheduler.Q_bar_t.shape: torch.Size([50, 1000, 1000])\n",
      "ic| scheduler.Q_t.shape: torch.Size([50, 1000, 1000])\n",
      "    scheduler.Q_bar_t.shape: torch.Size([50, 1000, 1000])\n"
     ]
    }
   ],
   "source": [
    "def compute_predicted_posterior(\n",
    "    scheduler: UniformScheduler, x0_logits: torch.Tensor, x_t: torch.Tensor, t: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute p_θ(x_{t-1}|x_t) using x₀-parameterization.\n",
    "\n",
    "    From Equation 4: p_θ(x_{t-1}|x_t) ∝ Σ q(x_{t-1},x_t|x̃₀) p̃_θ(x̃₀|x_t)\n",
    "\n",
    "    The true posterior is: q(x_{t-1}|x_t,x₀) ∝ q(x_t|x_{t-1}) q(x_{t-1}|x₀)\n",
    "\n",
    "    This is a fully vectorized implementation with no loops.\n",
    "    \"\"\"\n",
    "    batch_size, seq_len = x_t.shape\n",
    "    device = x_t.device\n",
    "    num_classes = scheduler.num_classes\n",
    "\n",
    "    # Convert model logits to probabilities\n",
    "    p_x0_given_xt = F.softmax(x0_logits, dim=-1)  # [B, L, K]\n",
    "\n",
    "    # Initialize result tensor\n",
    "    pred_posteriors = torch.zeros(batch_size, seq_len, num_classes, device=device)\n",
    "\n",
    "    # Handle t=0 case separately (early return for efficiency)\n",
    "    t_zero_mask = t == 0\n",
    "    if t_zero_mask.any():\n",
    "        # For t=0 cases, return softmax of x0_logits\n",
    "        pred_posteriors[t_zero_mask] = p_x0_given_xt[t_zero_mask]\n",
    "\n",
    "        # If all timesteps are 0, return early\n",
    "        if t_zero_mask.all():\n",
    "            return pred_posteriors\n",
    "\n",
    "    # Process non-zero timesteps\n",
    "    non_zero_mask = ~t_zero_mask\n",
    "    if not non_zero_mask.any():\n",
    "        return pred_posteriors\n",
    "\n",
    "    # Get indices for non-zero timesteps\n",
    "    t_non_zero = t[non_zero_mask]  # [N] where N = number of non-zero timesteps\n",
    "\n",
    "    # Get transition matrices for all non-zero timesteps\n",
    "    # Stack Q_t and Q_{t-1} matrices for vectorized operations\n",
    "    Q_t_stack = torch.stack([scheduler.Q_t[t_val] for t_val in t_non_zero])  # [N, K, K]\n",
    "    Q_t_minus_1_stack = torch.stack([scheduler.Q_t[t_val - 1] for t_val in t_non_zero])  # [N, K, K]\n",
    "\n",
    "    # Get relevant data for non-zero timesteps\n",
    "    x_t_non_zero = x_t[non_zero_mask]  # [N, L]\n",
    "    p_x0_non_zero = p_x0_given_xt[non_zero_mask]  # [N, L, K]\n",
    "\n",
    "    # Vectorized computation of posterior for all positions and timesteps\n",
    "    # We need to compute: Σ_{x0} p(x0|xt) * q(x_{t-1}|xt,x0)\n",
    "    # where q(x_{t-1}|xt,x0) ∝ q(xt|x_{t-1}) * q(x_{t-1}|x0)\n",
    "\n",
    "    # Create index tensors for gathering\n",
    "    batch_indices = torch.arange(len(t_non_zero), device=device)[:, None]  # [N, 1]\n",
    "    x_t_indices = x_t_non_zero  # [N, L] - current token indices\n",
    "\n",
    "    # For each possible x_{t-1} value, compute the posterior probability\n",
    "    pred_posterior_non_zero = torch.zeros(len(t_non_zero), seq_len, num_classes, device=device)\n",
    "\n",
    "    for x_prev in range(num_classes):\n",
    "        # For this x_{t-1} value, compute contribution from all possible x0 values\n",
    "\n",
    "        # q(x_t|x_{t-1}): transition probability from x_prev to current tokens\n",
    "        # Shape operations: Q_t_stack[batch_indices, x_prev, x_t_indices]\n",
    "        q_xt_given_xprev = Q_t_stack[batch_indices, x_prev, x_t_indices]  # [N, L]\n",
    "\n",
    "        # Avoid division by zero\n",
    "        Q_t_minus_1_vals = Q_t_minus_1_stack[batch_indices, x_prev, x_t_indices]  # [N, L]\n",
    "        q_xt_given_xprev = q_xt_given_xprev / (Q_t_minus_1_vals + 1e-8)\n",
    "\n",
    "        # q(x_{t-1}|x0): probability of being at x_prev given each possible x0\n",
    "        # Q_t_minus_1_stack[:, x0_indices, x_prev] for all x0_indices\n",
    "        q_xprev_given_x0 = Q_t_minus_1_stack[:, :, x_prev]  # [N, K]\n",
    "\n",
    "        # Expand dimensions for broadcasting\n",
    "        q_xt_given_xprev_expanded = q_xt_given_xprev[:, :, None]  # [N, L, 1]\n",
    "        q_xprev_given_x0_expanded = q_xprev_given_x0[:, None, :]  # [N, 1, K]\n",
    "\n",
    "        # Compute unnormalized posterior contribution for this x_{t-1}\n",
    "        # Shape: [N, L, K] = [N, L, 1] * [N, 1, K] * [N, L, K]\n",
    "        unnorm_contrib = q_xt_given_xprev_expanded * q_xprev_given_x0_expanded * p_x0_non_zero\n",
    "\n",
    "        # Sum over all possible x0 values (marginalization)\n",
    "        pred_posterior_non_zero[:, :, x_prev] = unnorm_contrib.sum(dim=-1)  # [N, L]\n",
    "\n",
    "    # Normalize the posterior distributions\n",
    "    pred_posterior_non_zero = pred_posterior_non_zero / (pred_posterior_non_zero.sum(dim=-1, keepdim=True) + 1e-8)\n",
    "\n",
    "    # Place results back into the full tensor\n",
    "    pred_posteriors[non_zero_mask] = pred_posterior_non_zero\n",
    "\n",
    "    return pred_posteriors\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "vocab_size = 1000\n",
    "seq_len = 20\n",
    "num_timesteps = 50  # Total number of timesteps\n",
    "t = torch.randint(0, num_timesteps, (batch_size,), device=device)\n",
    "x_t = torch.randint(0, vocab_size, (batch_size, seq_len), device=device)  # Simulated noisy input\n",
    "x0_logits = torch.randn(batch_size, seq_len, vocab_size, device=device)  # Simulated model output\n",
    "ic(x_t.shape, x0_logits.shape, t.shape)\n",
    "\n",
    "scheduler = UniformScheduler(num_classes=vocab_size, num_timesteps=num_timesteps).to(device)\n",
    "ic(scheduler.Q_t.shape, scheduler.Q_bar_t.shape)\n",
    "pred_posterior = compute_predicted_posterior(scheduler=scheduler, x0_logits=x0_logits, x_t=x_t, t=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43db492b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎨 Visual demonstration of compute_predicted_posterior...\n",
      "\n",
      "🔍 Timestep t = 0:\n",
      "   Input x_t: [[0, 1, 2], [2, 0, 1]],  Predicted x0 (argmax): [[0, 1, 2], [3, 0, 1]]\n",
      "   Posterior p(x_{t-1}|x_t) for each position:\n",
      "     Batch 0, Pos 0: most likely x_{t-1} = 0 (prob=0.980)full distribution: ['0.980', '0.007', '0.007', '0.007']\n",
      "     Batch 0, Pos 1: most likely x_{t-1} = 1 (prob=0.980)full distribution: ['0.007', '0.980', '0.007', '0.007']\n",
      "     Batch 0, Pos 2: most likely x_{t-1} = 2 (prob=0.980)full distribution: ['0.007', '0.007', '0.980', '0.007']\n",
      "     Batch 1, Pos 0: most likely x_{t-1} = 3 (prob=0.980)full distribution: ['0.007', '0.007', '0.007', '0.980']\n",
      "     Batch 1, Pos 1: most likely x_{t-1} = 0 (prob=0.980)full distribution: ['0.980', '0.007', '0.007', '0.007']\n",
      "     Batch 1, Pos 2: most likely x_{t-1} = 1 (prob=0.980)full distribution: ['0.007', '0.980', '0.007', '0.007']\n",
      "   Entropy (uncertainty): [[0.11907892674207687, 0.11907892674207687, 0.11907892674207687], [0.11907892674207687, 0.11907892674207687, 0.11907892674207687]]\n",
      "\n",
      "🔍 Timestep t = 1:\n",
      "   Input x_t: [[0, 1, 2], [2, 0, 1]],  Predicted x0 (argmax): [[0, 1, 2], [3, 0, 1]]\n",
      "   Posterior p(x_{t-1}|x_t) for each position:\n",
      "     Batch 0, Pos 0: most likely x_{t-1} = 0 (prob=0.492)full distribution: ['0.492', '0.169', '0.169', '0.169']\n",
      "     Batch 0, Pos 1: most likely x_{t-1} = 1 (prob=0.492)full distribution: ['0.169', '0.492', '0.169', '0.169']\n",
      "     Batch 0, Pos 2: most likely x_{t-1} = 2 (prob=0.492)full distribution: ['0.169', '0.169', '0.492', '0.169']\n",
      "     Batch 1, Pos 0: most likely x_{t-1} = 3 (prob=0.987)full distribution: ['0.007', '0.007', '0.000', '0.987']\n",
      "     Batch 1, Pos 1: most likely x_{t-1} = 0 (prob=0.492)full distribution: ['0.492', '0.169', '0.169', '0.169']\n",
      "     Batch 1, Pos 2: most likely x_{t-1} = 1 (prob=0.492)full distribution: ['0.169', '0.492', '0.169', '0.169']\n",
      "   Entropy (uncertainty): [[1.2512774467468262, 1.2512774467468262, 1.2512774467468262], [0.08140797913074493, 1.2512774467468262, 1.2512774467468262]]\n",
      "\n",
      "🔍 Timestep t = 3:\n",
      "   Input x_t: [[0, 1, 2], [2, 0, 1]],  Predicted x0 (argmax): [[0, 1, 2], [3, 0, 1]]\n",
      "   Posterior p(x_{t-1}|x_t) for each position:\n",
      "     Batch 0, Pos 0: most likely x_{t-1} = 0 (prob=0.960)full distribution: ['0.960', '0.013', '0.013', '0.013']\n",
      "     Batch 0, Pos 1: most likely x_{t-1} = 1 (prob=0.960)full distribution: ['0.013', '0.960', '0.013', '0.013']\n",
      "     Batch 0, Pos 2: most likely x_{t-1} = 2 (prob=0.960)full distribution: ['0.013', '0.013', '0.960', '0.013']\n",
      "     Batch 1, Pos 0: most likely x_{t-1} = 3 (prob=0.976)full distribution: ['0.009', '0.009', '0.006', '0.976']\n",
      "     Batch 1, Pos 1: most likely x_{t-1} = 0 (prob=0.960)full distribution: ['0.960', '0.013', '0.013', '0.013']\n",
      "     Batch 1, Pos 2: most likely x_{t-1} = 1 (prob=0.960)full distribution: ['0.013', '0.960', '0.013', '0.013']\n",
      "   Entropy (uncertainty): [[0.21273937821388245, 0.21273937821388245, 0.21273937821388245], [0.14017626643180847, 0.21273937821388245, 0.21273937821388245]]\n",
      "\n",
      "📊 Summary insights:\n",
      "   • At t=0: Returns exact softmax of model predictions\n",
      "   • At t>0: Incorporates diffusion process uncertainty\n",
      "   • Higher t → more uncertainty (higher entropy)\n",
      "   • Function respects probability constraints (sum=1, non-negative)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Visual demonstration of compute_predicted_posterior function behavior.\n",
    "\"\"\"\n",
    "print(\"🎨 Visual demonstration of compute_predicted_posterior...\")\n",
    "\n",
    "# Use a very small example for clarity\n",
    "demo_vocab_size = 4\n",
    "demo_num_timesteps = 5\n",
    "demo_scheduler = UniformScheduler(num_classes=demo_vocab_size, num_timesteps=demo_num_timesteps).to(device)\n",
    "batch_size, seq_len = 2, 3\n",
    "\n",
    "# Test different timesteps\n",
    "for t_val in [0, 1, 3]:\n",
    "    print(f\"\\n🔍 Timestep t = {t_val}:\")\n",
    "\n",
    "    t = torch.tensor([t_val, t_val], device=device)\n",
    "    x_t = torch.tensor([[0, 1, 2], [2, 0, 1]], device=device)\n",
    "\n",
    "    # Create logits that strongly prefer certain tokens\n",
    "    x0_logits = torch.zeros(batch_size, seq_len, demo_vocab_size, device=device)\n",
    "    x0_logits[0, 0, 0] = 5.0  # Strongly predict token 0 for position 0\n",
    "    x0_logits[0, 1, 1] = 5.0  # Strongly predict token 1 for position 1\n",
    "    x0_logits[0, 2, 2] = 5.0  # Strongly predict token 2 for position 2\n",
    "    x0_logits[1, 0, 3] = 5.0  # Strongly predict token 3 for position 0\n",
    "    x0_logits[1, 1, 0] = 5.0  # Strongly predict token 0 for position 1\n",
    "    x0_logits[1, 2, 1] = 5.0  # Strongly predict token 1 for position 2\n",
    "\n",
    "    result = compute_predicted_posterior(demo_scheduler, x0_logits, x_t, t)\n",
    "\n",
    "    print(\n",
    "        f\"   Input x_t: {x_t.tolist()},  Predicted x0 (argmax): {F.softmax(x0_logits, dim=-1).argmax(dim=-1).tolist()}\"\n",
    "    )\n",
    "    print(f\"   Posterior p(x_{{t-1}}|x_t) for each position:\")\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        for pos in range(seq_len):\n",
    "            posterior = result[b, pos]\n",
    "            max_prob_token = posterior.argmax().item()\n",
    "            max_prob = posterior.max().item()\n",
    "            print(\n",
    "                f\"     Batch {b}, Pos {pos}: most likely x_{{t-1}} = {max_prob_token} (prob={max_prob:.3f})\"\n",
    "                f\"full distribution: {[f'{p:.3f}' for p in posterior.tolist()]}\"\n",
    "            )\n",
    "\n",
    "    # Show entropy (measure of uncertainty)\n",
    "    entropy = -(result * torch.log(result + 1e-8)).sum(dim=-1)\n",
    "    print(f\"   Entropy (uncertainty): {entropy.tolist()}\")\n",
    "\n",
    "print(f\"\\n📊 Summary insights:\")\n",
    "print(f\"   • At t=0: Returns exact softmax of model predictions\")\n",
    "print(f\"   • At t>0: Incorporates diffusion process uncertainty\")\n",
    "print(f\"   • Higher t → more uncertainty (higher entropy)\")\n",
    "print(f\"   • Function respects probability constraints (sum=1, non-negative)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5fb805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Tokenizer trained and saved to ./simple_1000_dylan_tokenizer\n",
      "Max sequence length in dataset: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x_0.shape: torch.Size([32, 3])\n",
      "| x_0.shape: torch.Size([32, 3])\n",
      "ic| x_t.shape: torch.Size([32, 3])\n",
      "ic| x_t.shape: torch.Size([32, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before training step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x0_logits.shape: torch.Size([32, 3, 1000])\n",
      "| x0_logits.shape: torch.Size([32, 3, 1000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training step\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Training step on a single batch. \"\"\"\n",
    "\n",
    "\n",
    "def training_step(\n",
    "    scheduler: UniformScheduler, model: SimpleD3PMModel, x_0: torch.Tensor, t: torch.Tensor\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    x_t = scheduler.add_noise(x_0, t)\n",
    "    ic(x_t.shape)\n",
    "    x0_logits = model(x_t, t)\n",
    "    ic(x0_logits.shape)\n",
    "    true_posterior = scheduler.get_posterior_params(x_t, x_0, t)\n",
    "    # ic(true_posterior.shape)\n",
    "\n",
    "    pred_posterior = compute_predicted_posterior(scheduler=scheduler, x0_logits=x0_logits, x_t=x_t, t=t)\n",
    "    # ic(pred_posterior.shape)\n",
    "\n",
    "    kl_terms = scheduler.compute_kl_divergence(true_posterior, pred_posterior)\n",
    "    # ic(kl_terms.shape)\n",
    "    return x0_logits, kl_terms\n",
    "\n",
    "\n",
    "num_timesteps = 50\n",
    "max_seq_len = 22\n",
    "batch_size = 32\n",
    "vocab_size = 1000\n",
    "dylan_tokenizer = SimpleDylanTokenizer(vocab_size=1000)\n",
    "dylan_tokenizer.train_tokenizer(corpus=lines, save_path=f\"./simple_{vocab_size}_dylan_tokenizer\")\n",
    "tokenizer = dylan_tokenizer.get_transformers_tokenizer()\n",
    "sm_dataset = SimpleDylanDataset(lines[:100], tokenizer, seq_len=seq_len)\n",
    "sm_dataloader = DataLoader(sm_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "scheduler = UniformScheduler(num_classes=vocab_size, num_timesteps=num_timesteps, beta_start=0.0001, beta_end=0.02).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "model = SimpleD3PMModel(vocab_size=vocab_size, max_seq_len=max_seq_len, d_model=128, num_heads=2, num_layers=1).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "t = torch.randint(0, num_timesteps, (batch_size,), device=device)  # Changed from (batch_size, 1) to (batch_size,)\n",
    "x_0 = next(iter(sm_dataloader))  # Get a batch from the small dataset\n",
    "x_0 = x_0.to(device)\n",
    "ic(x_0.shape)  # Should be [batch_size, seq_len]\n",
    "# Forward pass\n",
    "print(\"before training step\")\n",
    "x0_logits, kl_terms = training_step(scheduler=scheduler, model=model, x_0=x_0, t=t)\n",
    "print(\"after training step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa7e5584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and scheduler created successfully!\n",
      "Model parameters: 3,809,256\n",
      "Vocab size: 1000\n",
      "Num timesteps: 50\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming SimpleD3PMModel and UniformScheduler are defined elsewhere\n",
    "# from your_model_definition import SimpleD3PMModel, UniformScheduler\n",
    "\n",
    "# Simple model and scheduler setup for training\n",
    "seq_len = 20\n",
    "vocab_size = len(tokenizer)\n",
    "num_timesteps = 50\n",
    "\n",
    "# Create model and scheduler\n",
    "model = SimpleD3PMModel(vocab_size=vocab_size, max_seq_len=seq_len).to(device)\n",
    "scheduler = UniformScheduler(num_classes=vocab_size, num_timesteps=num_timesteps, beta_start=0.0001, beta_end=0.02).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "\n",
    "# Simple loss function\n",
    "def d3pm_loss(\n",
    "    x0_logits: torch.Tensor, kl_terms: torch.Tensor, x_0: torch.Tensor, lambda_weight: float = 0.001\n",
    ") -> tuple[torch.Tensor, dict]:\n",
    "    # VB loss: average KL terms\n",
    "    vb_loss = kl_terms.mean()\n",
    "\n",
    "    # Auxiliary loss: cross entropy between predicted x0 and true x0\n",
    "    flat_logits = x0_logits.view(-1, vocab_size)\n",
    "    flat_targets = x_0.view(-1)\n",
    "    aux_loss = F.cross_entropy(flat_logits, flat_targets)\n",
    "\n",
    "    # Total loss\n",
    "    total_loss = vb_loss + lambda_weight * aux_loss\n",
    "\n",
    "    return total_loss, {\"total\": total_loss, \"vb\": vb_loss, \"aux\": aux_loss}\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "print(\"Model and scheduler created successfully!\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Vocab size: {vocab_size}\")\n",
    "print(f\"Num timesteps: {num_timesteps}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4c66f1",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "211eecdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Tokenizer trained and saved to ./simple_1000_dylan_tokenizer\n",
      "Max sequence length in dataset: 26\n",
      "Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e8dd0961734d1d94e92754c7aa0692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 1/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 0: Loss = 7.0998\n",
      "  Batch 1: Loss = 7.2222\n",
      "  Batch 2: Loss = 7.0029\n",
      "  Batch 3: Loss = 7.0429\n",
      "Epoch 0 completed. Average Loss: 7.0920\n",
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965ef60ad51a4dd195ddbec87a587698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 2/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 0: Loss = 7.0096\n",
      "  Batch 1: Loss = 7.0208\n",
      "  Batch 2: Loss = 6.9288\n",
      "  Batch 3: Loss = 6.8718\n",
      "Epoch 1 completed. Average Loss: 6.9577\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6490fb8a02c04701aebab627b0d66e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 3/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 0: Loss = 6.8476\n",
      "  Batch 1: Loss = 6.8689\n",
      "  Batch 2: Loss = 6.7555\n",
      "  Batch 3: Loss = 6.8193\n",
      "Epoch 2 completed. Average Loss: 6.8228\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73cc13c3114d48d291164338cc9f032e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 4/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 0: Loss = 6.7583\n",
      "  Batch 1: Loss = 6.7116\n",
      "  Batch 2: Loss = 6.6082\n",
      "  Batch 3: Loss = 6.7722\n",
      "Epoch 3 completed. Average Loss: 6.7126\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9d0a3ab4ab46f4846f0756dc928bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 5/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 0: Loss = 6.6490\n",
      "  Batch 1: Loss = 6.5517\n",
      "  Batch 2: Loss = 6.6078\n",
      "  Batch 3: Loss = 6.4862\n",
      "Epoch 4 completed. Average Loss: 6.5737\n",
      "Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299dbc2032364072a388113f8d150414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 6/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 0: Loss = 6.6309\n",
      "  Batch 1: Loss = 6.3946\n",
      "  Batch 2: Loss = 6.3643\n",
      "  Batch 3: Loss = 6.4136\n",
      "Epoch 5 completed. Average Loss: 6.4509\n",
      "Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12c86d34904428bb625a029d322b8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 7/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 0: Loss = 6.3583\n",
      "  Batch 1: Loss = 6.2544\n",
      "  Batch 2: Loss = 6.5605\n",
      "  Batch 3: Loss = 6.0924\n",
      "Epoch 6 completed. Average Loss: 6.3164\n",
      "Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf4b4a065d44c32ac5b51c44988b075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 8/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 0: Loss = 6.0321\n",
      "  Batch 1: Loss = 6.1358\n",
      "  Batch 2: Loss = 6.3136\n",
      "  Batch 3: Loss = 6.0323\n",
      "Epoch 7 completed. Average Loss: 6.1284\n",
      "Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714d5a279d5248f3ba658d65dedcd215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 9/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 0: Loss = 6.0587\n",
      "  Batch 1: Loss = 6.1084\n",
      "  Batch 2: Loss = 6.0547\n",
      "  Batch 3: Loss = 5.9406\n",
      "Epoch 8 completed. Average Loss: 6.0406\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc0ee2b26d04cf6aeea07ac1aa49260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 10/10:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 0: Loss = 6.1449\n",
      "  Batch 1: Loss = 5.6857\n",
      "  Batch 2: Loss = 5.9953\n",
      "  Batch 3: Loss = 5.7868\n",
      "Epoch 9 completed. Average Loss: 5.9032\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Training loop working correctly! IndexError has been fixed.\n"
     ]
    }
   ],
   "source": [
    "from my_transformer import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "\n",
    "vocab_size = 1000\n",
    "num_timesteps = 100\n",
    "max_seq_len = 20\n",
    "batch_size = 16\n",
    "\n",
    "sm_lines = lines[:64]  # Use a smaller subset for testing\n",
    "dylan_tokenizer = SimpleDylanTokenizer(vocab_size=vocab_size)\n",
    "dylan_tokenizer.train_tokenizer(corpus=sm_lines, save_path=f\"./simple_{vocab_size}_dylan_tokenizer\")\n",
    "tokenizer = dylan_tokenizer.get_transformers_tokenizer()\n",
    "sm_dataset = SimpleDylanDataset(sm_lines, tokenizer, seq_len=seq_len)\n",
    "sm_dataloader = DataLoader(sm_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloader = sm_dataloader\n",
    "\n",
    "model = SimpleD3PMModel(vocab_size=vocab_size, max_seq_len=max_seq_len, d_model=128, num_heads=2, num_layers=1).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "scheduler = UniformScheduler(num_classes=vocab_size, num_timesteps=num_timesteps, beta_start=0.0001, beta_end=0.02).to(\n",
    "    device\n",
    ")\n",
    "do_train = True\n",
    "if do_train:\n",
    "    # optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "    learning_rate = 1e-4\n",
    "    weight_decay = 1e-5  # Added weight decay\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    # Adaptive learning rate scheduler\n",
    "    lr_scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=3, T_mult=2, eta_min=1e-6)\n",
    "    train_losses = []\n",
    "    learning_rates = []\n",
    "    model.train()\n",
    "\n",
    "    # Training loop - IndexError fixed!\n",
    "    num_epochs = 10\n",
    "\n",
    "    model_name = \"d3pm\"\n",
    "    model_version = \"1.0\"\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_dir = f\"../runs/{model_name}_{model_version}_training_{timestamp}\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    global_step = 0\n",
    "    num_batches = len(dataloader)\n",
    "    ic(num_batches)\n",
    "\n",
    "    ic.disable()\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        pbar = tqdm(dataloader, desc=f\"epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        for b, x_0 in enumerate(pbar):\n",
    "            if b >= num_batches:\n",
    "                break\n",
    "\n",
    "            x_0 = x_0.to(device)\n",
    "            batch_size = x_0.shape[0]\n",
    "\n",
    "            # Sample random timesteps\n",
    "            t = torch.randint(0, num_timesteps, (batch_size,), device=device)\n",
    "\n",
    "            # Training step\n",
    "            x0_logits, kl_terms = training_step(scheduler=scheduler, model=model, x_0=x_0, t=t)\n",
    "            loss, loss_dict = d3pm_loss(x0_logits, kl_terms, x_0)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            global_step += 1\n",
    "            current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "            avg_epoch_loss = epoch_loss / num_batches\n",
    "\n",
    "            print(f\"  Batch {b}: Loss = {loss.item():.4f}\")\n",
    "            if global_step % 2 == 0:\n",
    "                writer.add_scalar(\"Loss/Batch\", loss.item(), global_step)\n",
    "                writer.add_scalar(\"Learning_Rate\", current_lr, global_step)\n",
    "                writer.add_scalar(\n",
    "                    \"Gradient_Norm\",\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=float(\"inf\")),\n",
    "                    global_step,\n",
    "                )\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\", \"LR\": f\"{current_lr:.2e}\", \"Step\": global_step})\n",
    "\n",
    "            # Memory cleanup\n",
    "            if b % 5 == 0:\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                elif torch.backends.mps.is_available():\n",
    "                    torch.mps.empty_cache()\n",
    "\n",
    "        train_losses.append(avg_epoch_loss)\n",
    "        learning_rates.append(current_lr)\n",
    "\n",
    "        utils.save_model(model, model_name=model_name, model_version=model_version, iter=epoch)\n",
    "        print(f\"Epoch {epoch} completed. Average Loss: {epoch_loss / num_batches:.4f}\")\n",
    "\n",
    "    # Plot training curves\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # Loss curve\n",
    "    ax1.plot(train_losses)\n",
    "    ax1.set_title(\"Training Loss\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Learning rate curve\n",
    "    ax2.plot(learning_rates)\n",
    "    ax2.set_title(\"Learning Rate Schedule\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Learning Rate\")\n",
    "    ax2.set_yscale(\"log\")\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(\"../plots\", exist_ok=True)\n",
    "    plt.savefig(f\"../plots/training_curves_{timestamp}.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    writer.close()\n",
    "    print(\"\\n✅ Training loop working correctly! IndexError has been fixed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9cb73b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e67b34",
   "metadata": {},
   "source": [
    "## Sampling output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fbff1b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = utils.load_model(model_name=model_name, model_version=model_version, iter=num_epochs - 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4b6db84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| prompt_txt: 'How does it feel'\n",
      "ic| output_txt: 'How d o es it f e e l [PAD] es [PAD] [PAD] ork j'\n",
      "ic| output_txt: 'How d o es it f e e l [PAD] [PAD] [PAD] [PAD] no L an'\n",
      "ic| output_txt: 'How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] ork an'\n",
      "ic| output_txt: 'How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] ime an'\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] an')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] an')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] an')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] an')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] v')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n",
      "ic| output_txt: ('How d o es it f e e l [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                 '[PAD] [PAD]')\n"
     ]
    }
   ],
   "source": [
    "ic.enable()\n",
    "prompt_txt = \"How does it feel\"\n",
    "prompt = torch.Tensor(tokenizer.encode(prompt_txt, add_special_tokens=True)).unsqueeze(0).to(device)\n",
    "ic(prompt_txt)\n",
    "temperature = 0.1\n",
    "\n",
    "num_steps = 1\n",
    "\n",
    "# Handle prompt\n",
    "prompt_len = prompt.shape[1]\n",
    "\n",
    "if prompt_len >= seq_len:\n",
    "    # If prompt is longer than desired sequence, just return prompt\n",
    "    raise ValueError(\"Prompt length exceeds sequence length.\")\n",
    "\n",
    "# Start from uniform random tokens\n",
    "x = torch.randint(0, model.vocab_size, (1, seq_len), device=device)\n",
    "x[:, :prompt_len] = prompt\n",
    "\n",
    "# Create mask for which positions to generate (non-prompt positions)\n",
    "generation_mask = torch.ones(seq_len, dtype=torch.bool, device=device)\n",
    "generation_mask[:prompt_len] = False\n",
    "\n",
    "# Reverse diffusion process\n",
    "timesteps = torch.linspace(scheduler.num_timesteps - 1, 0, scheduler.num_timesteps, dtype=torch.long, device=device)\n",
    "\n",
    "model.eval()\n",
    "for i, t_val in enumerate(timesteps):\n",
    "    t = torch.full((batch_size,), t_val, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Predict x₀\n",
    "        x0_logits = model(x, t)\n",
    "\n",
    "        if i == len(timesteps) - 1:\n",
    "            # Final step: use x₀ prediction directly\n",
    "            new_x = torch.argmax(x0_logits, dim=-1)\n",
    "        else:\n",
    "            # Sample from x₀ prediction with temperature and top-k\n",
    "            x0_probs = F.softmax(x0_logits / temperature, dim=-1)\n",
    "\n",
    "            # Sample\n",
    "            flat_probs = x0_probs.view(-1, model.vocab_size)\n",
    "            flat_samples = torch.multinomial(flat_probs, 1).squeeze(-1)\n",
    "            new_x = flat_samples.view(batch_size, seq_len)\n",
    "\n",
    "        # Only update non-prompt positions\n",
    "        x = torch.where(generation_mask.unsqueeze(0), new_x, x)\n",
    "\n",
    "        # ic(x.shape)\n",
    "        output_txt = tokenizer.decode(x[0].cpu().numpy(), skip_special_tokens=False)\n",
    "        ic(output_txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-implementations (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
