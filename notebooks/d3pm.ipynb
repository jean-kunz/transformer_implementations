{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e60c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n",
      "env: PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0\n"
     ]
    }
   ],
   "source": [
    "# | default_exp attention\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "%env PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4404c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "from icecream import ic\n",
    "import math\n",
    "from my_transformer.utils import save_model, load_model\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, normalizers\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "868188ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7edbbc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Hard Times In New York Town',\n",
       "  'Come you ladies and you gentlemen, a-listen to my song',\n",
       "  'Sing it to you right, but you might think it’s wrong',\n",
       "  'Just a little glimpse of a story I’ll tell',\n",
       "  '’Bout an East Coast city that you all know well',\n",
       "  'It’s hard times in the city',\n",
       "  'Livin’ down in New York town',\n",
       "  'Old New York City is a friendly old town',\n",
       "  'From Washington Heights to Harlem on down',\n",
       "  'There’s a-mighty many people all millin’ all around'],\n",
       " 14318)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset/bob_dylan_lyrics.csv\")\n",
    "lines = []\n",
    "nb_rows = 999999\n",
    "row_id = 0\n",
    "for r in df.iterrows():\n",
    "    # todo: one line is one sentence.\n",
    "    lines.append(r[1][\"title\"])\n",
    "    # sentences.append(r[1][\"title\"] + \"\\n\" + r[1][\"lyrics\"])\n",
    "    lyrics = r[1][\"lyrics\"].split(\"\\n\")\n",
    "    for line in lyrics:\n",
    "        if len(line.strip()) > 0:\n",
    "            lines.append(line.strip())\n",
    "        row_id += 1\n",
    "\n",
    "lines[:10], len(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6bab58",
   "metadata": {},
   "source": [
    "# Simple Custom Tokenizer for Bob Dylan Lyrics\n",
    "\n",
    "Create a simple BPE (Byte-Pair Encoding) tokenizer trained specifically on Dylan's lyrics.\n",
    "This will:\n",
    "1. Learn Dylan's vocabulary efficiently\n",
    "2. Handle his common words and phrases better than BERT\n",
    "3. Use a smaller vocabulary size for memory efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92266e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDylanTokenizer:\n",
    "    def __init__(self, vocab_size=3000):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tokenizer = None\n",
    "\n",
    "    def train_tokenizer(self, corpus: list[str], save_path: str = \"./simple_dylan_tokenizer\"):\n",
    "        # Initialize simple BPE tokenizer\n",
    "        tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "\n",
    "        # Simple whitespace pre-tokenization\n",
    "        tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "        # Simple trainer\n",
    "        trainer = BpeTrainer(\n",
    "            vocab_size=self.vocab_size, special_tokens=[\"[PAD]\", \"[UNK]\", \"[MASK]\"], min_frequency=2, show_progress=True\n",
    "        )\n",
    "\n",
    "        # Train the tokenizer\n",
    "        tokenizer.train_from_iterator(corpus, trainer)\n",
    "\n",
    "        # Save tokenizer\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        tokenizer.save(f\"{save_path}/tokenizer.json\")\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        print(f\"Tokenizer trained and saved to {save_path}\")\n",
    "\n",
    "        return tokenizer\n",
    "\n",
    "    def load_tokenizer(self, save_path=\"./simple_dylan_tokenizer\"):\n",
    "        \"\"\"Load the trained tokenizer\"\"\"\n",
    "        tokenizer_path = f\"{save_path}/tokenizer.json\"\n",
    "        if os.path.exists(tokenizer_path):\n",
    "            self.tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "            return self.tokenizer\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Tokenizer not found at {tokenizer_path}\")\n",
    "\n",
    "    def get_transformers_tokenizer(self):\n",
    "        \"\"\"Convert to HuggingFace tokenizer for compatibility\"\"\"\n",
    "        if self.tokenizer is None:\n",
    "            raise ValueError(\"Tokenizer not trained or loaded\")\n",
    "\n",
    "        # Create fast tokenizer wrapper\n",
    "        fast_tokenizer = PreTrainedTokenizerFast(\n",
    "            tokenizer_object=self.tokenizer, pad_token=\"[PAD]\", unk_token=\"[UNK]\", mask_token=\"[MASK]\"\n",
    "        )\n",
    "\n",
    "        return fast_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76920799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(tokenizer): 5000\n",
      "ic| tokenizer.special_tokens_map: {'mask_token': '[MASK]', 'pad_token': '[PAD]', 'unk_token': | len(tokenizer): 5000\n",
      "ic| tokenizer.special_tokens_map: {'mask_token': '[MASK]', 'pad_token': '[PAD]', 'unk_token': '[UNK]'}\n",
      "'[UNK]'}\n",
      "ic| phrase: \"The answer my friend is blowin' in the wind\"\n",
      "ic| decoded: \"The answer my friend is blowin ' in the wind\"ic| phrase: \"The answer my friend is blowin' in the wind\"\n",
      "ic| decoded: \"The answer my friend is blowin ' in the wind\"\n",
      "ic| token_strs: ['The', 'answer', 'my', 'friend', 'is', 'blowin', \"'\",\n",
      "ic| token_strs: ['The', 'answer', 'my', 'friend', 'is', 'blowin', \"'\","
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Tokenizer trained and saved to ./simple_dylan_tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 'in', 'the', 'wind''in', 'the', 'wind']\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Initialize simple Dylan tokenizer\n",
    "dylan_tokenizer = SimpleDylanTokenizer(vocab_size=5000)\n",
    "\n",
    "# Train the tokenizer on Dylan lyrics\n",
    "dylan_tokenizer.train_tokenizer(corpus=lines, save_path=\"./simple_dylan_tokenizer\")\n",
    "\n",
    "# Convert to HuggingFace format for compatibility\n",
    "tokenizer = dylan_tokenizer.get_transformers_tokenizer()\n",
    "\n",
    "ic(len(tokenizer))\n",
    "ic(tokenizer.special_tokens_map)\n",
    "\n",
    "\n",
    "phrase = \"The answer my friend is blowin' in the wind\"\n",
    "\n",
    "tokens = tokenizer.encode(phrase, add_special_tokens=False)\n",
    "decoded = tokenizer.decode(tokens, skip_special_tokens=False)\n",
    "token_strs = tokenizer.convert_ids_to_tokens(tokens)\n",
    "ic(phrase)\n",
    "ic(decoded)\n",
    "ic(token_strs);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a50552a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up dataset with simple Dylan tokenizer...\n",
      "Max sequence length in dataset: 40\n",
      "Dataset created with 14318 examples\n",
      "Sequence length: 32\n",
      "Batch size: 8\n",
      "Tokenizer vocabulary size: 5000\n",
      "\n",
      "Sample batch shape: torch.Size([8, 32])\n",
      "Sample sequence: Well , I ’ ve been to Lon don and I ’ ve been to g ay P are e [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Max sequence length in dataset: 40\n",
      "Dataset created with 14318 examples\n",
      "Sequence length: 32\n",
      "Batch size: 8\n",
      "Tokenizer vocabulary size: 5000\n",
      "\n",
      "Sample batch shape: torch.Size([8, 32])\n",
      "Sample sequence: Well , I ’ ve been to Lon don and I ’ ve been to g ay P are e [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "# Update dataset to use simple Dylan tokenizer\n",
    "print(\"Setting up dataset with simple Dylan tokenizer...\")\n",
    "\n",
    "\n",
    "# Create simple dataset\n",
    "seq_len = 32  # Keep shorter sequences for memory efficiency\n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "class SimpleDylanDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, seq_len=128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "        self.examples = []\n",
    "        max_seq_len = 0\n",
    "\n",
    "        for line in texts:\n",
    "            # Simple tokenization - no structure tokens\n",
    "            tokens = tokenizer.encode(line.strip(), add_special_tokens=False)\n",
    "            token_nb = len(tokens)\n",
    "            max_seq_len = max(max_seq_len, token_nb)\n",
    "            # Truncate if too long\n",
    "\n",
    "            if token_nb > seq_len:\n",
    "                tokens = tokens[:seq_len]\n",
    "\n",
    "            if token_nb > 0:  # Skip empty sequences\n",
    "                self.examples.append(tokens)\n",
    "        print(f\"Max sequence length in dataset: {max_seq_len}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.examples[idx]\n",
    "        pad_id = self.tokenizer.pad_token_id if hasattr(self.tokenizer, \"pad_token_id\") else 0\n",
    "\n",
    "        # Pad to sequence length\n",
    "        padded = tokens + [pad_id] * (self.seq_len - len(tokens))\n",
    "        return torch.tensor(padded[: self.seq_len], dtype=torch.long)\n",
    "\n",
    "\n",
    "# Create dataset with selected tokenizer\n",
    "dataset = SimpleDylanDataset(lines, tokenizer, seq_len=seq_len)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"Dataset created with {len(dataset)} examples\")\n",
    "print(f\"Sequence length: {seq_len}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Tokenizer vocabulary size: {len(tokenizer)}\")\n",
    "\n",
    "# Test the dataset\n",
    "sample_batch = next(iter(dataloader))\n",
    "print(f\"\\nSample batch shape: {sample_batch.shape}\")\n",
    "print(f\"Sample sequence: {tokenizer.decode(sample_batch[0].tolist(), skip_special_tokens=False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9cab4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tears of R age [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Tears of R age [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Tears of R bull [PAD] [PAD] few [PAD] Fris [PAD] [PAD] [PAD] dale [PAD] flies [PAD] think cook Where lone [PAD] [PAD] sw mu [PAD] [PAD] Mu [PAD] [PAD] taken [PAD] [PAD]\n",
      "Was of tin age fil rum [PAD] [PAD] Ind sess bash [PAD] lady bloody Chang [PAD] job Hen cy green [PAD] strapped answer accept [PAD] ica path Unto shock [PAD] Half sc\n"
     ]
    }
   ],
   "source": [
    "class D3pmDiffusion(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_discrete_states: int, num_timesteps: int = 1000, beta_start: float = 0.0001, beta_end: float = 0.02\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_discrete_states = num_discrete_states\n",
    "        self.num_timesteps = num_timesteps\n",
    "\n",
    "        # More conservative beta schedule\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alpha_bars = torch.cumprod(self.alphas, dim=0)\n",
    "\n",
    "        # Precompute transition matrices\n",
    "        self.transition_matrices_t = nn.ParameterList()\n",
    "        self.cumulative_transition_matrices_t = nn.ParameterList()\n",
    "\n",
    "        Q_prev_cumulative = torch.eye(num_discrete_states)\n",
    "\n",
    "        for t in range(num_timesteps):\n",
    "            beta = self.betas[t].item()\n",
    "\n",
    "            # More conservative transition matrix\n",
    "            diag_prob = 1.0 - beta\n",
    "            off_diag_prob = beta / (num_discrete_states - 1) if num_discrete_states > 1 else 0.0\n",
    "\n",
    "            Q_t = torch.eye(num_discrete_states) * diag_prob\n",
    "            Q_t = (\n",
    "                Q_t\n",
    "                + (torch.ones(num_discrete_states, num_discrete_states) - torch.eye(num_discrete_states))\n",
    "                * off_diag_prob\n",
    "            )\n",
    "            Q_t = Q_t / Q_t.sum(dim=1, keepdim=True)\n",
    "\n",
    "            self.transition_matrices_t.append(nn.Parameter(Q_t, requires_grad=False))\n",
    "\n",
    "            Q_current_cumulative = torch.matmul(Q_t, Q_prev_cumulative)\n",
    "            self.cumulative_transition_matrices_t.append(nn.Parameter(Q_current_cumulative, requires_grad=False))\n",
    "            Q_prev_cumulative = Q_current_cumulative\n",
    "\n",
    "    def forward(self, x_0: torch.Tensor, t: torch.Tensor):\n",
    "        \"\"\"Forward diffusion process\"\"\"\n",
    "        original_shape = x_0.shape\n",
    "        batch_size = original_shape[0]\n",
    "        x_flat = x_0.view(batch_size, -1)\n",
    "        num_elements = x_flat.shape[1]\n",
    "\n",
    "        # Convert to one-hot encoding\n",
    "        x_one_hot = F.one_hot(x_flat, num_classes=self.num_discrete_states).float()\n",
    "\n",
    "        # Gather transition matrices for batch\n",
    "        Q_bar_t_batch = torch.stack([self.cumulative_transition_matrices_t[idx] for idx in t])\n",
    "\n",
    "        # Apply transition\n",
    "        next_state_probs = torch.bmm(x_one_hot, Q_bar_t_batch)\n",
    "\n",
    "        # Sample from categorical distribution\n",
    "        x_t = torch.multinomial(next_state_probs.view(-1, self.num_discrete_states), num_samples=1).squeeze(dim=1)\n",
    "        x_t = x_t.view(original_shape)\n",
    "\n",
    "        return x_t\n",
    "\n",
    "    def compute_loss(self, x_0: torch.Tensor, predicted_logits: torch.Tensor, t: torch.Tensor, pad_token_id: int = 0):\n",
    "        \"\"\"Compute proper D3PM loss with padding mask\"\"\"\n",
    "        batch_size, seq_len = x_0.shape\n",
    "\n",
    "        # Create padding mask\n",
    "        pad_mask = (x_0 != pad_token_id).float()  # 1 for real tokens, 0 for padding\n",
    "\n",
    "        # Compute cross-entropy loss\n",
    "        loss = F.cross_entropy(predicted_logits.view(-1, self.num_discrete_states), x_0.view(-1), reduction=\"none\")\n",
    "\n",
    "        # Apply padding mask\n",
    "        loss = loss.view(batch_size, seq_len)\n",
    "        masked_loss = loss * pad_mask\n",
    "\n",
    "        # Average over non-padded tokens\n",
    "        total_loss = masked_loss.sum() / pad_mask.sum().clamp(min=1)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "\n",
    "# Define parameters\n",
    "NUM_STATES = len(tokenizer)  # e.g., pixel values 0, 1, 2, 3\n",
    "BETA_PER_STEP = 0.2  # Probability of changing state at each step\n",
    "NUM_TIMESTEPS = 100  # Number of diffusion steps\n",
    "# Create the forward diffusion module\n",
    "forward_diffuser = D3pmDiffusion(num_discrete_states=NUM_STATES, num_timesteps=NUM_TIMESTEPS).to(device)\n",
    "inp = next(iter(dataloader)).to(device)\n",
    "\n",
    "\n",
    "def demo_noise(inp, line_nb, step):\n",
    "    src_line = tokenizer.decode(inp[line_nb].cpu().numpy())\n",
    "    noisy_inp = forward_diffuser.forward(inp[line_nb : line_nb + 1], torch.tensor([step]).to(device))\n",
    "    noisy_line = tokenizer.decode(noisy_inp[0].cpu().numpy())\n",
    "    return src_line, noisy_line\n",
    "\n",
    "\n",
    "ic.disable()\n",
    "ic.enable()\n",
    "sent_nb = 4\n",
    "print(demo_noise(inp, sent_nb, 0)[1])\n",
    "print(demo_noise(inp, sent_nb, 12)[1])\n",
    "print(demo_noise(inp, sent_nb, 60)[1])\n",
    "print(demo_noise(inp, sent_nb, 99)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13a12987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, t):\n",
    "        half = self.lin.in_features // 2\n",
    "        freqs = torch.exp(-math.log(10000) * torch.arange(half, dtype=torch.float32) / half).to(t.device)\n",
    "        args = t[:, None].float() * freqs[None]\n",
    "        emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "        return self.lin(emb)\n",
    "\n",
    "\n",
    "class DiffusionTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, seq_len, dim=512, heads=8, layers=6):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, dim)\n",
    "        self.pos_emb = nn.Embedding(seq_len, dim)\n",
    "        self.time_emb = TimeEmbedding(dim)\n",
    "        enc_layer = nn.TransformerEncoderLayer(dim, heads, dim * 4)\n",
    "        self.transformer = nn.TransformerEncoder(enc_layer, layers)\n",
    "        self.to_logits = nn.Linear(dim, vocab_size)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        B, L = x.shape\n",
    "        tok = self.token_emb(x)\n",
    "        pos = self.pos_emb(torch.arange(L, device=x.device))\n",
    "        temb = self.time_emb(t).unsqueeze(1)\n",
    "        h = tok + pos + temb\n",
    "        h = self.transformer(h.transpose(0, 1)).transpose(0, 1)\n",
    "        return self.to_logits(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "319bd9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating limited dataset with 100 records for faster setup...\n",
      "Max sequence length in dataset: 20\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating limited dataset with 100 records for faster setup...\")\n",
    "\n",
    "# Take only first 100 lines for quick testing\n",
    "limited_lines = lines[:100]\n",
    "\n",
    "# Create limited dataset\n",
    "limited_dataset = SimpleDylanDataset(limited_lines, tokenizer, seq_len=seq_len)\n",
    "limited_dataloader = DataLoader(limited_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "545b5027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length in dataset: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jkunz/Projects/transformer_implementations/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard logs will be saved to: ../runs/d3pm_training_20250606_144338\n",
      "To view logs, run: tensorboard --logdir ../runs/d3pm_training_20250606_144338\n",
      "\n",
      "Starting enhanced training loop...\n",
      "Model parameters: 24,312,200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582540092b994a03bab6035559aa7a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 4.2366\n",
      "Epoch 1/30 completed:\n",
      "  Average Loss: 4.2366\n",
      "  Learning Rate: 1.00e-04\n",
      "  Global Step: 448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39674bdb07334629b28430b0d3447ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 2.8227\n",
      "Epoch 2/30 completed:\n",
      "  Average Loss: 2.8227\n",
      "  Learning Rate: 7.52e-05\n",
      "  Global Step: 896\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e92afb1845e4999bd302ddeb31cf286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 2.4845\n",
      "Epoch 3/30 completed:\n",
      "  Average Loss: 2.4845\n",
      "  Learning Rate: 2.58e-05\n",
      "  Global Step: 1344\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ab62e557be454b850241b3d0f41b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 2.3223\n",
      "Epoch 4/30 completed:\n",
      "  Average Loss: 2.3223\n",
      "  Learning Rate: 1.00e-04\n",
      "  Global Step: 1792\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3fb55259be4cad89468e865c4f9af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 2.1183\n",
      "Checkpoint saved: ../models/d3pm_epoch_5_2_0.pth\n",
      "Epoch 5/30 completed:\n",
      "  Average Loss: 2.1183\n",
      "  Learning Rate: 9.34e-05\n",
      "  Global Step: 2240\n",
      "Checkpoint saved: ../models/d3pm_epoch_5_2_0.pth\n",
      "Epoch 5/30 completed:\n",
      "  Average Loss: 2.1183\n",
      "  Learning Rate: 9.34e-05\n",
      "  Global Step: 2240\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af90e0b15eb4e77b91173aa2b555ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 1.9824\n",
      "Epoch 6/30 completed:\n",
      "  Average Loss: 1.9824\n",
      "  Learning Rate: 7.52e-05\n",
      "  Global Step: 2688\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524500a3882342da89be6a2cc8781d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 1.9195\n",
      "Epoch 7/30 completed:\n",
      "  Average Loss: 1.9195\n",
      "  Learning Rate: 5.05e-05\n",
      "  Global Step: 3136\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbbfda454394a4bb8216ab80c13db40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 1.8552\n",
      "Epoch 8/30 completed:\n",
      "  Average Loss: 1.8552\n",
      "  Learning Rate: 2.58e-05\n",
      "  Global Step: 3584\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4e17997c994ee7bf306c497c01c3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 1.8294\n",
      "Epoch 9/30 completed:\n",
      "  Average Loss: 1.8294\n",
      "  Learning Rate: 7.63e-06\n",
      "  Global Step: 4032\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f65c8e918fa4dcba6fe031d148b4d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: ../models/d3pm_epoch_10_2_0.pth\n",
      "Epoch 10/30 completed:\n",
      "  Average Loss: 1.8740\n",
      "  Learning Rate: 1.00e-04\n",
      "  Global Step: 4480\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3ccacdedd14932ac49ede49da2d2c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 1.8144\n",
      "Epoch 11/30 completed:\n",
      "  Average Loss: 1.8144\n",
      "  Learning Rate: 9.83e-05\n",
      "  Global Step: 4928\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90006b7030248d58c3efe41a851e155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 1.7604\n",
      "Epoch 12/30 completed:\n",
      "  Average Loss: 1.7604\n",
      "  Learning Rate: 9.34e-05\n",
      "  Global Step: 5376\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d75522dd32c469d855c8174e152aa9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 1.6961\n",
      "Epoch 13/30 completed:\n",
      "  Average Loss: 1.6961\n",
      "  Learning Rate: 8.55e-05\n",
      "  Global Step: 5824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e99b91b577c49fd9f0402f24208e507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 1.6602\n",
      "Epoch 14/30 completed:\n",
      "  Average Loss: 1.6602\n",
      "  Learning Rate: 7.52e-05\n",
      "  Global Step: 6272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ba50963ca14e518256f46501378d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 1.6298\n",
      "Checkpoint saved: ../models/d3pm_epoch_15_2_0.pth\n",
      "Epoch 15/30 completed:\n",
      "  Average Loss: 1.6298\n",
      "  Learning Rate: 6.33e-05\n",
      "  Global Step: 6720\n",
      "Checkpoint saved: ../models/d3pm_epoch_15_2_0.pth\n",
      "Epoch 15/30 completed:\n",
      "  Average Loss: 1.6298\n",
      "  Learning Rate: 6.33e-05\n",
      "  Global Step: 6720\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ac2a8ff3f0435d93c202dd8c1884f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 1.6047\n",
      "Epoch 16/30 completed:\n",
      "  Average Loss: 1.6047\n",
      "  Learning Rate: 5.05e-05\n",
      "  Global Step: 7168\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affce6dcfd2e49ddb23819bddfd8c304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 1.5935\n",
      "Epoch 17/30 completed:\n",
      "  Average Loss: 1.5935\n",
      "  Learning Rate: 3.77e-05\n",
      "  Global Step: 7616\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4185ec7e8ae44db6b2b780a565de2aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 1.5546\n",
      "Epoch 18/30 completed:\n",
      "  Average Loss: 1.5546\n",
      "  Learning Rate: 2.58e-05\n",
      "  Global Step: 8064\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea58c45bf1f4d09a8d6173cdb994f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 1.5416\n",
      "Epoch 19/30 completed:\n",
      "  Average Loss: 1.5416\n",
      "  Learning Rate: 1.55e-05\n",
      "  Global Step: 8512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39516f0c4da9475d843a8b4e6b0adf7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 1.5384\n",
      "Checkpoint saved: ../models/d3pm_epoch_20_2_0.pth\n",
      "Epoch 20/30 completed:\n",
      "  Average Loss: 1.5384\n",
      "  Learning Rate: 7.63e-06\n",
      "  Global Step: 8960\n",
      "Checkpoint saved: ../models/d3pm_epoch_20_2_0.pth\n",
      "Epoch 20/30 completed:\n",
      "  Average Loss: 1.5384\n",
      "  Learning Rate: 7.63e-06\n",
      "  Global Step: 8960\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07821a973be84acf9f678a9c77d98565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 1.5207\n",
      "Epoch 21/30 completed:\n",
      "  Average Loss: 1.5207\n",
      "  Learning Rate: 2.69e-06\n",
      "  Global Step: 9408\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c8c94fa189416fbe50b47bd3919910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 completed:\n",
      "  Average Loss: 1.5937\n",
      "  Learning Rate: 1.00e-04\n",
      "  Global Step: 9856\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b93611328f14d77a6c00d7fba8ec0a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 completed:\n",
      "  Average Loss: 1.5890\n",
      "  Learning Rate: 9.96e-05\n",
      "  Global Step: 10304\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b9eb6669b04afebcad40514acfad18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 completed:\n",
      "  Average Loss: 1.5591\n",
      "  Learning Rate: 9.83e-05\n",
      "  Global Step: 10752\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd10ff4043f47b8930f58d3ee4e1146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: ../models/d3pm_epoch_25_2_0.pth\n",
      "Epoch 25/30 completed:\n",
      "  Average Loss: 1.5331\n",
      "  Learning Rate: 9.62e-05\n",
      "  Global Step: 11200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c439b9f8e7554a99b4042328b33d6071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 1.4861\n",
      "Epoch 26/30 completed:\n",
      "  Average Loss: 1.4861\n",
      "  Learning Rate: 9.34e-05\n",
      "  Global Step: 11648\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113152ab61a542b7b5970034647838e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 1.4656\n",
      "Epoch 27/30 completed:\n",
      "  Average Loss: 1.4656\n",
      "  Learning Rate: 8.98e-05\n",
      "  Global Step: 12096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b27abf05f345ccbeea4c297a97f015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 1.4303\n",
      "Epoch 28/30 completed:\n",
      "  Average Loss: 1.4303\n",
      "  Learning Rate: 8.55e-05\n",
      "  Global Step: 12544\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178b0b8b53fc446f9575420cf0a1b8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 completed:\n",
      "  Average Loss: 1.4388\n",
      "  Learning Rate: 8.06e-05\n",
      "  Global Step: 12992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738887766247497d9e488e08703edcd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/30:   0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 1.4094\n",
      "Checkpoint saved: ../models/d3pm_epoch_30_2_0.pth\n",
      "Epoch 30/30 completed:\n",
      "  Average Loss: 1.4094\n",
      "  Learning Rate: 7.52e-05\n",
      "  Global Step: 13440\n",
      "Checkpoint saved: ../models/d3pm_epoch_30_2_0.pth\n",
      "Epoch 30/30 completed:\n",
      "  Average Loss: 1.4094\n",
      "  Learning Rate: 7.52e-05\n",
      "  Global Step: 13440\n",
      "\n",
      "Training complete!\n",
      "Final model saved: ../models/d3pm_final_2_0.pth\n",
      "Best loss achieved: 1.4094\n",
      "Total training steps: 13440\n",
      "TensorBoard logs: ../runs/d3pm_training_20250606_144338\n",
      "\n",
      "Training complete!\n",
      "Final model saved: ../models/d3pm_final_2_0.pth\n",
      "Best loss achieved: 1.4094\n",
      "Total training steps: 13440\n",
      "TensorBoard logs: ../runs/d3pm_training_20250606_144338\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "import os\n",
    "\n",
    "# Hyperparameters\n",
    "seq_len = 20\n",
    "batch_size = 32\n",
    "num_epochs = 30\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-5  # Added weight decay\n",
    "vocab_size = tokenizer.vocab_size\n",
    "num_timesteps = 100\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = SimpleDylanDataset(lines, tokenizer, seq_len=seq_len)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Instantiate models\n",
    "diffuser = D3pmDiffusion(num_discrete_states=vocab_size, num_timesteps=num_timesteps).to(device)\n",
    "model = DiffusionTransformer(vocab_size=vocab_size, seq_len=seq_len).to(device)\n",
    "\n",
    "# Enhanced optimizer with weight decay\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Adaptive learning rate scheduler\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=3, T_mult=2, eta_min=1e-6)\n",
    "# Alternative: ReduceLROnPlateau for validation-based scheduling\n",
    "# scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "# TensorBoard setup\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_dir = f\"../runs/d3pm_training_{timestamp}\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "print(f\"TensorBoard logs will be saved to: {log_dir}\")\n",
    "print(f\"To view logs, run: tensorboard --logdir {log_dir}\")\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "\n",
    "model_name = \"d3pm\"\n",
    "version = \"2_0\"  # Updated version with enhancements\n",
    "do_train = True\n",
    "\n",
    "if do_train:\n",
    "    print(\"\\nStarting enhanced training loop...\")\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "    global_step = 0\n",
    "    best_loss = float(\"inf\")\n",
    "\n",
    "    # Training metrics tracking\n",
    "    train_losses = []\n",
    "    learning_rates = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        # Progress bar for batches\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        for batch_idx, batch_x_0 in enumerate(pbar):\n",
    "            batch_x_0 = batch_x_0.to(device)\n",
    "            batch_size_actual = batch_x_0.shape[0]\n",
    "\n",
    "            # Sample random timesteps\n",
    "            timesteps = torch.randint(0, num_timesteps, (batch_size_actual,), device=device)\n",
    "\n",
    "            # Forward diffusion process\n",
    "            x_t = diffuser(batch_x_0, timesteps)\n",
    "\n",
    "            # Model prediction\n",
    "            predicted_logits = model(x_t, timesteps)\n",
    "\n",
    "            # Compute loss\n",
    "            # loss = criterion(predicted_logits.view(-1, vocab_size), batch_x_0.view(-1))\n",
    "            loss = diffuser.compute_loss(batch_x_0, predicted_logits, timesteps, pad_token_id=tokenizer.pad_token_id)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping for stability\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update metrics\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            global_step += 1\n",
    "\n",
    "            # Get current learning rate\n",
    "            current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "            # Log to TensorBoard (every 10 steps to avoid too much logging)\n",
    "            if global_step % 10 == 0:\n",
    "                writer.add_scalar(\"Loss/Batch\", loss.item(), global_step)\n",
    "                writer.add_scalar(\"Learning_Rate\", current_lr, global_step)\n",
    "                writer.add_scalar(\n",
    "                    \"Gradient_Norm\",\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=float(\"inf\")),\n",
    "                    global_step,\n",
    "                )\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\", \"LR\": f\"{current_lr:.2e}\", \"Step\": global_step})\n",
    "\n",
    "            # Memory cleanup\n",
    "            if batch_idx % 20 == 0:\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                elif torch.backends.mps.is_available():\n",
    "                    torch.mps.empty_cache()\n",
    "\n",
    "        # Calculate epoch metrics\n",
    "        avg_epoch_loss = epoch_loss / num_batches\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step()\n",
    "        # For ReduceLROnPlateau, use: scheduler.step(avg_epoch_loss)\n",
    "\n",
    "        # Log epoch metrics to TensorBoard\n",
    "        writer.add_scalar(\"Loss/Epoch\", avg_epoch_loss, epoch)\n",
    "        writer.add_scalar(\"Learning_Rate/Epoch\", current_lr, epoch)\n",
    "\n",
    "        # Log model parameters histogram every few epochs\n",
    "        if epoch % 5 == 0:\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    writer.add_histogram(f\"Parameters/{name}\", param.data, epoch)\n",
    "                    if param.grad is not None:\n",
    "                        writer.add_histogram(f\"Gradients/{name}\", param.grad.data, epoch)\n",
    "\n",
    "        # Save best model\n",
    "        if avg_epoch_loss < best_loss:\n",
    "            best_loss = avg_epoch_loss\n",
    "            best_model_path = f\"../models/{model_name}_best_{version}.pth\"\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                    \"loss\": best_loss,\n",
    "                    \"global_step\": global_step,\n",
    "                },\n",
    "                best_model_path,\n",
    "            )\n",
    "            print(f\"✓ New best model saved with loss: {best_loss:.4f}\")\n",
    "\n",
    "        # Regular checkpoint saving\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            checkpoint_path = f\"../models/{model_name}_epoch_{epoch + 1}_{version}.pth\"\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                    \"loss\": avg_epoch_loss,\n",
    "                    \"global_step\": global_step,\n",
    "                },\n",
    "                checkpoint_path,\n",
    "            )\n",
    "            print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "        # Store metrics for plotting\n",
    "        train_losses.append(avg_epoch_loss)\n",
    "        learning_rates.append(current_lr)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} completed:\")\n",
    "        print(f\"  Average Loss: {avg_epoch_loss:.4f}\")\n",
    "        print(f\"  Learning Rate: {current_lr:.2e}\")\n",
    "        print(f\"  Global Step: {global_step}\")\n",
    "\n",
    "    # Final model save\n",
    "    final_model_path = f\"../models/{model_name}_final_{version}.pth\"\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": num_epochs,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "            \"loss\": avg_epoch_loss,\n",
    "            \"global_step\": global_step,\n",
    "            \"train_losses\": train_losses,\n",
    "            \"learning_rates\": learning_rates,\n",
    "        },\n",
    "        final_model_path,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTraining complete!\")\n",
    "    print(f\"Final model saved: {final_model_path}\")\n",
    "    print(f\"Best loss achieved: {best_loss:.4f}\")\n",
    "    print(f\"Total training steps: {global_step}\")\n",
    "    print(f\"TensorBoard logs: {log_dir}\")\n",
    "\n",
    "    # Close TensorBoard writer\n",
    "    writer.close()\n",
    "\n",
    "    # Plot training curves\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # Loss curve\n",
    "    ax1.plot(train_losses)\n",
    "    ax1.set_title(\"Training Loss\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Learning rate curve\n",
    "    ax2.plot(learning_rates)\n",
    "    ax2.set_title(\"Learning Rate Schedule\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Learning Rate\")\n",
    "    ax2.set_yscale(\"log\")\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(\"../plots\", exist_ok=True)\n",
    "    plt.savefig(f\"../plots/training_curves_{timestamp}.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    # Load existing model\n",
    "    model_path = f\"../models/{model_name}_best_{version}.pth\"\n",
    "    if os.path.exists(model_path):\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        print(f\"Loaded model from {model_path}\")\n",
    "    else:\n",
    "        print(f\"Model file not found: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2683f047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \"how many roads\"\n",
      "Initial noisy sequence:\n",
      "how many roads Moon reek wine Seven attered pump Said ves mitting bout ces plain though gun aband zed pain\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e8ab4de2cb400ea9628fabf3d98b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Denoising with prompt:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 100: how many roads , , wine , , pump the ’ you bout the plain though gun the the pain\n",
      "  Step 80: how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n",
      "  Step 80: how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n",
      "  Step 60: how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n",
      "  Step 60: how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n",
      "  Step 40: how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n",
      "  Step 40: how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n",
      "  Step 20: how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n",
      "\n",
      "Final generated text:\n",
      "how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n",
      "  Step 20: how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n",
      "\n",
      "Final generated text:\n",
      "how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    input_prompt_text = \"the answer is\"  # Try different prompts\n",
    "    input_prompt_text = \"how many roads\"\n",
    "    # input_prompt_text = \"like a rolling\"\n",
    "\n",
    "    prompt_tokens = tokenizer.encode(input_prompt_text, add_special_tokens=False)\n",
    "    prompt_len = len(prompt_tokens)\n",
    "\n",
    "    if prompt_len >= seq_len:\n",
    "        raise ValueError(\n",
    "            f\"Prompt length ({prompt_len}) exceeds sequence length ({seq_len}). Please shorten the prompt.\"\n",
    "        )\n",
    "\n",
    "    initial_sequence = torch.full((1, seq_len), tokenizer.pad_token_id, dtype=torch.long, device=device)\n",
    "\n",
    "    initial_sequence[0, :prompt_len] = torch.tensor(prompt_tokens, dtype=torch.long, device=device)\n",
    "\n",
    "    # Fill the rest with random tokens (pure noise for the parts to be completed)\n",
    "    rand_tokens = torch.randint(low=0, high=vocab_size, size=(1, seq_len - prompt_len), device=device)\n",
    "    if tokenizer.pad_token_id != -1:  # Assuming -1 means no specific pad_token_id\n",
    "        rand_tokens[rand_tokens == tokenizer.pad_token_id] = tokenizer.unk_token_id\n",
    "\n",
    "    initial_sequence[0, prompt_len:] = rand_tokens[0]\n",
    "\n",
    "    print(f'Prompt: \"{input_prompt_text}\"')\n",
    "    print(f\"Initial noisy sequence:\\n{tokenizer.decode(initial_sequence[0].cpu().tolist())}\")\n",
    "\n",
    "    current_x = initial_sequence.clone()\n",
    "    # The actual denoising loop should go from T down to 1\n",
    "    inference_steps = num_timesteps  # Max T is num_timesteps (from 1 to num_timesteps)\n",
    "\n",
    "    for t_idx in tqdm(range(inference_steps, 0, -1), desc=\"Denoising with prompt\"):\n",
    "        t_tensor = torch.tensor([t_idx], dtype=torch.long, device=device)\n",
    "\n",
    "        # Model predicts logits for x_0 given current_x and t\n",
    "        predicted_logits_x0 = model(current_x, t_tensor)\n",
    "        predicted_probs_x0 = F.softmax(predicted_logits_x0, dim=-1)\n",
    "\n",
    "        # could use top-k sampling or temperature.\n",
    "        next_x_sampled = torch.argmax(predicted_probs_x0, dim=-1)  # (1, seq_len)\n",
    "\n",
    "        # Keep the prompt tokens unchanged\n",
    "        next_x_sampled[0, :prompt_len] = initial_sequence[0, :prompt_len]\n",
    "\n",
    "        current_x = next_x_sampled\n",
    "\n",
    "        # Print intermediate results for a few steps\n",
    "        if t_idx % (inference_steps // 5) == 0:\n",
    "            print(f\"  Step {t_idx}: {tokenizer.decode(current_x[0].cpu().tolist())}\")\n",
    "\n",
    "    final_generated_text = tokenizer.decode(current_x[0].cpu().tolist())\n",
    "    print(f\"\\nFinal generated text:\\n{final_generated_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ccfc46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b14bb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93dace5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a limited dataset with only 100 records for system setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543652a3",
   "metadata": {},
   "source": [
    "# Improved D3PM Implementation\n",
    "\n",
    "Based on the analysis of the training issues, here are the key improvements:\n",
    "\n",
    "1. **Larger vocabulary size** (5000 tokens) for better expressiveness\n",
    "2. **Longer sequences** (64 tokens) to capture more meaningful patterns\n",
    "3. **Better diffusion schedule** with lower beta values\n",
    "4. **Improved model architecture** with larger dimensions\n",
    "5. **Proper D3PM loss formulation**\n",
    "6. **Better learning rate schedule**\n",
    "7. **Validation set** for monitoring overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae060e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved tokenizer with larger vocabulary\n",
    "print(\"Creating improved tokenizer with larger vocabulary...\")\n",
    "\n",
    "# Initialize Dylan tokenizer with larger vocabulary\n",
    "improved_tokenizer = SimpleDylanTokenizer(vocab_size=5000)\n",
    "\n",
    "# Train the tokenizer on Dylan lyrics\n",
    "improved_tokenizer.train_tokenizer(corpus=lines, save_path=\"./improved_dylan_tokenizer\")\n",
    "\n",
    "# Convert to HuggingFace format\n",
    "improved_hf_tokenizer = improved_tokenizer.get_transformers_tokenizer()\n",
    "\n",
    "print(f\"Improved tokenizer vocabulary size: {len(improved_hf_tokenizer)}\")\n",
    "print(f\"Special tokens: {improved_hf_tokenizer.special_tokens_map}\")\n",
    "\n",
    "# Test the improved tokenizer\n",
    "phrase = \"The answer my friend is blowin' in the wind\"\n",
    "tokens = improved_hf_tokenizer.encode(phrase, add_special_tokens=False)\n",
    "decoded = improved_hf_tokenizer.decode(tokens, skip_special_tokens=False)\n",
    "token_strs = improved_hf_tokenizer.convert_ids_to_tokens(tokens)\n",
    "\n",
    "print(f\"Original: {phrase}\")\n",
    "print(f\"Decoded: {decoded}\")\n",
    "print(f\"Tokens: {token_strs}\")\n",
    "print(f\"Number of tokens: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e5ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved dataset with longer sequences and validation split\n",
    "print(\"Creating improved dataset with longer sequences...\")\n",
    "\n",
    "# Improved dataset parameters\n",
    "IMPROVED_SEQ_LEN = 41  # Longer sequences to capture more context\n",
    "IMPROVED_BATCH_SIZE = 16  # Adjusted for longer sequences\n",
    "\n",
    "\n",
    "class ImprovedDylanDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, seq_len=64, min_length=10):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "        self.examples = []\n",
    "\n",
    "        for line in texts:\n",
    "            if len(line.strip()) < min_length:  # Skip very short lines\n",
    "                continue\n",
    "\n",
    "            tokens = tokenizer.encode(line.strip(), add_special_tokens=False)\n",
    "\n",
    "            # Only include sequences that have meaningful content\n",
    "            if len(tokens) >= min_length:\n",
    "                # Truncate if too long\n",
    "                if len(tokens) > seq_len:\n",
    "                    tokens = tokens[:seq_len]\n",
    "\n",
    "                self.examples.append(tokens)\n",
    "\n",
    "        print(f\"Created dataset with {len(self.examples)} examples\")\n",
    "        print(f\"Average sequence length: {np.mean([len(ex) for ex in self.examples]):.1f}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.examples[idx]\n",
    "        pad_id = self.tokenizer.pad_token_id if hasattr(self.tokenizer, \"pad_token_id\") else 0\n",
    "\n",
    "        # Pad to sequence length\n",
    "        padded = tokens + [pad_id] * (self.seq_len - len(tokens))\n",
    "        return torch.tensor(padded[: self.seq_len], dtype=torch.long)\n",
    "\n",
    "\n",
    "# Split data into train/validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_lines, val_lines = train_test_split(lines, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"Training lines: {len(train_lines)}\")\n",
    "print(f\"Validation lines: {len(val_lines)}\")\n",
    "\n",
    "# Create improved datasets\n",
    "train_dataset = ImprovedDylanDataset(train_lines, improved_hf_tokenizer, seq_len=IMPROVED_SEQ_LEN)\n",
    "val_dataset = ImprovedDylanDataset(val_lines, improved_hf_tokenizer, seq_len=IMPROVED_SEQ_LEN)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=IMPROVED_BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=IMPROVED_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Train batches: {len(train_dataloader)}\")\n",
    "print(f\"Validation batches: {len(val_dataloader)}\")\n",
    "\n",
    "# Test the dataset\n",
    "sample_batch = next(iter(train_dataloader))\n",
    "print(f\"Sample batch shape: {sample_batch.shape}\")\n",
    "print(f\"Sample sequence: {improved_hf_tokenizer.decode(sample_batch[0].tolist(), skip_special_tokens=False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d60602",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedD3PM(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_discrete_states: int, num_timesteps: int = 1000, beta_start: float = 0.0001, beta_end: float = 0.02\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_discrete_states = num_discrete_states\n",
    "        self.num_timesteps = num_timesteps\n",
    "\n",
    "        # More conservative beta schedule\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alpha_bars = torch.cumprod(self.alphas, dim=0)\n",
    "\n",
    "        # Precompute transition matrices\n",
    "        self.transition_matrices_t = nn.ParameterList()\n",
    "        self.cumulative_transition_matrices_t = nn.ParameterList()\n",
    "\n",
    "        Q_prev_cumulative = torch.eye(num_discrete_states)\n",
    "\n",
    "        for t in range(num_timesteps):\n",
    "            beta = self.betas[t].item()\n",
    "\n",
    "            # More conservative transition matrix\n",
    "            diag_prob = 1.0 - beta\n",
    "            off_diag_prob = beta / (num_discrete_states - 1) if num_discrete_states > 1 else 0.0\n",
    "\n",
    "            Q_t = torch.eye(num_discrete_states) * diag_prob\n",
    "            Q_t = (\n",
    "                Q_t\n",
    "                + (torch.ones(num_discrete_states, num_discrete_states) - torch.eye(num_discrete_states))\n",
    "                * off_diag_prob\n",
    "            )\n",
    "            Q_t = Q_t / Q_t.sum(dim=1, keepdim=True)\n",
    "\n",
    "            self.transition_matrices_t.append(nn.Parameter(Q_t, requires_grad=False))\n",
    "\n",
    "            Q_current_cumulative = torch.matmul(Q_t, Q_prev_cumulative)\n",
    "            self.cumulative_transition_matrices_t.append(nn.Parameter(Q_current_cumulative, requires_grad=False))\n",
    "            Q_prev_cumulative = Q_current_cumulative\n",
    "\n",
    "    def forward(self, x_0: torch.Tensor, t: torch.Tensor):\n",
    "        \"\"\"Forward diffusion process\"\"\"\n",
    "        original_shape = x_0.shape\n",
    "        batch_size = original_shape[0]\n",
    "        x_flat = x_0.view(batch_size, -1)\n",
    "        num_elements = x_flat.shape[1]\n",
    "\n",
    "        # Convert to one-hot encoding\n",
    "        x_one_hot = F.one_hot(x_flat, num_classes=self.num_discrete_states).float()\n",
    "\n",
    "        # Gather transition matrices for batch\n",
    "        Q_bar_t_batch = torch.stack([self.cumulative_transition_matrices_t[idx] for idx in t])\n",
    "\n",
    "        # Apply transition\n",
    "        next_state_probs = torch.bmm(x_one_hot, Q_bar_t_batch)\n",
    "\n",
    "        # Sample from categorical distribution\n",
    "        x_t = torch.multinomial(next_state_probs.view(-1, self.num_discrete_states), num_samples=1).squeeze(dim=1)\n",
    "        x_t = x_t.view(original_shape)\n",
    "\n",
    "        return x_t\n",
    "\n",
    "    def compute_loss(self, x_0: torch.Tensor, predicted_logits: torch.Tensor, t: torch.Tensor, pad_token_id: int = 0):\n",
    "        \"\"\"Compute proper D3PM loss with padding mask\"\"\"\n",
    "        batch_size, seq_len = x_0.shape\n",
    "\n",
    "        # Create padding mask\n",
    "        pad_mask = (x_0 != pad_token_id).float()  # 1 for real tokens, 0 for padding\n",
    "\n",
    "        # Compute cross-entropy loss\n",
    "        loss = F.cross_entropy(predicted_logits.view(-1, self.num_discrete_states), x_0.view(-1), reduction=\"none\")\n",
    "\n",
    "        # Apply padding mask\n",
    "        loss = loss.view(batch_size, seq_len)\n",
    "        masked_loss = loss * pad_mask\n",
    "\n",
    "        # Average over non-padded tokens\n",
    "        total_loss = masked_loss.sum() / pad_mask.sum().clamp(min=1)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "\n",
    "print(\"Improved D3PM implementation created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4497323",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedTimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.mlp = nn.Sequential(nn.Linear(dim, dim * 4), nn.GELU(), nn.Linear(dim * 4, dim))\n",
    "\n",
    "    def forward(self, t):\n",
    "        half = self.dim // 2\n",
    "        freqs = torch.exp(-math.log(10000) * torch.arange(half, dtype=torch.float32) / half).to(t.device)\n",
    "        args = t[:, None].float() * freqs[None]\n",
    "        emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "        return self.mlp(emb)\n",
    "\n",
    "\n",
    "class ImprovedDiffusionTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, seq_len, dim=768, heads=12, layers=12, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.dim = dim\n",
    "\n",
    "        # Embeddings\n",
    "        self.token_emb = nn.Embedding(vocab_size, dim)\n",
    "        self.pos_emb = nn.Embedding(seq_len, dim)\n",
    "        self.time_emb = ImprovedTimeEmbedding(dim)\n",
    "\n",
    "        # Transformer layers with improved architecture\n",
    "        encoder_layers = []\n",
    "        for _ in range(layers):\n",
    "            layer = nn.TransformerEncoderLayer(\n",
    "                d_model=dim,\n",
    "                nhead=heads,\n",
    "                dim_feedforward=dim * 4,\n",
    "                dropout=dropout,\n",
    "                activation=\"gelu\",\n",
    "                batch_first=True,\n",
    "                norm_first=True,  # Pre-norm for better training stability\n",
    "            )\n",
    "            encoder_layers.append(layer)\n",
    "\n",
    "        self.transformer = nn.ModuleList(encoder_layers)\n",
    "\n",
    "        # Output projection\n",
    "        self.layer_norm = nn.LayerNorm(dim)\n",
    "        self.to_logits = nn.Linear(dim, vocab_size)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            torch.nn.init.zeros_(module.bias)\n",
    "            torch.nn.init.ones_(module.weight)\n",
    "\n",
    "    def forward(self, x, t, attention_mask=None):\n",
    "        B, L = x.shape\n",
    "\n",
    "        # Token embeddings\n",
    "        tok_emb = self.token_emb(x)  # (B, L, D)\n",
    "\n",
    "        # Position embeddings\n",
    "        pos_indices = torch.arange(L, device=x.device).expand(B, -1)\n",
    "        pos_emb = self.pos_emb(pos_indices)  # (B, L, D)\n",
    "\n",
    "        # Time embeddings\n",
    "        time_emb = self.time_emb(t).unsqueeze(1).expand(-1, L, -1)  # (B, L, D)\n",
    "\n",
    "        # Combine embeddings\n",
    "        h = tok_emb + pos_emb + time_emb\n",
    "\n",
    "        # Create attention mask for padding tokens\n",
    "        if attention_mask is None:\n",
    "            # Assume padding tokens are 0\n",
    "            attention_mask = (x != 0).float()\n",
    "\n",
    "        # Convert to transformer format (True = masked positions)\n",
    "        src_key_padding_mask = attention_mask == 0\n",
    "\n",
    "        # Apply transformer layers\n",
    "        for layer in self.transformer:\n",
    "            h = layer(h, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        # Layer norm and output projection\n",
    "        h = self.layer_norm(h)\n",
    "        logits = self.to_logits(h)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "print(\"Improved transformer model created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ddf0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved training setup\n",
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Improved hyperparameters\n",
    "IMPROVED_HYPERPARAMS = {\n",
    "    \"seq_len\": IMPROVED_SEQ_LEN,\n",
    "    \"batch_size\": IMPROVED_BATCH_SIZE,\n",
    "    \"num_epochs\": 20,\n",
    "    \"learning_rate\": 3e-4,  # Higher learning rate\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"vocab_size\": len(improved_hf_tokenizer),\n",
    "    \"num_timesteps\": 1000,  # More timesteps\n",
    "    \"model_dim\": 768,  # Larger model\n",
    "    \"model_heads\": 12,\n",
    "    \"model_layers\": 8,  # Reasonable depth\n",
    "    \"dropout\": 0.1,\n",
    "    \"gradient_clip\": 1.0,\n",
    "    \"warmup_steps\": 1000,\n",
    "    \"beta_start\": 0.0001,\n",
    "    \"beta_end\": 0.02,  # More conservative\n",
    "}\n",
    "\n",
    "print(\"Improved hyperparameters:\")\n",
    "for key, value in IMPROVED_HYPERPARAMS.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Initialize improved models\n",
    "print(\"\\nInitializing improved models...\")\n",
    "improved_diffuser = ImprovedD3PM(\n",
    "    num_discrete_states=IMPROVED_HYPERPARAMS[\"vocab_size\"],\n",
    "    num_timesteps=IMPROVED_HYPERPARAMS[\"num_timesteps\"],\n",
    "    beta_start=IMPROVED_HYPERPARAMS[\"beta_start\"],\n",
    "    beta_end=IMPROVED_HYPERPARAMS[\"beta_end\"],\n",
    ").to(device)\n",
    "\n",
    "improved_model = ImprovedDiffusionTransformer(\n",
    "    vocab_size=IMPROVED_HYPERPARAMS[\"vocab_size\"],\n",
    "    seq_len=IMPROVED_HYPERPARAMS[\"seq_len\"],\n",
    "    dim=IMPROVED_HYPERPARAMS[\"model_dim\"],\n",
    "    heads=IMPROVED_HYPERPARAMS[\"model_heads\"],\n",
    "    layers=IMPROVED_HYPERPARAMS[\"model_layers\"],\n",
    "    dropout=IMPROVED_HYPERPARAMS[\"dropout\"],\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in improved_model.parameters()):,}\")\n",
    "\n",
    "# Improved optimizer and scheduler\n",
    "optimizer = torch.optim.AdamW(\n",
    "    improved_model.parameters(),\n",
    "    lr=IMPROVED_HYPERPARAMS[\"learning_rate\"],\n",
    "    weight_decay=IMPROVED_HYPERPARAMS[\"weight_decay\"],\n",
    "    betas=(0.9, 0.95),\n",
    ")\n",
    "\n",
    "# One cycle learning rate scheduler\n",
    "total_steps = len(train_dataloader) * IMPROVED_HYPERPARAMS[\"num_epochs\"]\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=IMPROVED_HYPERPARAMS[\"learning_rate\"],\n",
    "    total_steps=total_steps,\n",
    "    pct_start=0.1,  # Warmup for 10% of training\n",
    "    anneal_strategy=\"cos\",\n",
    "    cycle_momentum=True,\n",
    "    base_momentum=0.85,\n",
    "    max_momentum=0.95,\n",
    ")\n",
    "\n",
    "# TensorBoard setup\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_dir = f\"../runs/improved_d3pm_{timestamp}\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "print(f\"TensorBoard logs: {log_dir}\")\n",
    "print(f\"Total training steps: {total_steps:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b748e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, diffuser, val_dataloader, tokenizer, device):\n",
    "    \"\"\"Validation function\"\"\"\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    num_val_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x_0 in val_dataloader:\n",
    "            batch_x_0 = batch_x_0.to(device)\n",
    "            batch_size_actual = batch_x_0.shape[0]\n",
    "\n",
    "            # Sample timesteps\n",
    "            timesteps = torch.randint(0, diffuser.num_timesteps, (batch_size_actual,), device=device)\n",
    "\n",
    "            # Forward diffusion\n",
    "            x_t = diffuser(batch_x_0, timesteps)\n",
    "\n",
    "            # Model prediction\n",
    "            predicted_logits = model(x_t, timesteps)\n",
    "\n",
    "            # Compute loss using improved loss function\n",
    "            loss = diffuser.compute_loss(batch_x_0, predicted_logits, timesteps, pad_token_id=tokenizer.pad_token_id)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            num_val_batches += 1\n",
    "\n",
    "    model.train()\n",
    "    return total_val_loss / num_val_batches if num_val_batches > 0 else float(\"inf\")\n",
    "\n",
    "\n",
    "# Improved training loop\n",
    "print(\"\\n=== Starting Improved Training ===\")\n",
    "\n",
    "model_name = \"improved_d3pm\"\n",
    "version = \"3_0\"\n",
    "do_train = True\n",
    "\n",
    "if do_train:\n",
    "    global_step = 0\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience = 3\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training metrics\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    learning_rates = []\n",
    "\n",
    "    for epoch in range(IMPROVED_HYPERPARAMS[\"num_epochs\"]):\n",
    "        improved_model.train()\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        # Training loop\n",
    "        pbar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{IMPROVED_HYPERPARAMS['num_epochs']}\")\n",
    "\n",
    "        for batch_idx, batch_x_0 in enumerate(pbar):\n",
    "            batch_x_0 = batch_x_0.to(device)\n",
    "            batch_size_actual = batch_x_0.shape[0]\n",
    "\n",
    "            # Sample random timesteps\n",
    "            timesteps = torch.randint(0, improved_diffuser.num_timesteps, (batch_size_actual,), device=device)\n",
    "\n",
    "            # Forward diffusion\n",
    "            x_t = improved_diffuser(batch_x_0, timesteps)\n",
    "\n",
    "            # Model prediction\n",
    "            predicted_logits = improved_model(x_t, timesteps)\n",
    "\n",
    "            # Compute improved loss\n",
    "            loss = improved_diffuser.compute_loss(\n",
    "                batch_x_0, predicted_logits, timesteps, pad_token_id=improved_hf_tokenizer.pad_token_id\n",
    "            )\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(improved_model.parameters(), max_norm=IMPROVED_HYPERPARAMS[\"gradient_clip\"])\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Update metrics\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            global_step += 1\n",
    "\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "            # Log to TensorBoard\n",
    "            if global_step % 50 == 0:\n",
    "                writer.add_scalar(\"Loss/Train_Step\", loss.item(), global_step)\n",
    "                writer.add_scalar(\"Learning_Rate\", current_lr, global_step)\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\", \"LR\": f\"{current_lr:.2e}\", \"Step\": global_step})\n",
    "\n",
    "            # Memory cleanup\n",
    "            if batch_idx % 50 == 0:\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                elif torch.backends.mps.is_available():\n",
    "                    torch.mps.empty_cache()\n",
    "\n",
    "        # Calculate epoch metrics\n",
    "        avg_train_loss = epoch_loss / num_batches\n",
    "\n",
    "        # Validation\n",
    "        print(\"\\nRunning validation...\")\n",
    "        avg_val_loss = validate_model(improved_model, improved_diffuser, val_dataloader, improved_hf_tokenizer, device)\n",
    "\n",
    "        # Store metrics\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        learning_rates.append(current_lr)\n",
    "\n",
    "        # Log epoch metrics\n",
    "        writer.add_scalar(\"Loss/Train_Epoch\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/Validation_Epoch\", avg_val_loss, epoch)\n",
    "        writer.add_scalar(\"Learning_Rate/Epoch\", current_lr, epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{IMPROVED_HYPERPARAMS['num_epochs']} Results:\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"  Val Loss: {avg_val_loss:.4f}\")\n",
    "        print(f\"  Learning Rate: {current_lr:.2e}\")\n",
    "        print(f\"  Global Step: {global_step:,}\")\n",
    "\n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "\n",
    "            best_model_path = f\"../models/{model_name}_best_{version}.pth\"\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": improved_model.state_dict(),\n",
    "                    \"diffuser_state_dict\": improved_diffuser.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                    \"train_loss\": avg_train_loss,\n",
    "                    \"val_loss\": avg_val_loss,\n",
    "                    \"global_step\": global_step,\n",
    "                    \"hyperparams\": IMPROVED_HYPERPARAMS,\n",
    "                },\n",
    "                best_model_path,\n",
    "            )\n",
    "\n",
    "            print(f\"  ✓ New best model saved! Val loss: {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"  No improvement. Patience: {patience_counter}/{patience}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "\n",
    "        # Sample generation every few epochs\n",
    "        if (epoch + 1) % 3 == 0:\n",
    "            print(\"\\nGenerating sample...\")\n",
    "            improved_model.eval()\n",
    "            with torch.no_grad():\n",
    "                try:\n",
    "                    sample_prompt = \"The answer my friend\"\n",
    "                    sample_tokens = improved_hf_tokenizer.encode(sample_prompt, add_special_tokens=False)\n",
    "\n",
    "                    if len(sample_tokens) < IMPROVED_SEQ_LEN:\n",
    "                        pad_length = IMPROVED_SEQ_LEN - len(sample_tokens)\n",
    "                        sample_input = torch.tensor(\n",
    "                            [sample_tokens + [improved_hf_tokenizer.pad_token_id] * pad_length],\n",
    "                            device=device,\n",
    "                            dtype=torch.long,\n",
    "                        )\n",
    "\n",
    "                        # Simple denoising\n",
    "                        timesteps_sample = torch.tensor([improved_diffuser.num_timesteps // 2], device=device)\n",
    "                        x_t_sample = improved_diffuser(sample_input, timesteps_sample)\n",
    "                        predicted_logits_sample = improved_model(x_t_sample, timesteps_sample)\n",
    "                        predicted_tokens = torch.argmax(predicted_logits_sample, dim=-1)\n",
    "\n",
    "                        generated_text = improved_hf_tokenizer.decode(\n",
    "                            predicted_tokens[0].cpu().tolist(), skip_special_tokens=True\n",
    "                        )\n",
    "                        print(f\"  Sample: '{generated_text}'\")\n",
    "                        writer.add_text(\"Sample_Generation\", generated_text, epoch)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"  Sample generation failed: {e}\")\n",
    "\n",
    "            improved_model.train()\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    # Final save\n",
    "    final_model_path = f\"../models/{model_name}_final_{version}.pth\"\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": improved_model.state_dict(),\n",
    "            \"diffuser_state_dict\": improved_diffuser.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "            \"train_losses\": train_losses,\n",
    "            \"val_losses\": val_losses,\n",
    "            \"learning_rates\": learning_rates,\n",
    "            \"best_val_loss\": best_val_loss,\n",
    "            \"global_step\": global_step,\n",
    "            \"hyperparams\": IMPROVED_HYPERPARAMS,\n",
    "        },\n",
    "        final_model_path,\n",
    "    )\n",
    "\n",
    "    print(f\"\\n=== Training Complete ===\")\n",
    "    print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "    print(f\"Final model saved: {final_model_path}\")\n",
    "    print(f\"Total steps: {global_step:,}\")\n",
    "    print(f\"TensorBoard logs: {log_dir}\")\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    # Plot training curves\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "    # Loss curves\n",
    "    epochs_range = range(1, len(train_losses) + 1)\n",
    "    ax1.plot(epochs_range, train_losses, label=\"Train Loss\", color=\"blue\")\n",
    "    ax1.plot(epochs_range, val_losses, label=\"Validation Loss\", color=\"red\")\n",
    "    ax1.set_title(\"Training and Validation Loss\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Learning rate\n",
    "    ax2.plot(epochs_range, learning_rates)\n",
    "    ax2.set_title(\"Learning Rate Schedule\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Learning Rate\")\n",
    "    ax2.set_yscale(\"log\")\n",
    "    ax2.grid(True)\n",
    "\n",
    "    # Loss difference\n",
    "    loss_diff = np.array(val_losses) - np.array(train_losses)\n",
    "    ax3.plot(epochs_range, loss_diff)\n",
    "    ax3.axhline(y=0, color=\"black\", linestyle=\"--\", alpha=0.5)\n",
    "    ax3.set_title(\"Validation - Training Loss (Overfitting Check)\")\n",
    "    ax3.set_xlabel(\"Epoch\")\n",
    "    ax3.set_ylabel(\"Loss Difference\")\n",
    "    ax3.grid(True)\n",
    "\n",
    "    # Training progress\n",
    "    ax4.plot(epochs_range, train_losses, label=\"Train\", alpha=0.7)\n",
    "    ax4.plot(epochs_range, val_losses, label=\"Validation\", alpha=0.7)\n",
    "    ax4.fill_between(epochs_range, train_losses, alpha=0.3)\n",
    "    ax4.fill_between(epochs_range, val_losses, alpha=0.3)\n",
    "    ax4.set_title(\"Training Progress Overview\")\n",
    "    ax4.set_xlabel(\"Epoch\")\n",
    "    ax4.set_ylabel(\"Loss\")\n",
    "    ax4.legend()\n",
    "    ax4.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(\"../plots\", exist_ok=True)\n",
    "    plt.savefig(f\"../plots/improved_training_curves_{timestamp}.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Training disabled. Set do_train=True to start training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbe3d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_inference(model, diffuser, tokenizer, prompt, seq_len=64, num_steps=100, temperature=1.0, top_k=50):\n",
    "    \"\"\"Improved inference with better sampling strategies\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Prepare prompt\n",
    "        prompt_tokens = tokenizer.encode(prompt, add_special_tokens=False)\n",
    "        prompt_len = len(prompt_tokens)\n",
    "\n",
    "        if prompt_len >= seq_len:\n",
    "            print(f\"Warning: Prompt too long ({prompt_len} tokens). Truncating.\")\n",
    "            prompt_tokens = prompt_tokens[: seq_len - 1]\n",
    "            prompt_len = len(prompt_tokens)\n",
    "\n",
    "        # Initialize sequence\n",
    "        initial_sequence = torch.full((1, seq_len), tokenizer.pad_token_id, dtype=torch.long, device=device)\n",
    "        initial_sequence[0, :prompt_len] = torch.tensor(prompt_tokens, dtype=torch.long, device=device)\n",
    "\n",
    "        # Fill rest with random tokens\n",
    "        rand_tokens = torch.randint(low=1, high=len(tokenizer) - 1, size=(1, seq_len - prompt_len), device=device)\n",
    "        initial_sequence[0, prompt_len:] = rand_tokens[0]\n",
    "\n",
    "        print(f'Prompt: \"{prompt}\"')\n",
    "        print(f\"Initial sequence: {tokenizer.decode(initial_sequence[0].tolist(), skip_special_tokens=True)}\")\n",
    "\n",
    "        current_x = initial_sequence.clone()\n",
    "\n",
    "        # Denoising loop\n",
    "        for t_idx in tqdm(range(num_steps, 0, -1), desc=\"Denoising\"):\n",
    "            t_tensor = torch.tensor([t_idx], dtype=torch.long, device=device)\n",
    "\n",
    "            # Model prediction\n",
    "            predicted_logits = model(current_x, t_tensor)\n",
    "\n",
    "            # Apply temperature\n",
    "            if temperature > 0:\n",
    "                predicted_logits = predicted_logits / temperature\n",
    "\n",
    "            # Top-k sampling for non-prompt tokens\n",
    "            for pos in range(prompt_len, seq_len):\n",
    "                logits = predicted_logits[0, pos, :]\n",
    "\n",
    "                if top_k > 0:\n",
    "                    # Top-k sampling\n",
    "                    top_k_logits, top_k_indices = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                    probs = F.softmax(top_k_logits, dim=-1)\n",
    "                    sampled_idx = torch.multinomial(probs, num_samples=1)\n",
    "                    current_x[0, pos] = top_k_indices[sampled_idx]\n",
    "                else:\n",
    "                    # Standard sampling\n",
    "                    probs = F.softmax(logits, dim=-1)\n",
    "                    current_x[0, pos] = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "            # Keep prompt tokens unchanged\n",
    "            current_x[0, :prompt_len] = initial_sequence[0, :prompt_len]\n",
    "\n",
    "            # Print progress\n",
    "            if t_idx % (num_steps // 5) == 0 or t_idx == 1:\n",
    "                intermediate_text = tokenizer.decode(current_x[0].cpu().tolist(), skip_special_tokens=True)\n",
    "                print(f\"  Step {t_idx:3d}: {intermediate_text}\")\n",
    "\n",
    "    final_text = tokenizer.decode(current_x[0].cpu().tolist(), skip_special_tokens=True)\n",
    "    print(f\"\\nFinal result: {final_text}\")\n",
    "    return final_text\n",
    "\n",
    "\n",
    "print(\"Improved inference function created.\")\n",
    "print(\"\\nTo test the improved model after training, use:\")\n",
    "print(\"improved_inference(improved_model, improved_diffuser, improved_hf_tokenizer, 'Your prompt here')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4573f8",
   "metadata": {},
   "source": [
    "# Summary of Key Improvements to Fix Training Loss\n",
    "\n",
    "## Issues Identified in Original Implementation:\n",
    "\n",
    "1. **Vocabulary Size**: 1000 tokens → **5000 tokens** (better expressiveness)\n",
    "2. **Sequence Length**: 16-20 tokens → **64 tokens** (capture more context)\n",
    "3. **Diffusion Schedule**: Beta end 0.5 → **0.02** (less aggressive noise)\n",
    "4. **Model Architecture**: 512 dim, 6 layers → **768 dim, 8 layers** (more capacity)\n",
    "5. **Loss Function**: Basic CrossEntropy → **Proper D3PM loss with padding masks**\n",
    "6. **Learning Rate**: 1e-4 → **3e-4** with OneCycle scheduler\n",
    "7. **Validation**: None → **Train/val split with early stopping**\n",
    "8. **Attention**: No masking → **Proper attention masking for padding**\n",
    "\n",
    "## Expected Improvements:\n",
    "\n",
    "- **Loss should drop below 2.0** with these changes\n",
    "- Better text generation quality\n",
    "- More stable training\n",
    "- Proper overfitting detection\n",
    "\n",
    "## If Loss Still Doesn't Improve:\n",
    "\n",
    "1. **Check data quality**: Ensure sufficient text variety\n",
    "2. **Increase model size**: Try 1024 dim, 12 layers\n",
    "3. **Adjust diffusion schedule**: Try linear/cosine schedules\n",
    "4. **Learning rate**: Try 1e-3 or adaptive scheduling\n",
    "5. **Batch size**: Increase to 32-64 if memory allows\n",
    "6. **Training time**: Train for more epochs (50+)\n",
    "\n",
    "## Quick Start:\n",
    "\n",
    "```python\n",
    "# Run the improved training\n",
    "do_train = True  # Set this to True in the training cell\n",
    "\n",
    "# After training, test with:\n",
    "improved_inference(\n",
    "    improved_model, improved_diffuser, improved_hf_tokenizer,\n",
    "    \"The answer my friend\", temperature=0.8, top_k=50\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb553ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional imports for improved implementation\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"All required imports loaded for improved D3PM implementation.\")\n",
    "print(\"\\nReady to run improved training!\")\n",
    "print(\"\\nKey changes made:\")\n",
    "print(\"✓ Larger vocabulary (5000 tokens)\")\n",
    "print(\"✓ Longer sequences (64 tokens)\")\n",
    "print(\"✓ Better diffusion schedule (beta_end=0.02)\")\n",
    "print(\"✓ Improved model architecture (768 dim, 8 layers)\")\n",
    "print(\"✓ Proper D3PM loss with padding masks\")\n",
    "print(\"✓ OneCycle learning rate scheduler\")\n",
    "print(\"✓ Train/validation split with early stopping\")\n",
    "print(\"✓ Better inference with top-k sampling\")\n",
    "print(\"\\nExpected: Loss should drop significantly below 4.7!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df215e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models():\n",
    "    \"\"\"Compare original vs improved model parameters\"\"\"\n",
    "    print(\"Model Comparison:\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Original model specs\n",
    "    original_vocab = 1000\n",
    "    original_seq_len = 16\n",
    "    original_dim = 512\n",
    "    original_layers = 6\n",
    "    original_heads = 8\n",
    "\n",
    "    # Calculate original params (rough estimate)\n",
    "    original_params = (\n",
    "        original_vocab * original_dim  # token embedding\n",
    "        + original_seq_len * original_dim  # pos embedding\n",
    "        + original_dim * original_dim  # time embedding\n",
    "        + original_layers * (4 * original_dim * original_dim + original_dim * 4 * original_dim)  # transformer\n",
    "        + original_dim * original_vocab  # output projection\n",
    "    )\n",
    "\n",
    "    print(f\"Original Model:\")\n",
    "    print(f\"  Vocabulary: {original_vocab:,}\")\n",
    "    print(f\"  Sequence Length: {original_seq_len}\")\n",
    "    print(f\"  Dimensions: {original_dim}\")\n",
    "    print(f\"  Layers: {original_layers}\")\n",
    "    print(f\"  Estimated Parameters: {original_params:,}\")\n",
    "    print(f\"  Beta End: 0.5 (too aggressive)\")\n",
    "    print(f\"  Learning Rate: 1e-4 (too low)\")\n",
    "\n",
    "    print(f\"\\nImproved Model:\")\n",
    "    print(f\"  Vocabulary: {IMPROVED_HYPERPARAMS['vocab_size']:,}\")\n",
    "    print(f\"  Sequence Length: {IMPROVED_HYPERPARAMS['seq_len']}\")\n",
    "    print(f\"  Dimensions: {IMPROVED_HYPERPARAMS['model_dim']}\")\n",
    "    print(f\"  Layers: {IMPROVED_HYPERPARAMS['model_layers']}\")\n",
    "    if \"improved_model\" in globals():\n",
    "        actual_params = sum(p.numel() for p in improved_model.parameters())\n",
    "        print(f\"  Actual Parameters: {actual_params:,}\")\n",
    "    print(f\"  Beta End: {IMPROVED_HYPERPARAMS['beta_end']} (conservative)\")\n",
    "    print(f\"  Learning Rate: {IMPROVED_HYPERPARAMS['learning_rate']} (with OneCycle)\")\n",
    "\n",
    "    print(f\"\\nKey Improvements:\")\n",
    "    print(f\"  🚀 {IMPROVED_HYPERPARAMS['vocab_size'] / original_vocab:.1f}x larger vocabulary\")\n",
    "    print(f\"  📏 {IMPROVED_HYPERPARAMS['seq_len'] / original_seq_len:.1f}x longer sequences\")\n",
    "    print(f\"  🧠 {IMPROVED_HYPERPARAMS['model_dim'] / original_dim:.1f}x more dimensions\")\n",
    "    print(f\"  ⚡ {IMPROVED_HYPERPARAMS['learning_rate'] / (1e-4):.1f}x higher learning rate\")\n",
    "    print(f\"  🎯 Proper loss masking for padding tokens\")\n",
    "    print(f\"  📊 Train/validation split for monitoring\")\n",
    "    print(f\"  🔄 Advanced learning rate scheduling\")\n",
    "\n",
    "\n",
    "def diagnostic_check():\n",
    "    \"\"\"Run diagnostic checks on the training setup\"\"\"\n",
    "    print(\"\\nDiagnostic Check:\")\n",
    "    print(\"=\" * 30)\n",
    "\n",
    "    # Check if models are initialized\n",
    "    models_ready = all(name in globals() for name in [\"improved_model\", \"improved_diffuser\", \"improved_hf_tokenizer\"])\n",
    "    print(f\"✓ Models initialized: {models_ready}\")\n",
    "\n",
    "    # Check data\n",
    "    data_ready = all(\n",
    "        name in globals() for name in [\"train_dataloader\", \"val_dataloader\", \"train_dataset\", \"val_dataset\"]\n",
    "    )\n",
    "    print(f\"✓ Data ready: {data_ready}\")\n",
    "\n",
    "    if data_ready:\n",
    "        print(f\"  - Training samples: {len(train_dataset):,}\")\n",
    "        print(f\"  - Validation samples: {len(val_dataset):,}\")\n",
    "        print(f\"  - Training batches: {len(train_dataloader):,}\")\n",
    "\n",
    "    # Check device\n",
    "    print(f\"✓ Device: {device}\")\n",
    "\n",
    "    # Check memory\n",
    "    if torch.cuda.is_available():\n",
    "        memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "        print(f\"✓ GPU Memory: {memory_gb:.1f} GB\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        print(f\"✓ Using Apple Metal Performance Shaders\")\n",
    "\n",
    "    print(f\"\\n🎯 Ready to train! Expected loss improvement: 4.7 → <2.0\")\n",
    "\n",
    "\n",
    "# Run diagnostics\n",
    "compare_models()\n",
    "diagnostic_check()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-implementations (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
