{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e60c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n",
      "env: PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0\n"
     ]
    }
   ],
   "source": [
    "# | default_exp attention\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "%env PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4404c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "from icecream import ic\n",
    "import math\n",
    "from my_transformer.utils import save_model, load_model\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, normalizers\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "import json\n",
    "import os\n",
    "from rich import print\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b82294f",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7edbbc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Hard Times In New York Town',\n",
       "  'Come you ladies and you gentlemen, a-listen to my song',\n",
       "  'Sing it to you right, but you might think it’s wrong',\n",
       "  'Just a little glimpse of a story I’ll tell',\n",
       "  '’Bout an East Coast city that you all know well',\n",
       "  'It’s hard times in the city',\n",
       "  'Livin’ down in New York town',\n",
       "  'Old New York City is a friendly old town',\n",
       "  'From Washington Heights to Harlem on down',\n",
       "  'There’s a-mighty many people all millin’ all around'],\n",
       " 14318)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset/bob_dylan_lyrics.csv\")\n",
    "lines = []\n",
    "nb_rows = 999999\n",
    "row_id = 0\n",
    "for r in df.iterrows():\n",
    "    # todo: one line is one sentence.\n",
    "    lines.append(r[1][\"title\"])\n",
    "    # sentences.append(r[1][\"title\"] + \"\\n\" + r[1][\"lyrics\"])\n",
    "    lyrics = r[1][\"lyrics\"].split(\"\\n\")\n",
    "    for line in lyrics:\n",
    "        if len(line.strip()) > 0:\n",
    "            lines.append(line.strip())\n",
    "        row_id += 1\n",
    "\n",
    "lines[:10], len(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6bab58",
   "metadata": {},
   "source": [
    "### Simple Custom Tokenizer for Bob Dylan Lyrics\n",
    "\n",
    "Create a simple BPE (Byte-Pair Encoding) tokenizer trained specifically on Dylan's lyrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92266e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDylanTokenizer:\n",
    "    def __init__(self, vocab_size=3000):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tokenizer = None\n",
    "\n",
    "    def train_tokenizer(self, corpus: list[str], save_path: str = \"./simple_dylan_tokenizer\"):\n",
    "        # Initialize simple BPE tokenizer\n",
    "        tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "\n",
    "        # Simple whitespace pre-tokenization\n",
    "        tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "        # Simple trainer\n",
    "        trainer = BpeTrainer(\n",
    "            vocab_size=self.vocab_size, special_tokens=[\"[PAD]\", \"[UNK]\", \"[MASK]\"], min_frequency=2, show_progress=True\n",
    "        )\n",
    "\n",
    "        # Train the tokenizer\n",
    "        tokenizer.train_from_iterator(corpus, trainer)\n",
    "\n",
    "        # Save tokenizer\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        tokenizer.save(f\"{save_path}/tokenizer.json\")\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        print(f\"Tokenizer trained and saved to {save_path}\")\n",
    "\n",
    "        return tokenizer\n",
    "\n",
    "    def load_tokenizer(self, save_path=\"./simple_dylan_tokenizer\"):\n",
    "        \"\"\"Load the trained tokenizer\"\"\"\n",
    "        tokenizer_path = f\"{save_path}/tokenizer.json\"\n",
    "        if os.path.exists(tokenizer_path):\n",
    "            self.tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "            return self.tokenizer\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Tokenizer not found at {tokenizer_path}\")\n",
    "\n",
    "    def get_transformers_tokenizer(self):\n",
    "        \"\"\"Convert to HuggingFace tokenizer for compatibility\"\"\"\n",
    "        if self.tokenizer is None:\n",
    "            raise ValueError(\"Tokenizer not trained or loaded\")\n",
    "\n",
    "        # Create fast tokenizer wrapper\n",
    "        fast_tokenizer = PreTrainedTokenizerFast(\n",
    "            tokenizer_object=self.tokenizer, pad_token=\"[PAD]\", unk_token=\"[UNK]\", mask_token=\"[MASK]\"\n",
    "        )\n",
    "\n",
    "        return fast_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76920799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tokenizer trained and saved to .<span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">simple_dylan_tokenizer</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Tokenizer trained and saved to .\u001b[35m/\u001b[0m\u001b[95msimple_dylan_tokenizer\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(tokenizer): 5000\n",
      "ic| tokenizer.special_tokens_map: {'mask_token': '[MASK]', 'pad_token': '[PAD]', 'unk_token': '[UNK]'}\n",
      "ic| phrase: \"The answer my friend is blowin' in the wind\"\n",
      "ic| decoded: \"The answer my friend is blowin ' in the wind\"\n",
      "ic| token_strs: ['The', 'answer', 'my', 'friend', 'is', 'blowin', \"'\", 'in', 'the', 'wind']\n"
     ]
    }
   ],
   "source": [
    "# Initialize simple Dylan tokenizer\n",
    "dylan_tokenizer = SimpleDylanTokenizer(vocab_size=5000)\n",
    "\n",
    "# Train the tokenizer on Dylan lyrics\n",
    "dylan_tokenizer.train_tokenizer(corpus=lines, save_path=\"./simple_dylan_tokenizer\")\n",
    "\n",
    "# Convert to HuggingFace format for compatibility\n",
    "tokenizer = dylan_tokenizer.get_transformers_tokenizer()\n",
    "\n",
    "ic(len(tokenizer))\n",
    "ic(tokenizer.special_tokens_map)\n",
    "\n",
    "\n",
    "phrase = \"The answer my friend is blowin' in the wind\"\n",
    "\n",
    "tokens = tokenizer.encode(phrase, add_special_tokens=False)\n",
    "decoded = tokenizer.decode(tokens, skip_special_tokens=False)\n",
    "token_strs = tokenizer.convert_ids_to_tokens(tokens)\n",
    "ic(phrase)\n",
    "ic(decoded)\n",
    "ic(token_strs);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a50552a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Max sequence length in dataset: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Max sequence length in dataset: \u001b[1;36m40\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(dataset): 14318\n",
      "ic| seq_len: 20\n",
      "ic| len(tokenizer): 5000\n",
      "ic| sample_batch.shape: torch.Size([8, 20])\n",
      "ic| tokenizer.decode(sample_batch[0].tolist(), skip_special_tokens=False): ('I ’ m gone [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                                                                            '[PAD] [PAD] [PAD] [PAD] [PAD]')\n"
     ]
    }
   ],
   "source": [
    "class SimpleDylanDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, seq_len=128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "        self.examples = []\n",
    "        max_seq_len = 0\n",
    "\n",
    "        for line in texts:\n",
    "            # Simple tokenization - no structure tokens\n",
    "            tokens = tokenizer.encode(line.strip(), add_special_tokens=False)\n",
    "            token_nb = len(tokens)\n",
    "            max_seq_len = max(max_seq_len, token_nb)\n",
    "            # Truncate if too long\n",
    "\n",
    "            if token_nb > seq_len:\n",
    "                tokens = tokens[:seq_len]\n",
    "\n",
    "            if token_nb > 0:  # Skip empty sequences\n",
    "                self.examples.append(tokens)\n",
    "        print(f\"Max sequence length in dataset: {max_seq_len}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.examples[idx]\n",
    "        pad_id = self.tokenizer.pad_token_id if hasattr(self.tokenizer, \"pad_token_id\") else 0\n",
    "\n",
    "        # Pad to sequence length\n",
    "        padded = tokens + [pad_id] * (self.seq_len - len(tokens))\n",
    "        return torch.tensor(padded[: self.seq_len], dtype=torch.long)\n",
    "\n",
    "\n",
    "seq_len = 20  # Keep shorter sequences for memory efficiency\n",
    "batch_size = 8\n",
    "\n",
    "# Create dataset with selected tokenizer\n",
    "dataset = SimpleDylanDataset(lines, tokenizer, seq_len=seq_len)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "ic(len(dataset))\n",
    "ic(seq_len)\n",
    "ic(len(tokenizer))\n",
    "\n",
    "# Test the dataset\n",
    "sample_batch = next(iter(dataloader))\n",
    "ic(sample_batch.shape)\n",
    "ic(tokenizer.decode(sample_batch[0].tolist(), skip_special_tokens=False));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af94d38b",
   "metadata": {},
   "source": [
    "## Diffusion model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "54f5a9a5",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Timeline:  x₀ ────→ x₁ ────→ x₂ ────→ x₃\n",
    "          clean   noisy   noisier  noisiest\n",
    "           ↑        ↑        ↑        ↑\n",
    "         \"hello\"  \"h[M]lo\" \"[M][M]o\" \"[M][M][M]\"\n",
    "\n",
    "Forward process q(x_t | x_{t-1}):\n",
    "- q(x₁|x₀): \"hello\" → \"h[M]lo\" (add some noise)\n",
    "- q(x₂|x₁): \"h[M]lo\" → \"[M][M]o\" (add more noise)\n",
    "\n",
    "Posterior q(x_{t-1} | x_t, x₀):\n",
    "- q(x₁|x₂, x₀): Given \"[M][M]o\" and knowing original was \"hello\", \n",
    "                 what was x₁? Answer: probably \"h[M]lo\"\n",
    "- q(x₀|x₁, x₀): Given \"h[M]lo\" and knowing original was \"hello\",\n",
    "                 what was x₀? Answer: definitely \"hello\"\n",
    "\n",
    "\n",
    "# The KL loss compares:\n",
    "KL[q(x_{t-1}|x_t,x_0) || p_θ(x_{t-1}|x_t)]\n",
    "   ↑                    ↑\n",
    "   True denoising       Model's denoising\n",
    "   (uses ground truth) (learned)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "beb72e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformScheduler:\n",
    "    \"\"\"Simple uniform transition scheduler with linear noise schedule.\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int, num_timesteps: int, beta_start: float = 0.0001, beta_end: float = 0.02):\n",
    "        self.num_classes = num_classes\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "\n",
    "        # Create schedule and transition matrices\n",
    "        self.betas = self._create_linear_schedule()\n",
    "        self.Q_t = self._create_transition_matrices()\n",
    "        self.Q_bar_t = self._create_cumulative_matrices()\n",
    "\n",
    "    def _create_linear_schedule(self) -> torch.Tensor:\n",
    "        \"\"\"Create linear beta schedule: β_t increases linearly from beta_start to beta_end.\"\"\"\n",
    "        return torch.linspace(self.beta_start, self.beta_end, self.num_timesteps)\n",
    "\n",
    "    def _create_transition_matrices(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Create uniform transition matrices: Q_t = (1-β_t)I + β_t/K * 11^T\n",
    "\n",
    "        This means:\n",
    "        - Stay in same state with probability (1-β_t)\n",
    "        - Transition to any state (including same) with probability β_t/K each\n",
    "        \"\"\"\n",
    "        Q_matrices = torch.zeros(self.num_timesteps, self.num_classes, self.num_classes)\n",
    "\n",
    "        for t in range(self.num_timesteps):\n",
    "            beta_t = self.betas[t].item()\n",
    "\n",
    "            # Diagonal: probability of staying in same state\n",
    "            Q_t = (1 - beta_t) * torch.eye(self.num_classes)\n",
    "\n",
    "            # Off-diagonal: uniform probability of transitioning to any state\n",
    "            Q_t += beta_t / self.num_classes * torch.ones(self.num_classes, self.num_classes)\n",
    "\n",
    "            Q_matrices[t] = Q_t\n",
    "\n",
    "        return Q_matrices\n",
    "\n",
    "    def _create_cumulative_matrices(self) -> torch.Tensor:\n",
    "        \"\"\"Create cumulative matrices: Q̄_t = Q_1 * Q_2 * ... * Q_t\"\"\"\n",
    "        Q_bar_matrices = torch.zeros(self.num_timesteps, self.num_classes, self.num_classes)\n",
    "        Q_bar_matrices[0] = self.Q_t[0]\n",
    "\n",
    "        for t in range(1, self.num_timesteps):\n",
    "            Q_bar_matrices[t] = torch.matmul(Q_bar_matrices[t - 1], self.Q_t[t])\n",
    "\n",
    "        return Q_bar_matrices\n",
    "\n",
    "    def add_noise(self, x_0: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply forward diffusion: sample from q(x_t | x_0).\n",
    "\n",
    "        For uniform transitions, this uses the cumulative matrix Q̄_t.\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x_0.shape\n",
    "        device = x_0.device\n",
    "\n",
    "        # Convert to one-hot encoding\n",
    "        x_0_onehot = F.one_hot(x_0, self.num_classes).float()  # [B, L, K]\n",
    "\n",
    "        x_t = torch.zeros_like(x_0)\n",
    "\n",
    "        for i, t_val in enumerate(t):\n",
    "            # Get cumulative transition matrix for this timestep\n",
    "            Q_bar = self.Q_bar_t[t_val].to(device)  # [K, K]\n",
    "\n",
    "            # Compute transition probabilities: x_0 @ Q̄_t\n",
    "            # This gives probability distribution over x_t for each position\n",
    "            probs = torch.matmul(x_0_onehot[i], Q_bar)  # [L, K]\n",
    "\n",
    "            # Sample from categorical distribution\n",
    "            flat_probs = probs.view(-1, self.num_classes)  # [L, K]\n",
    "            flat_samples = torch.multinomial(flat_probs, 1).squeeze(-1)  # [L]\n",
    "            x_t[i] = flat_samples\n",
    "\n",
    "        return x_t\n",
    "\n",
    "    def get_posterior_params(self, x_t: torch.Tensor, x_0: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute true posterior q(x_{t-1} | x_t, x_0) using Equation 3.\n",
    "\n",
    "        From the paper: q(x_{t-1}|x_t,x_0) = Cat(x_{t-1}; p = x_t Q_t^T ⊙ x_0 Q̄_{t-1} / (x_0 Q̄_t x_t^T))\n",
    "\n",
    "        This tells us: given we observe x_t at time t and know the original was x_0,\n",
    "        what's the probability distribution over what x_{t-1} could have been?\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x_t.shape\n",
    "        device = x_t.device\n",
    "\n",
    "        posteriors = torch.zeros(batch_size, seq_len, self.num_classes, device=device)\n",
    "\n",
    "        for i, t_val in enumerate(t):\n",
    "            if t_val == 0:\n",
    "                # Special case: t=0 means we're asking for q(x_{-1}|x_0, x_0)\n",
    "                # This doesn't make physical sense, so return uniform or x_0\n",
    "                # In practice, this case shouldn't occur in training\n",
    "                posteriors[i] = F.one_hot(x_0[i], self.num_classes).float()\n",
    "                continue\n",
    "\n",
    "            # Get transition matrices\n",
    "            Q_t = self.Q_t[t_val].to(device)  # [K, K] - single step t\n",
    "            Q_bar_t_minus_1 = self.Q_bar_t[t_val - 1].to(device)  # [K, K] - cumulative to t-1\n",
    "            Q_bar_t = self.Q_bar_t[t_val].to(device)  # [K, K] - cumulative to t\n",
    "\n",
    "            # For each position in sequence\n",
    "            for pos in range(seq_len):\n",
    "                x_0_idx = x_0[i, pos].item()  # Original token index\n",
    "                x_t_idx = x_t[i, pos].item()  # Current token index\n",
    "\n",
    "                # Compute posterior using Bayes rule:\n",
    "                # q(x_{t-1}|x_t,x_0) ∝ q(x_t|x_{t-1},x_0) * q(x_{t-1}|x_0)\n",
    "                #                    = q(x_t|x_{t-1}) * q(x_{t-1}|x_0)  [Markov property]\n",
    "\n",
    "                posterior = torch.zeros(self.num_classes, device=device)\n",
    "\n",
    "                # For each possible value of x_{t-1}\n",
    "                for x_prev_idx in range(self.num_classes):\n",
    "                    # q(x_{t-1}|x_0): probability that x_{t-1} = x_prev_idx given x_0\n",
    "                    q_prev_given_x0 = Q_bar_t_minus_1[x_0_idx, x_prev_idx]\n",
    "\n",
    "                    # q(x_t|x_{t-1}): probability that x_t = x_t_idx given x_{t-1} = x_prev_idx\n",
    "                    q_curr_given_prev = Q_t[x_prev_idx, x_t_idx]\n",
    "\n",
    "                    # Joint probability\n",
    "                    posterior[x_prev_idx] = q_curr_given_prev * q_prev_given_x0\n",
    "\n",
    "                # Normalize to get proper probability distribution\n",
    "                posterior_sum = posterior.sum()\n",
    "                if posterior_sum > 1e-8:\n",
    "                    posterior = posterior / posterior_sum\n",
    "                else:\n",
    "                    # Fallback to uniform if numerical issues\n",
    "                    posterior = torch.ones(self.num_classes, device=device) / self.num_classes\n",
    "\n",
    "                posteriors[i, pos] = posterior\n",
    "\n",
    "        return posteriors\n",
    "\n",
    "    def compute_kl_divergence(self, true_posterior: torch.Tensor, pred_posterior: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute KL[q(x_{t-1}|x_t,x_0) || p_θ(x_{t-1}|x_t)]\"\"\"\n",
    "        kl = torch.sum(true_posterior * (torch.log(true_posterior + 1e-8) - torch.log(pred_posterior + 1e-8)), dim=-1)\n",
    "        return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09635f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d24517b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">t</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: x_0: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span><span style=\"font-weight: bold\">]</span>, x_t: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span><span style=\"font-weight: bold\">]</span>, true x_<span style=\"font-weight: bold\">{</span>t-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span><span style=\"font-weight: bold\">]</span>,\n",
       "equals x_0: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mt\u001b[0m=\u001b[1;36m1\u001b[0m: x_0: \u001b[1m[\u001b[0m\u001b[1;36m42\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m73\u001b[0m\u001b[1m]\u001b[0m, x_t: \u001b[1m[\u001b[0m\u001b[1;36m42\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m73\u001b[0m\u001b[1m]\u001b[0m, true x_\u001b[1m{\u001b[0mt-\u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m42\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m73\u001b[0m\u001b[1m]\u001b[0m,\n",
       "equals x_0: \u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">t</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>: x_0: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span><span style=\"font-weight: bold\">]</span>, x_t: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span><span style=\"font-weight: bold\">]</span>, true x_<span style=\"font-weight: bold\">{</span>t-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span><span style=\"font-weight: bold\">]</span>,\n",
       "equals x_0: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mt\u001b[0m=\u001b[1;36m10\u001b[0m: x_0: \u001b[1m[\u001b[0m\u001b[1;36m42\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m73\u001b[0m\u001b[1m]\u001b[0m, x_t: \u001b[1m[\u001b[0m\u001b[1;36m42\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m73\u001b[0m\u001b[1m]\u001b[0m, true x_\u001b[1m{\u001b[0mt-\u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m42\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m73\u001b[0m\u001b[1m]\u001b[0m,\n",
       "equals x_0: \u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">t</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>: x_0: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span><span style=\"font-weight: bold\">]</span>, x_t: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span><span style=\"font-weight: bold\">]</span>, true x_<span style=\"font-weight: bold\">{</span>t-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span><span style=\"font-weight: bold\">]</span>,\n",
       "equals x_0: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mt\u001b[0m=\u001b[1;36m50\u001b[0m: x_0: \u001b[1m[\u001b[0m\u001b[1;36m42\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m73\u001b[0m\u001b[1m]\u001b[0m, x_t: \u001b[1m[\u001b[0m\u001b[1;36m42\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m73\u001b[0m\u001b[1m]\u001b[0m, true x_\u001b[1m{\u001b[0mt-\u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m42\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m73\u001b[0m\u001b[1m]\u001b[0m,\n",
       "equals x_0: \u001b[3;92mTrue\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">t</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>: x_0: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span><span style=\"font-weight: bold\">]</span>, x_t: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48</span><span style=\"font-weight: bold\">]</span>, true x_<span style=\"font-weight: bold\">{</span>t-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48</span><span style=\"font-weight: bold\">]</span>,\n",
       "equals x_0: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mt\u001b[0m=\u001b[1;36m100\u001b[0m: x_0: \u001b[1m[\u001b[0m\u001b[1;36m42\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m73\u001b[0m\u001b[1m]\u001b[0m, x_t: \u001b[1m[\u001b[0m\u001b[1;36m42\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m48\u001b[0m\u001b[1m]\u001b[0m, true x_\u001b[1m{\u001b[0mt-\u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m42\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m48\u001b[0m\u001b[1m]\u001b[0m,\n",
       "equals x_0: \u001b[3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">t</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>: x_0: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">73</span><span style=\"font-weight: bold\">]</span>, x_t: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">]</span>, true x_<span style=\"font-weight: bold\">{</span>t-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">]</span>,\n",
       "equals x_0: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mt\u001b[0m=\u001b[1;36m500\u001b[0m: x_0: \u001b[1m[\u001b[0m\u001b[1;36m42\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m73\u001b[0m\u001b[1m]\u001b[0m, x_t: \u001b[1m[\u001b[0m\u001b[1;36m20\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m, true x_\u001b[1m{\u001b[0mt-\u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m20\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m,\n",
       "equals x_0: \u001b[3;91mFalse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scheduler = UniformScheduler(num_classes=100, num_timesteps=1000)\n",
    "\n",
    "x_0 = torch.tensor([[42, 15, 73]])  # Original tokens\n",
    "\n",
    "# Check at different timesteps\n",
    "for t_val in [1, 10, 50, 100, 500]:\n",
    "    t = torch.tensor([t_val])\n",
    "    x_t = scheduler.add_noise(x_0, t)\n",
    "\n",
    "    true_posterior = scheduler.get_posterior_params(x_t, x_0, t)\n",
    "    true_prev = true_posterior.argmax(dim=-1)\n",
    "\n",
    "    print(\n",
    "        f\"t={t_val}: x_0: {x_0[0].tolist()}, x_t: {x_t[0].tolist()}, true x_{{t-1}}: {true_prev[0].tolist()},\\nequals x_0: {true_prev[0].equal(x_0[0])}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac5fd249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Testing posterior evolution<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Testing posterior evolution\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evolution of posterior <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">q</span><span style=\"font-weight: bold\">(</span>x_<span style=\"font-weight: bold\">{</span>t-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span> | x_t, x_0<span style=\"font-weight: bold\">)</span> as t increases:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evolution of posterior \u001b[1;35mq\u001b[0m\u001b[1m(\u001b[0mx_\u001b[1m{\u001b[0mt-\u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m | x_t, x_0\u001b[1m)\u001b[0m as t increases:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span>Shows probability of each token being x_<span style=\"font-weight: bold\">{</span>t-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">})</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0mShows probability of each token being x_\u001b[1m{\u001b[0mt-\u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">t</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">x_0</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">x_t</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">P</span><span style=\"font-weight: bold\">(</span>x_<span style=\"font-weight: bold\">{</span>t-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span> = k<span style=\"font-weight: bold\">)</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'0.014'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.644'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.314'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.014'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.014'</span><span style=\"font-weight: bold\">]</span>,Most likely x_<span style=\"font-weight: bold\">{</span>t-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mt\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mx_0\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mx_t\u001b[0m=\u001b[1;36m2\u001b[0m,  \u001b[1;35mP\u001b[0m\u001b[1m(\u001b[0mx_\u001b[1m{\u001b[0mt-\u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m = k\u001b[1m)\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'0.014'\u001b[0m, \u001b[32m'0.644'\u001b[0m, \u001b[32m'0.314'\u001b[0m, \u001b[32m'0.014'\u001b[0m, \u001b[32m'0.014'\u001b[0m\u001b[1m]\u001b[0m,Most likely x_\u001b[1m{\u001b[0mt-\u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m: \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">t</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">x_0</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">x_t</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">P</span><span style=\"font-weight: bold\">(</span>x_<span style=\"font-weight: bold\">{</span>t-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span> = k<span style=\"font-weight: bold\">)</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'0.444'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.461'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.032'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.032'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.032'</span><span style=\"font-weight: bold\">]</span>,Most likely x_<span style=\"font-weight: bold\">{</span>t-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mt\u001b[0m=\u001b[1;36m2\u001b[0m, \u001b[33mx_0\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mx_t\u001b[0m=\u001b[1;36m0\u001b[0m,  \u001b[1;35mP\u001b[0m\u001b[1m(\u001b[0mx_\u001b[1m{\u001b[0mt-\u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m = k\u001b[1m)\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'0.444'\u001b[0m, \u001b[32m'0.461'\u001b[0m, \u001b[32m'0.032'\u001b[0m, \u001b[32m'0.032'\u001b[0m, \u001b[32m'0.032'\u001b[0m\u001b[1m]\u001b[0m,Most likely x_\u001b[1m{\u001b[0mt-\u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m: \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">t</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #808000; text-decoration-color: #808000\">x_0</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">x_t</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">P</span><span style=\"font-weight: bold\">(</span>x_<span style=\"font-weight: bold\">{</span>t-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span> = k<span style=\"font-weight: bold\">)</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'0.052'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.342'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.052'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.052'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.502'</span><span style=\"font-weight: bold\">]</span>,Most likely x_<span style=\"font-weight: bold\">{</span>t-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mt\u001b[0m=\u001b[1;36m3\u001b[0m, \u001b[33mx_0\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mx_t\u001b[0m=\u001b[1;36m4\u001b[0m,  \u001b[1;35mP\u001b[0m\u001b[1m(\u001b[0mx_\u001b[1m{\u001b[0mt-\u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m = k\u001b[1m)\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'0.052'\u001b[0m, \u001b[32m'0.342'\u001b[0m, \u001b[32m'0.052'\u001b[0m, \u001b[32m'0.052'\u001b[0m, \u001b[32m'0.502'\u001b[0m\u001b[1m]\u001b[0m,Most likely x_\u001b[1m{\u001b[0mt-\u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m: \u001b[1;36m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">t</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #808000; text-decoration-color: #808000\">x_0</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">x_t</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">P</span><span style=\"font-weight: bold\">(</span>x_<span style=\"font-weight: bold\">{</span>t-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span> = k<span style=\"font-weight: bold\">)</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'0.035'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.859'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.035'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.035'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.035'</span><span style=\"font-weight: bold\">]</span>,Most likely x_<span style=\"font-weight: bold\">{</span>t-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mt\u001b[0m=\u001b[1;36m4\u001b[0m, \u001b[33mx_0\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mx_t\u001b[0m=\u001b[1;36m1\u001b[0m,  \u001b[1;35mP\u001b[0m\u001b[1m(\u001b[0mx_\u001b[1m{\u001b[0mt-\u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m = k\u001b[1m)\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'0.035'\u001b[0m, \u001b[32m'0.859'\u001b[0m, \u001b[32m'0.035'\u001b[0m, \u001b[32m'0.035'\u001b[0m, \u001b[32m'0.035'\u001b[0m\u001b[1m]\u001b[0m,Most likely x_\u001b[1m{\u001b[0mt-\u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m: \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">t</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">x_0</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">x_t</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">P</span><span style=\"font-weight: bold\">(</span>x_<span style=\"font-weight: bold\">{</span>t-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span> = k<span style=\"font-weight: bold\">)</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'0.067'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.732'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.067'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.067'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0.067'</span><span style=\"font-weight: bold\">]</span>,Most likely x_<span style=\"font-weight: bold\">{</span>t-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mt\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33mx_0\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mx_t\u001b[0m=\u001b[1;36m1\u001b[0m,  \u001b[1;35mP\u001b[0m\u001b[1m(\u001b[0mx_\u001b[1m{\u001b[0mt-\u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m = k\u001b[1m)\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'0.067'\u001b[0m, \u001b[32m'0.732'\u001b[0m, \u001b[32m'0.067'\u001b[0m, \u001b[32m'0.067'\u001b[0m, \u001b[32m'0.067'\u001b[0m\u001b[1m]\u001b[0m,Most likely x_\u001b[1m{\u001b[0mt-\u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m: \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Test that posterior evolves correctly as we move through timesteps.\"\"\"\n",
    "print(\"Testing posterior evolution...\")\n",
    "\n",
    "vocab_size = 5  # Very small for clear visualization\n",
    "scheduler = UniformScheduler(num_classes=vocab_size, num_timesteps=10, beta_start=0.1, beta_end=0.9)\n",
    "\n",
    "x_0 = torch.tensor([[1]])  # Single token, original = 1\n",
    "\n",
    "print(\"Evolution of posterior q(x_{t-1} | x_t, x_0) as t increases:\")\n",
    "print(\"(Shows probability of each token being x_{t-1})\")\n",
    "print()\n",
    "\n",
    "for t_val in range(1, 6):\n",
    "    t = torch.tensor([t_val])\n",
    "    x_t = scheduler.add_noise(x_0, t)\n",
    "    posterior = scheduler.get_posterior_params(x_t, x_0, t)\n",
    "    true_prev = posterior.argmax(dim=-1)\n",
    "\n",
    "    print(\n",
    "        f\"t={t_val}, x_0=1, x_t={x_t[0, 0].item()},  P(x_{{t-1}} = k): {[f'{p:.3f}' for p in posterior[0, 0].tolist()]},Most likely x_{{t-1}}: {posterior[0, 0].argmax().item()}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f727c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| inp.shape: torch.Size([8, 20])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Ya know I just couldn ’ t make it by myself <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Ya know I just couldn ’ t make it by myself \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Ya know I just couldn ill t make it by myself <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> aist <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Ya know I just couldn ill t make it by myself \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m aist \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Ya blues Ke just couldn ’ t make it by myself watered <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> mankind <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> beer\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Ya blues Ke just couldn ’ t make it by myself watered \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m mankind \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m beer\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">swall know sight Señor ched ’ t army it by stories <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> nob <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span> Reed <span style=\"font-weight: bold\">[</span>PAD<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "swall know sight Señor ched ’ t army it by stories \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m nob \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m Reed \u001b[1m[\u001b[0mPAD\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate some noisy sentences\n",
    "inp = next(iter(dataloader)).to(device)\n",
    "ic(inp.shape)\n",
    "\n",
    "ds_scheduler = UniformScheduler(num_classes=len(tokenizer), num_timesteps=30)\n",
    "\n",
    "\n",
    "def demo_noise(inp, line_nb, step):\n",
    "    src_line = tokenizer.decode(inp[line_nb].cpu().numpy())\n",
    "    noisy_inp = ds_scheduler.add_noise(inp[line_nb : line_nb + 1], torch.tensor([step]).to(device))\n",
    "    noisy_line = tokenizer.decode(noisy_inp[0].cpu().numpy())\n",
    "    return src_line, noisy_line\n",
    "\n",
    "\n",
    "ic.disable()\n",
    "ic.enable()\n",
    "sent_nb = 4\n",
    "print(demo_noise(inp, sent_nb, 0)[1])\n",
    "print(demo_noise(inp, sent_nb, 12)[1])\n",
    "print(demo_noise(inp, sent_nb, 20)[1])\n",
    "print(demo_noise(inp, sent_nb, 29)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4de9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleD3PMModel(nn.Module):\n",
    "    \"\"\"Simple transformer model for D3PM.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        max_seq_len: int,\n",
    "        d_model: int = 256,\n",
    "        num_heads: int = 8,\n",
    "        num_layers: int = 4,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Embeddings\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_embedding = nn.Embedding(max_seq_len, d_model)\n",
    "\n",
    "        # Time embedding for diffusion timestep\n",
    "        self.time_embedding = nn.Sequential(nn.Linear(d_model, d_model), nn.GELU(), nn.Linear(d_model, d_model))\n",
    "\n",
    "        # Transformer layers\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=4 * d_model,\n",
    "            dropout=dropout,\n",
    "            activation=\"gelu\",\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "\n",
    "        # Output head to predict x₀\n",
    "        self.output_head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, vocab_size))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def _get_time_embedding(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Create sinusoidal time embeddings like in original Transformer.\"\"\"\n",
    "        half_dim = self.d_model // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=t.device, dtype=torch.float32) * -emb)\n",
    "        emb = t.float()[:, None] * emb[None, :]\n",
    "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "\n",
    "        if self.d_model % 2 == 1:  # Handle odd d_model\n",
    "            emb = torch.cat([emb, torch.zeros_like(emb[:, :1])], dim=1)\n",
    "\n",
    "        return self.time_embedding(emb)\n",
    "\n",
    "    def forward(self, x_t: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass: predict x₀ from x_t.\n",
    "\n",
    "        Args:\n",
    "            x_t: Noisy tokens, shape [batch_size, seq_len]\n",
    "            t: Timesteps, shape [batch_size]\n",
    "\n",
    "        Returns:\n",
    "            x0_logits: Predicted x₀ logits, shape [batch_size, seq_len, vocab_size]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x_t.shape\n",
    "        device = x_t.device\n",
    "\n",
    "        # Token embeddings\n",
    "        token_emb = self.token_embedding(x_t)  # [B, L, D]\n",
    "\n",
    "        # Position embeddings\n",
    "        positions = torch.arange(seq_len, device=device).unsqueeze(0).expand(batch_size, -1)\n",
    "        pos_emb = self.position_embedding(positions)  # [B, L, D]\n",
    "\n",
    "        # Time embeddings\n",
    "        time_emb = self._get_time_embedding(t)  # [B, D]\n",
    "        time_emb = time_emb.unsqueeze(1).expand(-1, seq_len, -1)  # [B, L, D]\n",
    "\n",
    "        # Combine all embeddings\n",
    "        x = self.dropout(token_emb + pos_emb + time_emb)  # [B, L, D]\n",
    "\n",
    "        # Transformer processing\n",
    "        x = self.transformer(x)  # [B, L, D]\n",
    "\n",
    "        # Predict x₀ logits\n",
    "        x0_logits = self.output_head(x)  # [B, L, vocab_size]\n",
    "\n",
    "        return x0_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0a19a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_predicted_posterior(\n",
    "    scheduler: UniformScheduler, x0_logits: torch.Tensor, x_t: torch.Tensor, t: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute p_θ(x_{t-1}|x_t) using x₀-parameterization.\n",
    "\n",
    "    From Equation 4: p_θ(x_{t-1}|x_t) ∝ Σ q(x_{t-1},x_t|x̃₀) p̃_θ(x̃₀|x_t)\n",
    "    \"\"\"\n",
    "    batch_size, seq_len = x_t.shape\n",
    "    device = x_t.device\n",
    "\n",
    "    # Convert model logits to probabilities\n",
    "    p_x0_given_xt = F.softmax(x0_logits, dim=-1)  # [B, L, K]\n",
    "\n",
    "    pred_posteriors = torch.zeros(batch_size, seq_len, scheduler.num_classes, device=device)\n",
    "\n",
    "    for i, t_val in enumerate(t):\n",
    "        if t_val == 0:\n",
    "            # At t=0, just return the x₀ prediction\n",
    "            pred_posteriors[i] = p_x0_given_xt[i]\n",
    "            continue\n",
    "\n",
    "        # Get transition matrix Q_t\n",
    "        Q_t = scheduler.Q_t[t_val].to(device)  # [K, K]\n",
    "\n",
    "        # For each position, marginalize over possible x₀ values\n",
    "        for pos in range(seq_len):\n",
    "            p_x0_pos = p_x0_given_xt[i, pos]  # [K] - predicted x₀ distribution\n",
    "\n",
    "            # Get current token\n",
    "            x_t_pos = x_t[i, pos].item()\n",
    "\n",
    "            # Marginalize: p_θ(x_{t-1}|x_t) = Σ p(x_{t-1}|x_t,x₀) p_θ(x₀|x_t)\n",
    "            pred_posterior = torch.zeros(scheduler.num_classes, device=device)\n",
    "\n",
    "            for x0_idx in range(scheduler.num_classes):\n",
    "                # Weight by predicted probability of this x₀\n",
    "                weight = p_x0_pos[x0_idx]\n",
    "\n",
    "                # For this x₀, what's p(x_{t-1}|x_t,x₀)?\n",
    "                # This is like the true posterior but conditioned on specific x₀\n",
    "\n",
    "                # Simplified: if x₀ was token k, then x_{t-1} was likely k\n",
    "                # (since uniform transitions are symmetric)\n",
    "                for x_prev in range(scheduler.num_classes):\n",
    "                    # Probability that x_{t-1}=x_prev leads to x_t given x₀=x0_idx\n",
    "                    prob_prev_to_curr = Q_t[x_prev, x_t_pos]\n",
    "                    pred_posterior[x_prev] += weight * prob_prev_to_curr\n",
    "\n",
    "            # Normalize\n",
    "            pred_posterior = pred_posterior / (pred_posterior.sum() + 1e-8)\n",
    "            pred_posteriors[i, pos] = pred_posterior\n",
    "\n",
    "    return pred_posteriors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a5fb805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jkunz/Projects/transformer_implementations/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n",
      "ic| x0_logits.shape: torch.Size([1, 3, 100])\n",
      "ic| true_posterior.shape: torch.Size([1, 3, 100])\n",
      "ic| pred_posterior.shape: torch.Size([1, 3, 100])\n",
      "ic| kl_terms.shape: torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Training step on a single batch. \"\"\"\n",
    "\n",
    "\n",
    "def training_step(\n",
    "    scheduler: UniformScheduler, model: SimpleD3PMModel, x_0: torch.Tensor, t: torch.Tensor\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    x_t = scheduler.add_noise(x_0, t)\n",
    "    x0_logits = model(x_t, t)\n",
    "    ic(x0_logits.shape)\n",
    "    true_posterior = scheduler.get_posterior_params(x_t, x_0, t)\n",
    "    ic(true_posterior.shape)\n",
    "    pred_posterior = compute_predicted_posterior(scheduler=scheduler, x0_logits=x0_logits, x_t=x_t, t=t)\n",
    "    ic(pred_posterior.shape)\n",
    "\n",
    "    kl_terms = scheduler.compute_kl_divergence(true_posterior, pred_posterior)\n",
    "    ic(kl_terms.shape)\n",
    "    return x0_logits, kl_terms\n",
    "\n",
    "\n",
    "scheduler = UniformScheduler(num_classes=100, num_timesteps=10, beta_start=0.1, beta_end=0.9)\n",
    "x_0 = torch.tensor([[42, 15, 73]])\n",
    "model = SimpleD3PMModel(vocab_size=100, max_seq_len=10, d_model=64, num_heads=1, num_layers=1)\n",
    "t = torch.tensor([3])\n",
    "\n",
    "x0_logits, kl_terms = training_step(scheduler, model, x_0, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7e5584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06137f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33d0f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211eecdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff21f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| F.cross_entropy(pred.view(-1, 3), x_0.view(-1), reduction=\"mean\"): tensor(0., device='mps:0')\n",
      "| F.cross_entropy(pred.view(-1, 3), x_0.view(-1), reduction=\"mean\"): tensor(0., device='mps:0')\n",
      "ic| psm: tensor([[[1., 0., 0.],\n",
      "                  [0., 1., 0.],\n",
      "                  [0., 0., 1.]],ic| psm: tensor([[[1., 0., 0.],\n",
      "                  [0., 1., 0.],\n",
      "                  [0., 0., 1.]],\n",
      "         \n",
      "                 [[0., 0., 1.],\n",
      "\n",
      "         \n",
      "                 [[0., 0., 1.],\n",
      "                  [0., 1., 0.],\n",
      "                  [1., 0., 0.]]], device='mps:0')\n",
      "    psm.shape: torch.Size([2, 3, 3]                  [0., 1., 0.],\n",
      "                  [1., 0., 0.]]], device='mps:0')\n",
      "    psm.shape: torch.Size([2, 3, 3])\n",
      ")\n",
      "ic| x_0_onehot: tensor([[[1., 0., 0.],\n",
      "                         ic| x_0_onehot: tensor([[[1., 0., 0.],\n",
      "                         [0., 1., 0.],\n",
      "                         [0., 0., 1.]],\n",
      "                \n",
      "                        [[0., 0., 1.],\n",
      "                         [0., 1.,[0., 1., 0.],\n",
      "                         [0., 0., 1.]],\n",
      "                \n",
      "                        [[0., 0., 1.],\n",
      "                         [0., 1., 0.],\n",
      "                         [1., 0., 0.]]], device='mps:0')\n",
      "    x_0_onehot.shape: torch. 0.],\n",
      "                         [1., 0., 0.]]], device='mps:0')\n",
      "    x_0_onehot.shape: torch.Size([2, 3, 3])\n",
      "Size([2, 3, 3])\n",
      "ic| neg_log_likelihood: tensor([[-0., -0., -0.],\n",
      "                                [ic| neg_log_likelihood: tensor([[-0., -0., -0.],\n",
      "                                [-0., -0., -0.]], device='mps:0')\n",
      "    neg_log_likelihood.shape: torch.Size([2, 3])\n",
      "-0., -0., -0.]], device='mps:0')\n",
      "    neg_log_likelihood.shape: torch.Size([2, 3])\n",
      "ic| neg_log_likelihood.mean(): tensor(0., device='mps:0')\n",
      "ic| neg_log_likelihood.mean(): tensor(0., device='mps:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0., device='mps:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross entropy loss computation\n",
    "\n",
    "x_0 = torch.tensor([[0, 1, 2], [2, 1, 0]]).long().to(device)  # Use long for indices\n",
    "# preds are logits\n",
    "pred_logit = (\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [[1000, 0, 0], [0, 1000, 0], [0, 0, 1000]],\n",
    "            [[0, 0, 1000], [0, 1000, 0], [1000, 0, 0]],\n",
    "        ]\n",
    "    )\n",
    "    .float()\n",
    "    .to(device)\n",
    ")\n",
    "\n",
    "# For cross-entropy, pred needs to be reshaped to [batch*seq, num_classes]\n",
    "ic(F.cross_entropy(pred_logit.view(-1, 3), x_0.view(-1), reduction=\"mean\"))\n",
    "\n",
    "# For the manual computation, convert x_0 to one-hot encoding\n",
    "psm = F.softmax(pred_logit, dim=-1)  # Apply softmax over the last dimension (classes)\n",
    "ic(psm, psm.shape)\n",
    "\n",
    "# Convert x_0 to one-hot encoding\n",
    "x_0_onehot = F.one_hot(x_0, num_classes=3).float()  # Shape: [2, 3, 3]\n",
    "ic(x_0_onehot, x_0_onehot.shape)\n",
    "\n",
    "# Now compute the negative log likelihood\n",
    "neg_log_likelihood = -torch.sum(x_0_onehot * torch.log(psm + 1e-10), dim=-1)\n",
    "ic(neg_log_likelihood, neg_log_likelihood.shape)\n",
    "ic(neg_log_likelihood.mean())  # Mean over the sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50a86e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| model_logits.shape: torch.Size([2, 3, 10])\n",
      "| model_logits.shape: torch.Size([2, 3, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy data\n",
    "num_classes = 10\n",
    "num_timesteps = 5\n",
    "batch_size = 2\n",
    "seq_len = 3\n",
    "x_0 = torch.randint(0, num_classes, (batch_size, seq_len))  # Clean data\n",
    "x_t = torch.randint(0, num_classes, (batch_size, seq_len))  # Noisy data\n",
    "t = torch.randint(0, num_timesteps, (batch_size,))  # Timesteps\n",
    "\n",
    "# Model prediction (logits for p̃_θ(x̃_0|x_t))\n",
    "model_logits = torch.randn(batch_size, seq_len, num_classes)\n",
    "ic(model_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6238710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "class D3PMLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    D3PM Loss Function: L_λ = L_vb + λ * auxiliary_loss\n",
    "\n",
    "    Implements the hybrid loss from Equation 5 in the D3PM paper.\n",
    "    This is a simplified version that expects the model to handle\n",
    "    the complex posterior computations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lambda_weight: float = 0.001, use_auxiliary_loss: bool = True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lambda_weight = lambda_weight\n",
    "        self.use_auxiliary_loss = use_auxiliary_loss\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        model_x0_logits: torch.Tensor,  # Model's prediction of p̃_θ(x̃_0|x_t)\n",
    "        model_kl_terms: torch.Tensor,  # Pre-computed KL divergence terms\n",
    "        x_0: torch.Tensor,  # Original clean data\n",
    "        t: torch.Tensor,  # Timesteps\n",
    "        mask: Optional[torch.Tensor] = None,\n",
    "    ) -> tuple[torch.Tensor, dict]:\n",
    "        \"\"\"\n",
    "        Compute D3PM loss.\n",
    "\n",
    "        Args:\n",
    "            model_x0_logits: Model's logits for p̃_θ(x̃_0|x_t), shape [B, ..., K]\n",
    "            model_kl_terms: Pre-computed KL terms from model, shape [B, ...]\n",
    "            x_0: Clean data for auxiliary loss, shape [B, ...]\n",
    "            t: Timesteps, shape [B]\n",
    "            mask: Optional mask for sequence padding, shape [B, ...]\n",
    "\n",
    "        Returns:\n",
    "            loss: Total loss scalar\n",
    "            loss_dict: Dictionary with loss components\n",
    "        \"\"\"\n",
    "\n",
    "        # 1. Auxiliary loss: E[-log p̃_θ(x_0|x_t)]\n",
    "        auxiliary_loss = self._compute_auxiliary_loss(model_x0_logits, x_0, mask)\n",
    "\n",
    "        # 2. Variational bound loss: Use pre-computed KL terms from model\n",
    "        vb_loss = model_kl_terms.mean()\n",
    "\n",
    "        # 3. Combine losses\n",
    "        if self.use_auxiliary_loss:\n",
    "            total_loss = vb_loss + self.lambda_weight * auxiliary_loss\n",
    "        else:\n",
    "            total_loss = vb_loss\n",
    "\n",
    "        loss_dict = {\n",
    "            \"total_loss\": total_loss,\n",
    "            \"vb_loss\": vb_loss,\n",
    "            \"auxiliary_loss\": auxiliary_loss,\n",
    "            \"weighted_auxiliary\": self.lambda_weight * auxiliary_loss,\n",
    "        }\n",
    "\n",
    "        return total_loss, loss_dict\n",
    "\n",
    "    def _compute_auxiliary_loss(\n",
    "        self,\n",
    "        model_logits: torch.Tensor,  # [B, ..., K]\n",
    "        x_0: torch.Tensor,  # [B, ...]\n",
    "        mask: Optional[torch.Tensor] = None,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute auxiliary denoising loss: -log p̃_θ(x_0|x_t)\n",
    "        \"\"\"\n",
    "        # Flatten all but last dimension for cross entropy\n",
    "        flat_logits = model_logits.view(-1, model_logits.size(-1))  # [B*N, K]\n",
    "        flat_targets = x_0.view(-1).long()  # [B*N]\n",
    "\n",
    "        # Compute cross entropy loss\n",
    "        ce_loss = F.cross_entropy(flat_logits, flat_targets, reduction=\"none\")  # [B*N]\n",
    "\n",
    "        if mask is not None:\n",
    "            flat_mask = mask.view(-1).float()  # [B*N]\n",
    "            ce_loss = ce_loss * flat_mask\n",
    "            return ce_loss.sum() / (flat_mask.sum() + 1e-8)\n",
    "        else:\n",
    "            return ce_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de16ce78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9cab4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class D3pmDiffusion(nn.Module):\n",
    "    \"\"\"Implementation of uniform transition with linear beta schedule\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, num_discrete_states: int, num_timesteps: int = 1000, beta_start: float = 0.0001, beta_end: float = 0.02\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_discrete_states = num_discrete_states\n",
    "        self.num_timesteps = num_timesteps\n",
    "\n",
    "        # More conservative beta schedule\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alpha_bars = torch.cumprod(self.alphas, dim=0)\n",
    "\n",
    "        # Precompute transition matrices\n",
    "        self.transition_matrices_t = nn.ParameterList()\n",
    "        self.cumulative_transition_matrices_t = nn.ParameterList()\n",
    "\n",
    "        Q_prev_cumulative = torch.eye(num_discrete_states)\n",
    "\n",
    "        for t in range(num_timesteps):\n",
    "            beta = self.betas[t].item()\n",
    "\n",
    "            # More conservative transition matrix\n",
    "            diag_prob = 1.0 - beta\n",
    "            off_diag_prob = beta / (num_discrete_states - 1) if num_discrete_states > 1 else 0.0\n",
    "\n",
    "            Q_t = torch.eye(num_discrete_states) * diag_prob\n",
    "            Q_t = (\n",
    "                Q_t\n",
    "                + (torch.ones(num_discrete_states, num_discrete_states) - torch.eye(num_discrete_states))\n",
    "                * off_diag_prob\n",
    "            )\n",
    "            Q_t = Q_t / Q_t.sum(dim=1, keepdim=True)\n",
    "\n",
    "            self.transition_matrices_t.append(nn.Parameter(Q_t, requires_grad=False))\n",
    "\n",
    "            Q_current_cumulative = torch.matmul(Q_t, Q_prev_cumulative)\n",
    "            self.cumulative_transition_matrices_t.append(nn.Parameter(Q_current_cumulative, requires_grad=False))\n",
    "            Q_prev_cumulative = Q_current_cumulative\n",
    "\n",
    "    def forward(self, x_0: torch.Tensor, t: torch.Tensor):\n",
    "        \"\"\"Forward diffusion process\"\"\"\n",
    "        original_shape = x_0.shape\n",
    "        batch_size = original_shape[0]\n",
    "        x_flat = x_0.view(batch_size, -1)\n",
    "        num_elements = x_flat.shape[1]\n",
    "\n",
    "        # Convert to one-hot encoding\n",
    "        x_one_hot = F.one_hot(x_flat, num_classes=self.num_discrete_states).float()\n",
    "\n",
    "        # Gather transition matrices for batch\n",
    "        Q_bar_t_batch = torch.stack([self.cumulative_transition_matrices_t[idx] for idx in t])\n",
    "\n",
    "        # Apply transition\n",
    "        next_state_probs = torch.bmm(x_one_hot, Q_bar_t_batch)\n",
    "\n",
    "        # Sample from categorical distribution\n",
    "        x_t = torch.multinomial(next_state_probs.view(-1, self.num_discrete_states), num_samples=1).squeeze(dim=1)\n",
    "        x_t = x_t.view(original_shape)\n",
    "\n",
    "        return x_t\n",
    "\n",
    "    def compute_loss(self, x_0: torch.Tensor, predicted_logits: torch.Tensor, t: torch.Tensor, pad_token_id: int = 0):\n",
    "        \"\"\"Compute proper D3PM loss with padding mask\"\"\"\n",
    "        batch_size, seq_len = x_0.shape\n",
    "\n",
    "        # Create padding mask\n",
    "        pad_mask = (x_0 != pad_token_id).float()  # 1 for real tokens, 0 for padding\n",
    "\n",
    "        # Compute cross-entropy loss\n",
    "        ic(predicted_logits.view(-1, self.num_discrete_states).shape)\n",
    "        ic(x_0.view(-1).shape)\n",
    "        loss = F.cross_entropy(predicted_logits.view(-1, self.num_discrete_states), x_0.view(-1), reduction=\"none\")\n",
    "\n",
    "        # Apply padding mask\n",
    "        loss = loss.view(batch_size, seq_len)\n",
    "        masked_loss = loss * pad_mask\n",
    "\n",
    "        # Average over non-padded tokens\n",
    "        total_loss = masked_loss.sum() / pad_mask.sum().clamp(min=1)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "\n",
    "# Define parameters\n",
    "NUM_STATES = len(tokenizer)  # e.g., pixel values 0, 1, 2, 3\n",
    "NUM_CLASSES = len(tokenizer)  # Number of discrete states (e.g., vocabulary size)\n",
    "BETA_PER_STEP = 0.2  # Probability of changing state at each step\n",
    "NUM_TIMESTEPS = 2  # Number of diffusion steps\n",
    "# Create the forward diffusion module\n",
    "forward_diffuser = D3pmDiffusion(num_discrete_states=NUM_CLASSES, num_timesteps=NUM_TIMESTEPS).to(device)\n",
    "# x_0 = torch.tensor([[0, 1, 2], [2, 1, 0]]).to(device)\n",
    "# pred = torch.tensor([[[1, 0, 0], [0, 1, 0], [0, 0, 1]], [[0, 0, 1], [0, 1, 0], [1, 0, 0]]]).to(device)\n",
    "# forward_diffuser.compute_loss(x_0, pred, torch.tensor([0]).to(device), pad_token_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6c16e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 0., 0.,  ..., 0., 0., 0.]]], device='mps:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = next(iter(dataloader)).to(device)\n",
    "\n",
    "F.one_hot(inp, num_classes=len(tokenizer)).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd03ac10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| inp.shape: torch.Size([8, 20])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just you and me [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 12 is out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m sent_nb = \u001b[32m4\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(demo_noise(inp, sent_nb, \u001b[32m0\u001b[39m)[\u001b[32m1\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdemo_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msent_nb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m])\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(demo_noise(inp, sent_nb, \u001b[32m20\u001b[39m)[\u001b[32m1\u001b[39m])\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# print(demo_noise(inp, sent_nb, 99)[1])\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mdemo_noise\u001b[39m\u001b[34m(inp, line_nb, step)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdemo_noise\u001b[39m(inp, line_nb, step):\n\u001b[32m      6\u001b[39m     src_line = tokenizer.decode(inp[line_nb].cpu().numpy())\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     noisy_inp = \u001b[43mforward_diffuser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mline_nb\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_nb\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     noisy_line = tokenizer.decode(noisy_inp[\u001b[32m0\u001b[39m].cpu().numpy())\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m src_line, noisy_line\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mD3pmDiffusion.forward\u001b[39m\u001b[34m(self, x_0, t)\u001b[39m\n\u001b[32m     51\u001b[39m x_one_hot = F.one_hot(x_flat, num_classes=\u001b[38;5;28mself\u001b[39m.num_discrete_states).float()\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Gather transition matrices for batch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m Q_bar_t_batch = torch.stack([\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcumulative_transition_matrices_t\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m t])\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Apply transition\u001b[39;00m\n\u001b[32m     57\u001b[39m next_state_probs = torch.bmm(x_one_hot, Q_bar_t_batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/transformer_implementations/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:640\u001b[39m, in \u001b[36mParameterList.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m     idx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_abs_string_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(idx))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/transformer_implementations/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:619\u001b[39m, in \u001b[36mParameterList._get_abs_string_index\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    617\u001b[39m idx = operator.index(idx)\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (-\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) <= idx < \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mindex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is out of range\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m idx < \u001b[32m0\u001b[39m:\n\u001b[32m    621\u001b[39m     idx += \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: index 12 is out of range"
     ]
    }
   ],
   "source": [
    "inp = next(iter(dataloader)).to(device)\n",
    "ic(inp.shape)\n",
    "\n",
    "\n",
    "def demo_noise(inp, line_nb, step):\n",
    "    src_line = tokenizer.decode(inp[line_nb].cpu().numpy())\n",
    "    noisy_inp = forward_diffuser.forward(inp[line_nb : line_nb + 1], torch.tensor([step]).to(device))\n",
    "    noisy_line = tokenizer.decode(noisy_inp[0].cpu().numpy())\n",
    "    return src_line, noisy_line\n",
    "\n",
    "\n",
    "ic.disable()\n",
    "ic.enable()\n",
    "sent_nb = 4\n",
    "print(demo_noise(inp, sent_nb, 0)[1])\n",
    "print(demo_noise(inp, sent_nb, 12)[1])\n",
    "print(demo_noise(inp, sent_nb, 20)[1])\n",
    "# print(demo_noise(inp, sent_nb, 99)[1])\n",
    "\n",
    "forward_diffuser.compute_loss(\n",
    "    inp,\n",
    "    F.one_hot(inp, num_classes=len(tokenizer)).float(),\n",
    "    torch.tensor([0]).to(device),\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13a12987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, t):\n",
    "        half = self.lin.in_features // 2\n",
    "        freqs = torch.exp(-math.log(10000) * torch.arange(half, dtype=torch.float32) / half).to(t.device)\n",
    "        args = t[:, None].float() * freqs[None]\n",
    "        emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "        return self.lin(emb)\n",
    "\n",
    "\n",
    "class DiffusionTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, seq_len, dim=512, heads=8, layers=6):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, dim)\n",
    "        self.pos_emb = nn.Embedding(seq_len, dim)\n",
    "        self.time_emb = TimeEmbedding(dim)\n",
    "        enc_layer = nn.TransformerEncoderLayer(dim, heads, dim * 4)\n",
    "        self.transformer = nn.TransformerEncoder(enc_layer, layers)\n",
    "        self.to_logits = nn.Linear(dim, vocab_size)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        B, L = x.shape\n",
    "        tok = self.token_emb(x)\n",
    "        pos = self.pos_emb(torch.arange(L, device=x.device))\n",
    "        temb = self.time_emb(t).unsqueeze(1)\n",
    "        h = tok + pos + temb\n",
    "        h = self.transformer(h.transpose(0, 1)).transpose(0, 1)\n",
    "        return self.to_logits(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "545b5027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length in dataset: 40\n",
      "Max sequence length in dataset: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jkunz/Projects/transformer_implementations/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "import os\n",
    "\n",
    "# Hyperparameters\n",
    "seq_len = 20\n",
    "batch_size = 32\n",
    "num_epochs = 1  # 30\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-5  # Added weight decay\n",
    "vocab_size = tokenizer.vocab_size\n",
    "num_timesteps = 100\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = SimpleDylanDataset(lines, tokenizer, seq_len=seq_len)\n",
    "dataset = SimpleDylanDataset(lines[:100], tokenizer, seq_len=seq_len)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Instantiate models\n",
    "diffuser = D3pmDiffusion(num_discrete_states=vocab_size, num_timesteps=num_timesteps).to(device)\n",
    "model = DiffusionTransformer(vocab_size=vocab_size, seq_len=seq_len).to(device)\n",
    "\n",
    "# Enhanced optimizer with weight decay\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Adaptive learning rate scheduler\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=3, T_mult=2, eta_min=1e-6)\n",
    "# Alternative: ReduceLROnPlateau for validation-based scheduling\n",
    "# scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ca3fc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard logs will be saved to: ../runs/d3pm_training_20250607_185216\n",
      "To view logs, run: tensorboard --logdir ../runs/d3pm_training_20250607_185216\n",
      "\n",
      "Starting enhanced training loop...\n",
      "Model parameters: 24,312,200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb147ad1cff47c1aa24d15b3ae7f351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| predicted_logits.view(-1, self.num_discrete_states).shape: torch.Size([640, 5000])\n",
      "ic| x_0.view(-1).shape: torch.Size([640])\n",
      "ic| predicted_logits.view(-1, self.num_discrete_states).shape: torch.Size([640, 5000])\n",
      "ic| x_0.view(-1).shape: torch.Size([640])\n",
      "ic| predicted_logits.view(-1, self.num_discrete_states).shape: torch.Size([640, 5000])\n",
      "ic| x_0.view(-1).shape: torch.Size([640])\n",
      "ic| predicted_logits.view(-1, self.num_discrete_states).shape: torch.Size([80, 5000])\n",
      "ic| x_0.view(-1).shape: torch.Size([80])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved with loss: 7.9962\n",
      "Epoch 1/1 completed:\n",
      "  Average Loss: 7.9962\n",
      "  Learning Rate: 1.00e-04\n",
      "  Global Step: 4\n",
      "\n",
      "Training complete!\n",
      "Final model saved: ../models/d3pm_final_2_0.pth\n",
      "Best loss achieved: 7.9962\n",
      "Total training steps: 4\n",
      "TensorBoard logs: ../runs/d3pm_training_20250607_185216\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TensorBoard setup\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_dir = f\"../runs/d3pm_training_{timestamp}\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "print(f\"TensorBoard logs will be saved to: {log_dir}\")\n",
    "print(f\"To view logs, run: tensorboard --logdir {log_dir}\")\n",
    "\n",
    "\n",
    "model_name = \"d3pm\"\n",
    "version = \"2_0\"  # Updated version with enhancements\n",
    "do_train = True\n",
    "\n",
    "if do_train:\n",
    "    print(\"\\nStarting enhanced training loop...\")\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "    global_step = 0\n",
    "    best_loss = float(\"inf\")\n",
    "\n",
    "    # Training metrics tracking\n",
    "    train_losses = []\n",
    "    learning_rates = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        # Progress bar for batches\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        for batch_idx, batch_x_0 in enumerate(pbar):\n",
    "            batch_x_0 = batch_x_0.to(device)\n",
    "            batch_size_actual = batch_x_0.shape[0]\n",
    "\n",
    "            # Sample random timesteps\n",
    "            timesteps = torch.randint(0, num_timesteps, (batch_size_actual,), device=device)\n",
    "\n",
    "            # Forward diffusion process\n",
    "            x_t = diffuser(batch_x_0, timesteps)\n",
    "\n",
    "            predicted_logits = model(x_t, timesteps)\n",
    "            loss = diffuser.compute_loss(batch_x_0, predicted_logits, timesteps, pad_token_id=tokenizer.pad_token_id)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping for stability\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update metrics\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            global_step += 1\n",
    "\n",
    "            # Get current learning rate\n",
    "            current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "            # Log to TensorBoard (every 10 steps to avoid too much logging)\n",
    "            if global_step % 10 == 0:\n",
    "                writer.add_scalar(\"Loss/Batch\", loss.item(), global_step)\n",
    "                writer.add_scalar(\"Learning_Rate\", current_lr, global_step)\n",
    "                writer.add_scalar(\n",
    "                    \"Gradient_Norm\",\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=float(\"inf\")),\n",
    "                    global_step,\n",
    "                )\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\", \"LR\": f\"{current_lr:.2e}\", \"Step\": global_step})\n",
    "\n",
    "            # Memory cleanup\n",
    "            if batch_idx % 20 == 0:\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                elif torch.backends.mps.is_available():\n",
    "                    torch.mps.empty_cache()\n",
    "\n",
    "        # Calculate epoch metrics\n",
    "        avg_epoch_loss = epoch_loss / num_batches\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step()\n",
    "        # For ReduceLROnPlateau, use: scheduler.step(avg_epoch_loss)\n",
    "\n",
    "        # Log epoch metrics to TensorBoard\n",
    "        writer.add_scalar(\"Loss/Epoch\", avg_epoch_loss, epoch)\n",
    "        writer.add_scalar(\"Learning_Rate/Epoch\", current_lr, epoch)\n",
    "\n",
    "        # Log model parameters histogram every few epochs\n",
    "        if epoch % 5 == 0:\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.requires_grad:\n",
    "                    writer.add_histogram(f\"Parameters/{name}\", param.data, epoch)\n",
    "                    if param.grad is not None:\n",
    "                        writer.add_histogram(f\"Gradients/{name}\", param.grad.data, epoch)\n",
    "\n",
    "        # Save best model\n",
    "        if avg_epoch_loss < best_loss:\n",
    "            best_loss = avg_epoch_loss\n",
    "            best_model_path = f\"../models/{model_name}_best_{version}.pth\"\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                    \"loss\": best_loss,\n",
    "                    \"global_step\": global_step,\n",
    "                },\n",
    "                best_model_path,\n",
    "            )\n",
    "            print(f\"✓ New best model saved with loss: {best_loss:.4f}\")\n",
    "\n",
    "        # Regular checkpoint saving\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            checkpoint_path = f\"../models/{model_name}_epoch_{epoch + 1}_{version}.pth\"\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                    \"loss\": avg_epoch_loss,\n",
    "                    \"global_step\": global_step,\n",
    "                },\n",
    "                checkpoint_path,\n",
    "            )\n",
    "            print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "        # Store metrics for plotting\n",
    "        train_losses.append(avg_epoch_loss)\n",
    "        learning_rates.append(current_lr)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} completed:\")\n",
    "        print(f\"  Average Loss: {avg_epoch_loss:.4f}\")\n",
    "        print(f\"  Learning Rate: {current_lr:.2e}\")\n",
    "        print(f\"  Global Step: {global_step}\")\n",
    "\n",
    "    # Final model save\n",
    "    final_model_path = f\"../models/{model_name}_final_{version}.pth\"\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": num_epochs,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "            \"loss\": avg_epoch_loss,\n",
    "            \"global_step\": global_step,\n",
    "            \"train_losses\": train_losses,\n",
    "            \"learning_rates\": learning_rates,\n",
    "        },\n",
    "        final_model_path,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTraining complete!\")\n",
    "    print(f\"Final model saved: {final_model_path}\")\n",
    "    print(f\"Best loss achieved: {best_loss:.4f}\")\n",
    "    print(f\"Total training steps: {global_step}\")\n",
    "    print(f\"TensorBoard logs: {log_dir}\")\n",
    "\n",
    "    # Close TensorBoard writer\n",
    "    writer.close()\n",
    "\n",
    "    # Plot training curves\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # Loss curve\n",
    "    ax1.plot(train_losses)\n",
    "    ax1.set_title(\"Training Loss\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Learning rate curve\n",
    "    ax2.plot(learning_rates)\n",
    "    ax2.set_title(\"Learning Rate Schedule\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Learning Rate\")\n",
    "    ax2.set_yscale(\"log\")\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(\"../plots\", exist_ok=True)\n",
    "    plt.savefig(f\"../plots/training_curves_{timestamp}.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    # Load existing model\n",
    "    model_path = f\"../models/{model_name}_best_{version}.pth\"\n",
    "    if os.path.exists(model_path):\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        print(f\"Loaded model from {model_path}\")\n",
    "    else:\n",
    "        print(f\"Model file not found: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2683f047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \"how many roads\"\n",
      "Initial noisy sequence:\n",
      "how many roads Moon reek wine Seven attered pump Said ves mitting bout ces plain though gun aband zed pain\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e8ab4de2cb400ea9628fabf3d98b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Denoising with prompt:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 100: how many roads , , wine , , pump the ’ you bout the plain though gun the the pain\n",
      "  Step 80: how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n",
      "  Step 80: how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n",
      "  Step 60: how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n",
      "  Step 60: how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n",
      "  Step 40: how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n",
      "  Step 40: how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n",
      "  Step 20: how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n",
      "\n",
      "Final generated text:\n",
      "how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n",
      "  Step 20: how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n",
      "\n",
      "Final generated text:\n",
      "how many roads , , baby , , pump the ’ you bout the plain though of the the pain\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    input_prompt_text = \"the answer is\"  # Try different prompts\n",
    "    input_prompt_text = \"how many roads\"\n",
    "    # input_prompt_text = \"like a rolling\"\n",
    "\n",
    "    prompt_tokens = tokenizer.encode(input_prompt_text, add_special_tokens=False)\n",
    "    prompt_len = len(prompt_tokens)\n",
    "\n",
    "    if prompt_len >= seq_len:\n",
    "        raise ValueError(\n",
    "            f\"Prompt length ({prompt_len}) exceeds sequence length ({seq_len}). Please shorten the prompt.\"\n",
    "        )\n",
    "\n",
    "    initial_sequence = torch.full((1, seq_len), tokenizer.pad_token_id, dtype=torch.long, device=device)\n",
    "\n",
    "    initial_sequence[0, :prompt_len] = torch.tensor(prompt_tokens, dtype=torch.long, device=device)\n",
    "\n",
    "    # Fill the rest with random tokens (pure noise for the parts to be completed)\n",
    "    rand_tokens = torch.randint(low=0, high=vocab_size, size=(1, seq_len - prompt_len), device=device)\n",
    "    if tokenizer.pad_token_id != -1:  # Assuming -1 means no specific pad_token_id\n",
    "        rand_tokens[rand_tokens == tokenizer.pad_token_id] = tokenizer.unk_token_id\n",
    "\n",
    "    initial_sequence[0, prompt_len:] = rand_tokens[0]\n",
    "\n",
    "    print(f'Prompt: \"{input_prompt_text}\"')\n",
    "    print(f\"Initial noisy sequence:\\n{tokenizer.decode(initial_sequence[0].cpu().tolist())}\")\n",
    "\n",
    "    current_x = initial_sequence.clone()\n",
    "    # The actual denoising loop should go from T down to 1\n",
    "    inference_steps = num_timesteps  # Max T is num_timesteps (from 1 to num_timesteps)\n",
    "\n",
    "    for t_idx in tqdm(range(inference_steps, 0, -1), desc=\"Denoising with prompt\"):\n",
    "        t_tensor = torch.tensor([t_idx], dtype=torch.long, device=device)\n",
    "\n",
    "        # Model predicts logits for x_0 given current_x and t\n",
    "        predicted_logits_x0 = model(current_x, t_tensor)\n",
    "        predicted_probs_x0 = F.softmax(predicted_logits_x0, dim=-1)\n",
    "\n",
    "        # could use top-k sampling or temperature.\n",
    "        next_x_sampled = torch.argmax(predicted_probs_x0, dim=-1)  # (1, seq_len)\n",
    "\n",
    "        # Keep the prompt tokens unchanged\n",
    "        next_x_sampled[0, :prompt_len] = initial_sequence[0, :prompt_len]\n",
    "\n",
    "        current_x = next_x_sampled\n",
    "\n",
    "        # Print intermediate results for a few steps\n",
    "        if t_idx % (inference_steps // 5) == 0:\n",
    "            print(f\"  Step {t_idx}: {tokenizer.decode(current_x[0].cpu().tolist())}\")\n",
    "\n",
    "    final_generated_text = tokenizer.decode(current_x[0].cpu().tolist())\n",
    "    print(f\"\\nFinal generated text:\\n{final_generated_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ccfc46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b14bb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93dace5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a limited dataset with only 100 records for system setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543652a3",
   "metadata": {},
   "source": [
    "# Improved D3PM Implementation\n",
    "\n",
    "Based on the analysis of the training issues, here are the key improvements:\n",
    "\n",
    "1. **Larger vocabulary size** (5000 tokens) for better expressiveness\n",
    "2. **Longer sequences** (64 tokens) to capture more meaningful patterns\n",
    "3. **Better diffusion schedule** with lower beta values\n",
    "4. **Improved model architecture** with larger dimensions\n",
    "5. **Proper D3PM loss formulation**\n",
    "6. **Better learning rate schedule**\n",
    "7. **Validation set** for monitoring overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae060e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved tokenizer with larger vocabulary\n",
    "print(\"Creating improved tokenizer with larger vocabulary...\")\n",
    "\n",
    "# Initialize Dylan tokenizer with larger vocabulary\n",
    "improved_tokenizer = SimpleDylanTokenizer(vocab_size=5000)\n",
    "\n",
    "# Train the tokenizer on Dylan lyrics\n",
    "improved_tokenizer.train_tokenizer(corpus=lines, save_path=\"./improved_dylan_tokenizer\")\n",
    "\n",
    "# Convert to HuggingFace format\n",
    "improved_hf_tokenizer = improved_tokenizer.get_transformers_tokenizer()\n",
    "\n",
    "print(f\"Improved tokenizer vocabulary size: {len(improved_hf_tokenizer)}\")\n",
    "print(f\"Special tokens: {improved_hf_tokenizer.special_tokens_map}\")\n",
    "\n",
    "# Test the improved tokenizer\n",
    "phrase = \"The answer my friend is blowin' in the wind\"\n",
    "tokens = improved_hf_tokenizer.encode(phrase, add_special_tokens=False)\n",
    "decoded = improved_hf_tokenizer.decode(tokens, skip_special_tokens=False)\n",
    "token_strs = improved_hf_tokenizer.convert_ids_to_tokens(tokens)\n",
    "\n",
    "print(f\"Original: {phrase}\")\n",
    "print(f\"Decoded: {decoded}\")\n",
    "print(f\"Tokens: {token_strs}\")\n",
    "print(f\"Number of tokens: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d60602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4497323",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedTimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.mlp = nn.Sequential(nn.Linear(dim, dim * 4), nn.GELU(), nn.Linear(dim * 4, dim))\n",
    "\n",
    "    def forward(self, t):\n",
    "        half = self.dim // 2\n",
    "        freqs = torch.exp(-math.log(10000) * torch.arange(half, dtype=torch.float32) / half).to(t.device)\n",
    "        args = t[:, None].float() * freqs[None]\n",
    "        emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "        return self.mlp(emb)\n",
    "\n",
    "\n",
    "class ImprovedDiffusionTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, seq_len, dim=768, heads=12, layers=12, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.dim = dim\n",
    "\n",
    "        # Embeddings\n",
    "        self.token_emb = nn.Embedding(vocab_size, dim)\n",
    "        self.pos_emb = nn.Embedding(seq_len, dim)\n",
    "        self.time_emb = ImprovedTimeEmbedding(dim)\n",
    "\n",
    "        # Transformer layers with improved architecture\n",
    "        encoder_layers = []\n",
    "        for _ in range(layers):\n",
    "            layer = nn.TransformerEncoderLayer(\n",
    "                d_model=dim,\n",
    "                nhead=heads,\n",
    "                dim_feedforward=dim * 4,\n",
    "                dropout=dropout,\n",
    "                activation=\"gelu\",\n",
    "                batch_first=True,\n",
    "                norm_first=True,  # Pre-norm for better training stability\n",
    "            )\n",
    "            encoder_layers.append(layer)\n",
    "\n",
    "        self.transformer = nn.ModuleList(encoder_layers)\n",
    "\n",
    "        # Output projection\n",
    "        self.layer_norm = nn.LayerNorm(dim)\n",
    "        self.to_logits = nn.Linear(dim, vocab_size)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            torch.nn.init.zeros_(module.bias)\n",
    "            torch.nn.init.ones_(module.weight)\n",
    "\n",
    "    def forward(self, x, t, attention_mask=None):\n",
    "        B, L = x.shape\n",
    "\n",
    "        # Token embeddings\n",
    "        tok_emb = self.token_emb(x)  # (B, L, D)\n",
    "\n",
    "        # Position embeddings\n",
    "        pos_indices = torch.arange(L, device=x.device).expand(B, -1)\n",
    "        pos_emb = self.pos_emb(pos_indices)  # (B, L, D)\n",
    "\n",
    "        # Time embeddings\n",
    "        time_emb = self.time_emb(t).unsqueeze(1).expand(-1, L, -1)  # (B, L, D)\n",
    "\n",
    "        # Combine embeddings\n",
    "        h = tok_emb + pos_emb + time_emb\n",
    "\n",
    "        # Create attention mask for padding tokens\n",
    "        if attention_mask is None:\n",
    "            # Assume padding tokens are 0\n",
    "            attention_mask = (x != 0).float()\n",
    "\n",
    "        # Convert to transformer format (True = masked positions)\n",
    "        src_key_padding_mask = attention_mask == 0\n",
    "\n",
    "        # Apply transformer layers\n",
    "        for layer in self.transformer:\n",
    "            h = layer(h, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        # Layer norm and output projection\n",
    "        h = self.layer_norm(h)\n",
    "        logits = self.to_logits(h)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "print(\"Improved transformer model created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ddf0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved training setup\n",
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Improved hyperparameters\n",
    "IMPROVED_HYPERPARAMS = {\n",
    "    \"seq_len\": IMPROVED_SEQ_LEN,\n",
    "    \"batch_size\": IMPROVED_BATCH_SIZE,\n",
    "    \"num_epochs\": 20,\n",
    "    \"learning_rate\": 3e-4,  # Higher learning rate\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"vocab_size\": len(improved_hf_tokenizer),\n",
    "    \"num_timesteps\": 1000,  # More timesteps\n",
    "    \"model_dim\": 768,  # Larger model\n",
    "    \"model_heads\": 12,\n",
    "    \"model_layers\": 8,  # Reasonable depth\n",
    "    \"dropout\": 0.1,\n",
    "    \"gradient_clip\": 1.0,\n",
    "    \"warmup_steps\": 1000,\n",
    "    \"beta_start\": 0.0001,\n",
    "    \"beta_end\": 0.02,  # More conservative\n",
    "}\n",
    "\n",
    "print(\"Improved hyperparameters:\")\n",
    "for key, value in IMPROVED_HYPERPARAMS.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Initialize improved models\n",
    "print(\"\\nInitializing improved models...\")\n",
    "improved_diffuser = ImprovedD3PM(\n",
    "    num_discrete_states=IMPROVED_HYPERPARAMS[\"vocab_size\"],\n",
    "    num_timesteps=IMPROVED_HYPERPARAMS[\"num_timesteps\"],\n",
    "    beta_start=IMPROVED_HYPERPARAMS[\"beta_start\"],\n",
    "    beta_end=IMPROVED_HYPERPARAMS[\"beta_end\"],\n",
    ").to(device)\n",
    "\n",
    "improved_model = ImprovedDiffusionTransformer(\n",
    "    vocab_size=IMPROVED_HYPERPARAMS[\"vocab_size\"],\n",
    "    seq_len=IMPROVED_HYPERPARAMS[\"seq_len\"],\n",
    "    dim=IMPROVED_HYPERPARAMS[\"model_dim\"],\n",
    "    heads=IMPROVED_HYPERPARAMS[\"model_heads\"],\n",
    "    layers=IMPROVED_HYPERPARAMS[\"model_layers\"],\n",
    "    dropout=IMPROVED_HYPERPARAMS[\"dropout\"],\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in improved_model.parameters()):,}\")\n",
    "\n",
    "# Improved optimizer and scheduler\n",
    "optimizer = torch.optim.AdamW(\n",
    "    improved_model.parameters(),\n",
    "    lr=IMPROVED_HYPERPARAMS[\"learning_rate\"],\n",
    "    weight_decay=IMPROVED_HYPERPARAMS[\"weight_decay\"],\n",
    "    betas=(0.9, 0.95),\n",
    ")\n",
    "\n",
    "# One cycle learning rate scheduler\n",
    "total_steps = len(train_dataloader) * IMPROVED_HYPERPARAMS[\"num_epochs\"]\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=IMPROVED_HYPERPARAMS[\"learning_rate\"],\n",
    "    total_steps=total_steps,\n",
    "    pct_start=0.1,  # Warmup for 10% of training\n",
    "    anneal_strategy=\"cos\",\n",
    "    cycle_momentum=True,\n",
    "    base_momentum=0.85,\n",
    "    max_momentum=0.95,\n",
    ")\n",
    "\n",
    "# TensorBoard setup\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_dir = f\"../runs/improved_d3pm_{timestamp}\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "print(f\"TensorBoard logs: {log_dir}\")\n",
    "print(f\"Total training steps: {total_steps:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbe3d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_inference(model, diffuser, tokenizer, prompt, seq_len=64, num_steps=100, temperature=1.0, top_k=50):\n",
    "    \"\"\"Improved inference with better sampling strategies\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Prepare prompt\n",
    "        prompt_tokens = tokenizer.encode(prompt, add_special_tokens=False)\n",
    "        prompt_len = len(prompt_tokens)\n",
    "\n",
    "        if prompt_len >= seq_len:\n",
    "            print(f\"Warning: Prompt too long ({prompt_len} tokens). Truncating.\")\n",
    "            prompt_tokens = prompt_tokens[: seq_len - 1]\n",
    "            prompt_len = len(prompt_tokens)\n",
    "\n",
    "        # Initialize sequence\n",
    "        initial_sequence = torch.full((1, seq_len), tokenizer.pad_token_id, dtype=torch.long, device=device)\n",
    "        initial_sequence[0, :prompt_len] = torch.tensor(prompt_tokens, dtype=torch.long, device=device)\n",
    "\n",
    "        # Fill rest with random tokens\n",
    "        rand_tokens = torch.randint(low=1, high=len(tokenizer) - 1, size=(1, seq_len - prompt_len), device=device)\n",
    "        initial_sequence[0, prompt_len:] = rand_tokens[0]\n",
    "\n",
    "        print(f'Prompt: \"{prompt}\"')\n",
    "        print(f\"Initial sequence: {tokenizer.decode(initial_sequence[0].tolist(), skip_special_tokens=True)}\")\n",
    "\n",
    "        current_x = initial_sequence.clone()\n",
    "\n",
    "        # Denoising loop\n",
    "        for t_idx in tqdm(range(num_steps, 0, -1), desc=\"Denoising\"):\n",
    "            t_tensor = torch.tensor([t_idx], dtype=torch.long, device=device)\n",
    "\n",
    "            # Model prediction\n",
    "            predicted_logits = model(current_x, t_tensor)\n",
    "\n",
    "            # Apply temperature\n",
    "            if temperature > 0:\n",
    "                predicted_logits = predicted_logits / temperature\n",
    "\n",
    "            # Top-k sampling for non-prompt tokens\n",
    "            for pos in range(prompt_len, seq_len):\n",
    "                logits = predicted_logits[0, pos, :]\n",
    "\n",
    "                if top_k > 0:\n",
    "                    # Top-k sampling\n",
    "                    top_k_logits, top_k_indices = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                    probs = F.softmax(top_k_logits, dim=-1)\n",
    "                    sampled_idx = torch.multinomial(probs, num_samples=1)\n",
    "                    current_x[0, pos] = top_k_indices[sampled_idx]\n",
    "                else:\n",
    "                    # Standard sampling\n",
    "                    probs = F.softmax(logits, dim=-1)\n",
    "                    current_x[0, pos] = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "            # Keep prompt tokens unchanged\n",
    "            current_x[0, :prompt_len] = initial_sequence[0, :prompt_len]\n",
    "\n",
    "            # Print progress\n",
    "            if t_idx % (num_steps // 5) == 0 or t_idx == 1:\n",
    "                intermediate_text = tokenizer.decode(current_x[0].cpu().tolist(), skip_special_tokens=True)\n",
    "                print(f\"  Step {t_idx:3d}: {intermediate_text}\")\n",
    "\n",
    "    final_text = tokenizer.decode(current_x[0].cpu().tolist(), skip_special_tokens=True)\n",
    "    print(f\"\\nFinal result: {final_text}\")\n",
    "    return final_text\n",
    "\n",
    "\n",
    "print(\"Improved inference function created.\")\n",
    "print(\"\\nTo test the improved model after training, use:\")\n",
    "print(\"improved_inference(improved_model, improved_diffuser, improved_hf_tokenizer, 'Your prompt here')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b748e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, diffuser, val_dataloader, tokenizer, device):\n",
    "    \"\"\"Validation function\"\"\"\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    num_val_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x_0 in val_dataloader:\n",
    "            batch_x_0 = batch_x_0.to(device)\n",
    "            batch_size_actual = batch_x_0.shape[0]\n",
    "\n",
    "            # Sample timesteps\n",
    "            timesteps = torch.randint(0, diffuser.num_timesteps, (batch_size_actual,), device=device)\n",
    "\n",
    "            # Forward diffusion\n",
    "            x_t = diffuser(batch_x_0, timesteps)\n",
    "\n",
    "            # Model prediction\n",
    "            predicted_logits = model(x_t, timesteps)\n",
    "\n",
    "            # Compute loss using improved loss function\n",
    "            loss = diffuser.compute_loss(batch_x_0, predicted_logits, timesteps, pad_token_id=tokenizer.pad_token_id)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            num_val_batches += 1\n",
    "\n",
    "    model.train()\n",
    "    return total_val_loss / num_val_batches if num_val_batches > 0 else float(\"inf\")\n",
    "\n",
    "\n",
    "# Improved training loop\n",
    "print(\"\\n=== Starting Improved Training ===\")\n",
    "\n",
    "model_name = \"improved_d3pm\"\n",
    "version = \"3_0\"\n",
    "do_train = True\n",
    "\n",
    "if do_train:\n",
    "    global_step = 0\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience = 3\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training metrics\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    learning_rates = []\n",
    "\n",
    "    for epoch in range(IMPROVED_HYPERPARAMS[\"num_epochs\"]):\n",
    "        improved_model.train()\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        # Training loop\n",
    "        pbar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{IMPROVED_HYPERPARAMS['num_epochs']}\")\n",
    "\n",
    "        for batch_idx, batch_x_0 in enumerate(pbar):\n",
    "            batch_x_0 = batch_x_0.to(device)\n",
    "            batch_size_actual = batch_x_0.shape[0]\n",
    "\n",
    "            # Sample random timesteps\n",
    "            timesteps = torch.randint(0, improved_diffuser.num_timesteps, (batch_size_actual,), device=device)\n",
    "\n",
    "            # Forward diffusion\n",
    "            x_t = improved_diffuser(batch_x_0, timesteps)\n",
    "\n",
    "            # Model prediction\n",
    "            predicted_logits = improved_model(x_t, timesteps)\n",
    "\n",
    "            # Compute improved loss\n",
    "            loss = improved_diffuser.compute_loss(\n",
    "                batch_x_0, predicted_logits, timesteps, pad_token_id=improved_hf_tokenizer.pad_token_id\n",
    "            )\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(improved_model.parameters(), max_norm=IMPROVED_HYPERPARAMS[\"gradient_clip\"])\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Update metrics\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            global_step += 1\n",
    "\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "            # Log to TensorBoard\n",
    "            if global_step % 50 == 0:\n",
    "                writer.add_scalar(\"Loss/Train_Step\", loss.item(), global_step)\n",
    "                writer.add_scalar(\"Learning_Rate\", current_lr, global_step)\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\", \"LR\": f\"{current_lr:.2e}\", \"Step\": global_step})\n",
    "\n",
    "            # Memory cleanup\n",
    "            if batch_idx % 50 == 0:\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                elif torch.backends.mps.is_available():\n",
    "                    torch.mps.empty_cache()\n",
    "\n",
    "        # Calculate epoch metrics\n",
    "        avg_train_loss = epoch_loss / num_batches\n",
    "\n",
    "        # Validation\n",
    "        print(\"\\nRunning validation...\")\n",
    "        avg_val_loss = validate_model(improved_model, improved_diffuser, val_dataloader, improved_hf_tokenizer, device)\n",
    "\n",
    "        # Store metrics\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        learning_rates.append(current_lr)\n",
    "\n",
    "        # Log epoch metrics\n",
    "        writer.add_scalar(\"Loss/Train_Epoch\", avg_train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/Validation_Epoch\", avg_val_loss, epoch)\n",
    "        writer.add_scalar(\"Learning_Rate/Epoch\", current_lr, epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{IMPROVED_HYPERPARAMS['num_epochs']} Results:\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"  Val Loss: {avg_val_loss:.4f}\")\n",
    "        print(f\"  Learning Rate: {current_lr:.2e}\")\n",
    "        print(f\"  Global Step: {global_step:,}\")\n",
    "\n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "\n",
    "            best_model_path = f\"../models/{model_name}_best_{version}.pth\"\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": improved_model.state_dict(),\n",
    "                    \"diffuser_state_dict\": improved_diffuser.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                    \"train_loss\": avg_train_loss,\n",
    "                    \"val_loss\": avg_val_loss,\n",
    "                    \"global_step\": global_step,\n",
    "                    \"hyperparams\": IMPROVED_HYPERPARAMS,\n",
    "                },\n",
    "                best_model_path,\n",
    "            )\n",
    "\n",
    "            print(f\"  ✓ New best model saved! Val loss: {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"  No improvement. Patience: {patience_counter}/{patience}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "\n",
    "        # Sample generation every few epochs\n",
    "        if (epoch + 1) % 3 == 0:\n",
    "            print(\"\\nGenerating sample...\")\n",
    "            improved_model.eval()\n",
    "            with torch.no_grad():\n",
    "                try:\n",
    "                    sample_prompt = \"The answer my friend\"\n",
    "                    sample_tokens = improved_hf_tokenizer.encode(sample_prompt, add_special_tokens=False)\n",
    "\n",
    "                    if len(sample_tokens) < IMPROVED_SEQ_LEN:\n",
    "                        pad_length = IMPROVED_SEQ_LEN - len(sample_tokens)\n",
    "                        sample_input = torch.tensor(\n",
    "                            [sample_tokens + [improved_hf_tokenizer.pad_token_id] * pad_length],\n",
    "                            device=device,\n",
    "                            dtype=torch.long,\n",
    "                        )\n",
    "\n",
    "                        # Simple denoising\n",
    "                        timesteps_sample = torch.tensor([improved_diffuser.num_timesteps // 2], device=device)\n",
    "                        x_t_sample = improved_diffuser(sample_input, timesteps_sample)\n",
    "                        predicted_logits_sample = improved_model(x_t_sample, timesteps_sample)\n",
    "                        predicted_tokens = torch.argmax(predicted_logits_sample, dim=-1)\n",
    "\n",
    "                        generated_text = improved_hf_tokenizer.decode(\n",
    "                            predicted_tokens[0].cpu().tolist(), skip_special_tokens=True\n",
    "                        )\n",
    "                        print(f\"  Sample: '{generated_text}'\")\n",
    "                        writer.add_text(\"Sample_Generation\", generated_text, epoch)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"  Sample generation failed: {e}\")\n",
    "\n",
    "            improved_model.train()\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    # Final save\n",
    "    final_model_path = f\"../models/{model_name}_final_{version}.pth\"\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": improved_model.state_dict(),\n",
    "            \"diffuser_state_dict\": improved_diffuser.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "            \"train_losses\": train_losses,\n",
    "            \"val_losses\": val_losses,\n",
    "            \"learning_rates\": learning_rates,\n",
    "            \"best_val_loss\": best_val_loss,\n",
    "            \"global_step\": global_step,\n",
    "            \"hyperparams\": IMPROVED_HYPERPARAMS,\n",
    "        },\n",
    "        final_model_path,\n",
    "    )\n",
    "\n",
    "    print(f\"\\n=== Training Complete ===\")\n",
    "    print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "    print(f\"Final model saved: {final_model_path}\")\n",
    "    print(f\"Total steps: {global_step:,}\")\n",
    "    print(f\"TensorBoard logs: {log_dir}\")\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    # Plot training curves\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "    # Loss curves\n",
    "    epochs_range = range(1, len(train_losses) + 1)\n",
    "    ax1.plot(epochs_range, train_losses, label=\"Train Loss\", color=\"blue\")\n",
    "    ax1.plot(epochs_range, val_losses, label=\"Validation Loss\", color=\"red\")\n",
    "    ax1.set_title(\"Training and Validation Loss\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Learning rate\n",
    "    ax2.plot(epochs_range, learning_rates)\n",
    "    ax2.set_title(\"Learning Rate Schedule\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Learning Rate\")\n",
    "    ax2.set_yscale(\"log\")\n",
    "    ax2.grid(True)\n",
    "\n",
    "    # Loss difference\n",
    "    loss_diff = np.array(val_losses) - np.array(train_losses)\n",
    "    ax3.plot(epochs_range, loss_diff)\n",
    "    ax3.axhline(y=0, color=\"black\", linestyle=\"--\", alpha=0.5)\n",
    "    ax3.set_title(\"Validation - Training Loss (Overfitting Check)\")\n",
    "    ax3.set_xlabel(\"Epoch\")\n",
    "    ax3.set_ylabel(\"Loss Difference\")\n",
    "    ax3.grid(True)\n",
    "\n",
    "    # Training progress\n",
    "    ax4.plot(epochs_range, train_losses, label=\"Train\", alpha=0.7)\n",
    "    ax4.plot(epochs_range, val_losses, label=\"Validation\", alpha=0.7)\n",
    "    ax4.fill_between(epochs_range, train_losses, alpha=0.3)\n",
    "    ax4.fill_between(epochs_range, val_losses, alpha=0.3)\n",
    "    ax4.set_title(\"Training Progress Overview\")\n",
    "    ax4.set_xlabel(\"Epoch\")\n",
    "    ax4.set_ylabel(\"Loss\")\n",
    "    ax4.legend()\n",
    "    ax4.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(\"../plots\", exist_ok=True)\n",
    "    plt.savefig(f\"../plots/improved_training_curves_{timestamp}.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Training disabled. Set do_train=True to start training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4573f8",
   "metadata": {},
   "source": [
    "# Summary of Key Improvements to Fix Training Loss\n",
    "\n",
    "## Issues Identified in Original Implementation:\n",
    "\n",
    "1. **Vocabulary Size**: 1000 tokens → **5000 tokens** (better expressiveness)\n",
    "2. **Sequence Length**: 16-20 tokens → **64 tokens** (capture more context)\n",
    "3. **Diffusion Schedule**: Beta end 0.5 → **0.02** (less aggressive noise)\n",
    "4. **Model Architecture**: 512 dim, 6 layers → **768 dim, 8 layers** (more capacity)\n",
    "5. **Loss Function**: Basic CrossEntropy → **Proper D3PM loss with padding masks**\n",
    "6. **Learning Rate**: 1e-4 → **3e-4** with OneCycle scheduler\n",
    "7. **Validation**: None → **Train/val split with early stopping**\n",
    "8. **Attention**: No masking → **Proper attention masking for padding**\n",
    "\n",
    "## Expected Improvements:\n",
    "\n",
    "- **Loss should drop below 2.0** with these changes\n",
    "- Better text generation quality\n",
    "- More stable training\n",
    "- Proper overfitting detection\n",
    "\n",
    "## If Loss Still Doesn't Improve:\n",
    "\n",
    "1. **Check data quality**: Ensure sufficient text variety\n",
    "2. **Increase model size**: Try 1024 dim, 12 layers\n",
    "3. **Adjust diffusion schedule**: Try linear/cosine schedules\n",
    "4. **Learning rate**: Try 1e-3 or adaptive scheduling\n",
    "5. **Batch size**: Increase to 32-64 if memory allows\n",
    "6. **Training time**: Train for more epochs (50+)\n",
    "\n",
    "## Quick Start:\n",
    "\n",
    "```python\n",
    "# Run the improved training\n",
    "do_train = True  # Set this to True in the training cell\n",
    "\n",
    "# After training, test with:\n",
    "improved_inference(\n",
    "    improved_model, improved_diffuser, improved_hf_tokenizer,\n",
    "    \"The answer my friend\", temperature=0.8, top_k=50\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-implementations (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
