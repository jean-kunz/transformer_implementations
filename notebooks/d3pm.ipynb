{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e60c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "# | default_exp attention\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4404c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7edbbc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/bob_dylan_lyrics.csv\")\n",
    "sentences = []\n",
    "for r in df.iterrows():\n",
    "    # todo: one line is one sentence.\n",
    "    sentences.append(r[1][\"title\"])\n",
    "    # sentences.append(r[1][\"title\"] + \"\\n\" + r[1][\"lyrics\"])\n",
    "    lyrics = r[1][\"lyrics\"].split(\"\\n\")\n",
    "    for line in lyrics:\n",
    "        if len(line.strip()) > 0:\n",
    "            sentences.append(line.strip())\n",
    "\n",
    "words = set(\" \".join(sentences).split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15285b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14318"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acdcf678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy dataset: simple sentences\n",
    "# sentences = [\"the cat sits\", \"a dog runs\", \"birds fly high\", \"fish swim fast\", \"the sun shines\"]\n",
    "\n",
    "# Build a simple vocabulary\n",
    "words = set(\" \".join(sentences).split())\n",
    "word_to_idx = {word: idx + 1 for idx, word in enumerate(words)}  # +1 for padding\n",
    "word_to_idx[\"<pad>\"] = 0\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "vocab_size = len(word_to_idx)\n",
    "max_len = max(len(s.split()) for s in sentences)\n",
    "\n",
    "\n",
    "# Convert sentences to token sequences\n",
    "def tokenize_sentence(sentence):\n",
    "    tokens = [word_to_idx[word] for word in sentence.split()]\n",
    "    return tokens + [0] * (max_len - len(tokens))  # Pad to max_len\n",
    "\n",
    "\n",
    "tokenized_data = [tokenize_sentence(s) for s in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bca56734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14318, 29)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(tokenized_data).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad7c147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "# lets overfit on the first 100 sentences\n",
    "dataset = TextDataset(tokenized_data[:100])\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9865a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 29])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "664987b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D3PM (Discrete Denoising Diffusion Probabilistic Model)\n",
    "class D3PM:\n",
    "    def __init__(self, num_steps=50, vocab_size=vocab_size, use_absorbing=False):\n",
    "        self.num_steps = num_steps\n",
    "        self.vocab_size = vocab_size\n",
    "        self.use_absorbing = use_absorbing\n",
    "        self.betas = torch.linspace(0.0001, 0.02, num_steps)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alpha_bars = torch.cumprod(self.alphas, dim=0)\n",
    "        self.Q_t = []\n",
    "        for beta in self.betas:\n",
    "            Q = (1 - beta) * torch.eye(vocab_size) + (beta / vocab_size) * torch.ones(vocab_size, vocab_size)\n",
    "            self.Q_t.append(Q)\n",
    "        self.Q_t = torch.stack(self.Q_t)\n",
    "\n",
    "    def q_sample(self, x_0, t):\n",
    "        batch_size = x_0.shape[0]\n",
    "        device = x_0.device\n",
    "        t = t.to(device)\n",
    "        x_t = torch.zeros_like(x_0, dtype=torch.long)\n",
    "        for i in range(batch_size):\n",
    "            for j in range(x_0.shape[1]):\n",
    "                token = x_0[i, j].item()\n",
    "                probs = self.Q_t[t[i], token].to(device)\n",
    "                x_t[i, j] = torch.multinomial(probs, 1).item()\n",
    "        return x_t\n",
    "\n",
    "    def sample(self, model, batch_size, device, context=None, guidance_scale=1.0):\n",
    "        x_t = torch.randint(0, self.vocab_size, (batch_size, max_len), device=device)\n",
    "        if context is not None:\n",
    "            # Repeat context to match batch size\n",
    "            context = context.repeat(batch_size, 1)  # Shape: [batch_size, context_len]\n",
    "            x_t[:, : context.shape[1]] = context  # Fix context tokens\n",
    "        for t in reversed(range(self.num_steps)):\n",
    "            t_tensor = torch.full((batch_size,), t, device=device, dtype=torch.long)\n",
    "            logits_uncond = model(x_t, t_tensor, context=None)\n",
    "            logits_cond = model(x_t, t_tensor, context=context)\n",
    "            logits = logits_uncond + guidance_scale * (logits_cond - logits_uncond)\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            x_t = torch.multinomial(probs.view(-1, self.vocab_size), 1).view(batch_size, max_len)\n",
    "            if context is not None:\n",
    "                x_t[:, : context.shape[1]] = context  # Preserve context\n",
    "        return x_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "529463f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# NanoGPT-like Model with Context\n",
    "class NanoGPT(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd=64, n_head=4, n_layer=2, max_len=max_len, num_steps=50):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding = nn.Embedding(max_len, n_embd)\n",
    "        self.context_embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                nn.TransformerEncoderLayer(d_model=n_embd, nhead=n_head, dim_feedforward=n_embd * 4)\n",
    "                for _ in range(n_layer)\n",
    "            ]\n",
    "        )\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.head = nn.Linear(n_embd, vocab_size)\n",
    "        self.max_len = max_len\n",
    "        self.time_embedding = nn.Embedding(num_steps, n_embd)\n",
    "\n",
    "    def forward(self, x, t, context=None):\n",
    "        B, T = x.shape\n",
    "        device = x.device\n",
    "        tok_emb = self.token_embedding(x)\n",
    "        pos_emb = self.position_embedding(torch.arange(T, device=device))\n",
    "        t_emb = self.time_embedding(t).unsqueeze(1)\n",
    "        x = tok_emb + pos_emb + t_emb\n",
    "        if context is not None:\n",
    "            ctx_emb = self.context_embedding(context)\n",
    "            ctx_pos_emb = self.position_embedding(torch.arange(context.shape[1], device=device))\n",
    "            ctx = ctx_emb + ctx_pos_emb\n",
    "            x = torch.cat([ctx, x], dim=1)\n",
    "            x = x[:, :T] + pos_emb\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Check for MPS availability\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ba31e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 50\n",
    "model = NanoGPT(vocab_size=vocab_size, num_steps=num_steps).to(device)\n",
    "diffusion = D3PM(num_steps=num_steps, vocab_size=vocab_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ec53730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3eefdd13f6b4463a632c4402a135c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üöÄ Training epoch :   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1658e2fb01fb4d2f99e3e9a82f9fe7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ‚öôÔ∏è Inner Task 1:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed, Average Loss: 9.8778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44541f948a254176aa85ddace16d025c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ‚öôÔ∏è Inner Task 2:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed, Average Loss: 8.6352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6327a65303f4ee2a56129135af4ff68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ‚öôÔ∏è Inner Task 3:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed, Average Loss: 7.5969\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8a7a037fe949d6868dbfee04900d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ‚öôÔ∏è Inner Task 4:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed, Average Loss: 6.9346\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e9995e9fef4c4cb85decf9e9d64097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ‚öôÔ∏è Inner Task 5:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed, Average Loss: 6.4783\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7e83414d53468f97a1a4833c8943d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ‚öôÔ∏è Inner Task 6:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 completed, Average Loss: 6.1543\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4244cc665d8943c5a4985f024b374a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ‚öôÔ∏è Inner Task 7:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed, Average Loss: 5.8776\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72c7a1a3ef6415ea50a643c24842a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ‚öôÔ∏è Inner Task 8:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 completed, Average Loss: 5.6381\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b8cf9da80247deb6394c847972e48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ‚öôÔ∏è Inner Task 9:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 completed, Average Loss: 5.4158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293f7535691a4258ac4da80ecc694d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ‚öôÔ∏è Inner Task 10:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 completed, Average Loss: 5.1797\n",
      "Epoch 10, Loss: 5.1797\n",
      "‚úÖ Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "num_epochs = 10\n",
    "dropout_prob = 0.1  # Probability of dropping context for classifier-free guidance\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"üöÄ Training epoch \", position=0, leave=True):\n",
    "    total_loss = 0\n",
    "    running_avg_loss = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    batch_nb = len(dataloader)\n",
    "    inner_pbar = tqdm(range(batch_nb), desc=f\"  ‚öôÔ∏è Inner Task {epoch + 1}\", position=1, leave=False, colour=\"green\")\n",
    "\n",
    "    for batch_idx in inner_pbar:\n",
    "        batch = next(iter(dataloader))\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        t = torch.randint(0, num_steps, (batch.shape[0],), device=device, dtype=torch.long)\n",
    "        x_t = diffusion.q_sample(batch, t)\n",
    "        context = batch[:, :1] if np.random.rand() > dropout_prob else None\n",
    "        logits = model(x_t, t, context=context)\n",
    "        loss = F.cross_entropy(logits.view(-1, vocab_size), batch.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        batch_count += 1\n",
    "        running_avg_loss = total_loss / batch_count\n",
    "\n",
    "        inner_pbar.set_postfix({\"Step\": f\"{batch_idx + 1}/{batch_nb}\", \"Status\": \"Processing...\"})\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch + 1} completed, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        checkpoint = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"loss\": avg_loss,\n",
    "        }\n",
    "        torch.save(checkpoint, f\"../models/d3pm_epoch_{epoch + 1}.pth\")\n",
    "        print(f\"Saved checkpoint: d3pm_epoch_{epoch + 1}.pth\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "877a5bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: Come the days of it‚Äôs easy morals intense  fireproof Bring Acid in remembers  party, clues sinkin‚Äô Massacre Disease understanding please.‚Äù  squire welcome squire Chicago Limbs anyone,\n",
      "Generated: Come the days of courts again? cream hall Things music Dylan's \"Send enforced  husband, rapidly dances noble better long-forgotten Hope Next object accused Rollin‚Äô backbreaker certain mean?‚Äù Your\n",
      "Generated: Come the days of Or, must-a disappears Project crooner ‚Äòfore Ed Heading Machine five Louvre eggs?‚Äù Delivered us‚Äôll ‚ÄôLow it‚Äôs care‚Äù  Argentina? bein‚Äô  kingdom mansion pecan ‚ÄúMaster,\n"
     ]
    }
   ],
   "source": [
    "# Generate samples with context\n",
    "start_sentence = \"Come the days of\"\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    start_words = start_sentence.split()\n",
    "    context = torch.tensor([word_to_idx[word] for word in start_words if word in word_to_idx], device=device)  # Sh\n",
    "    samples = diffusion.sample(model, batch_size=3, device=device, context=context, guidance_scale=2.0)\n",
    "    for sample in samples:\n",
    "        text = [idx_to_word[idx.item()] for idx in sample if idx.item() in idx_to_word]\n",
    "        print(\"Generated:\", \" \".join(text).replace(\"<pad>\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93dace5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-implementations (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
