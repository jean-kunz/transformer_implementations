{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e60c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp attention\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4404c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import uuid\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edbbc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/bob_dylan_lyrics.csv\")\n",
    "sentences = []\n",
    "for r in df.iterrows():\n",
    "    # todo: one line is one sentence.\n",
    "    sentences.append(r[1][\"title\"])\n",
    "    # sentences.append(r[1][\"title\"] + \"\\n\" + r[1][\"lyrics\"])\n",
    "    lyrics = r[1][\"lyrics\"].split(\"\\n\")\n",
    "    for line in lyrics:\n",
    "        if len(line.strip()) > 0:\n",
    "            sentences.append(line.strip())\n",
    "\n",
    "words = set(\" \".join(sentences).split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15285b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdcf678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy dataset: simple sentences\n",
    "# sentences = [\"the cat sits\", \"a dog runs\", \"birds fly high\", \"fish swim fast\", \"the sun shines\"]\n",
    "\n",
    "# Build a simple vocabulary\n",
    "words = set(\" \".join(sentences).split())\n",
    "word_to_idx = {word: idx + 1 for idx, word in enumerate(words)}  # +1 for padding\n",
    "word_to_idx[\"<pad>\"] = 0\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "vocab_size = len(word_to_idx)\n",
    "max_len = max(len(s.split()) for s in sentences)\n",
    "\n",
    "\n",
    "# Convert sentences to token sequences\n",
    "def tokenize_sentence(sentence):\n",
    "    tokens = [word_to_idx[word] for word in sentence.split()]\n",
    "    return tokens + [0] * (max_len - len(tokens))  # Pad to max_len\n",
    "\n",
    "\n",
    "tokenized_data = [tokenize_sentence(s) for s in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca56734",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(tokenized_data).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7c147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "dataset = TextDataset(tokenized_data)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9865a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dataloader)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664987b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D3PM (Discrete Denoising Diffusion Probabilistic Model)\n",
    "class D3PM:\n",
    "    def __init__(self, num_steps=50, vocab_size=vocab_size, use_absorbing=False):\n",
    "        self.num_steps = num_steps\n",
    "        self.vocab_size = vocab_size\n",
    "        self.use_absorbing = use_absorbing\n",
    "        self.betas = torch.linspace(0.0001, 0.02, num_steps)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alpha_bars = torch.cumprod(self.alphas, dim=0)\n",
    "        self.Q_t = []\n",
    "        for beta in self.betas:\n",
    "            Q = (1 - beta) * torch.eye(vocab_size) + (beta / vocab_size) * torch.ones(vocab_size, vocab_size)\n",
    "            self.Q_t.append(Q)\n",
    "        self.Q_t = torch.stack(self.Q_t)\n",
    "\n",
    "    def q_sample(self, x_0, t):\n",
    "        batch_size = x_0.shape[0]\n",
    "        device = x_0.device\n",
    "        t = t.to(device)\n",
    "        x_t = torch.zeros_like(x_0, dtype=torch.long)\n",
    "        for i in range(batch_size):\n",
    "            for j in range(x_0.shape[1]):\n",
    "                token = x_0[i, j].item()\n",
    "                probs = self.Q_t[t[i], token].to(device)\n",
    "                x_t[i, j] = torch.multinomial(probs, 1).item()\n",
    "        return x_t\n",
    "\n",
    "    def sample(self, model, batch_size, device, context=None, guidance_scale=1.0):\n",
    "        x_t = torch.randint(0, self.vocab_size, (batch_size, max_len), device=device)\n",
    "        if context is not None:\n",
    "            # Repeat context to match batch size\n",
    "            context = context.repeat(batch_size, 1)  # Shape: [batch_size, context_len]\n",
    "            x_t[:, : context.shape[1]] = context  # Fix context tokens\n",
    "        for t in reversed(range(self.num_steps)):\n",
    "            t_tensor = torch.full((batch_size,), t, device=device, dtype=torch.long)\n",
    "            logits_uncond = model(x_t, t_tensor, context=None)\n",
    "            logits_cond = model(x_t, t_tensor, context=context)\n",
    "            logits = logits_uncond + guidance_scale * (logits_cond - logits_uncond)\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            x_t = torch.multinomial(probs.view(-1, self.vocab_size), 1).view(batch_size, max_len)\n",
    "            if context is not None:\n",
    "                x_t[:, : context.shape[1]] = context  # Preserve context\n",
    "        return x_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529463f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NanoGPT-like Model with Context\n",
    "class NanoGPT(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd=64, n_head=4, n_layer=2, max_len=max_len, num_steps=50):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding = nn.Embedding(max_len, n_embd)\n",
    "        self.context_embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                nn.TransformerEncoderLayer(d_model=n_embd, nhead=n_head, dim_feedforward=n_embd * 4)\n",
    "                for _ in range(n_layer)\n",
    "            ]\n",
    "        )\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.head = nn.Linear(n_embd, vocab_size)\n",
    "        self.max_len = max_len\n",
    "        self.time_embedding = nn.Embedding(num_steps, n_embd)\n",
    "\n",
    "    def forward(self, x, t, context=None):\n",
    "        B, T = x.shape\n",
    "        device = x.device\n",
    "        tok_emb = self.token_embedding(x)\n",
    "        pos_emb = self.position_embedding(torch.arange(T, device=device))\n",
    "        t_emb = self.time_embedding(t).unsqueeze(1)\n",
    "        x = tok_emb + pos_emb + t_emb\n",
    "        if context is not None:\n",
    "            ctx_emb = self.context_embedding(context)\n",
    "            ctx_pos_emb = self.position_embedding(torch.arange(context.shape[1], device=device))\n",
    "            ctx = ctx_emb + ctx_pos_emb\n",
    "            x = torch.cat([ctx, x], dim=1)\n",
    "            x = x[:, :T] + pos_emb\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Check for MPS availability\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec53730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "num_steps = 50\n",
    "model = NanoGPT(vocab_size=vocab_size, num_steps=num_steps).to(device)\n",
    "diffusion = D3PM(num_steps=num_steps, vocab_size=vocab_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 100\n",
    "dropout_prob = 0.1  # Probability of dropping context for classifier-free guidance\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        t = torch.randint(0, num_steps, (batch.shape[0],), device=device, dtype=torch.long)\n",
    "        x_t = diffusion.q_sample(batch, t)\n",
    "        context = batch[:, :1] if np.random.rand() > dropout_prob else None\n",
    "        logits = model(x_t, t, context=context)\n",
    "        loss = F.cross_entropy(logits.view(-1, vocab_size), batch.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(dataloader):.4f}\")\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        checkpoint = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"loss\": total_loss / len(dataloader),\n",
    "        }\n",
    "        torch.save(checkpoint, f\"../models/d3pm_epoch_{epoch + 1}.pth\")\n",
    "        print(f\"Saved checkpoint: d3pm_epoch_{epoch + 1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a5bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples with context\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    context = torch.tensor([[word_to_idx[\"the\"], word_to_idx[\"dog\"]]], device=device)\n",
    "    samples = diffusion.sample(model, batch_size=3, device=device, context=context, guidance_scale=2.0)\n",
    "    for sample in samples:\n",
    "        text = [idx_to_word[idx.item()] for idx in sample if idx.item() in idx_to_word]\n",
    "        print(\"Generated:\", \" \".join(text).replace(\"<pad>\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8adfe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-implementations (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
