{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e60c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n",
      "env: PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0\n"
     ]
    }
   ],
   "source": [
    "# | default_exp attention\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "%env PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4404c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "from icecream import ic\n",
    "import math\n",
    "from my_transformer.utils import save_model, load_model\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, normalizers\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "import json\n",
    "import os\n",
    "\n",
    "# from rich import print\n",
    "from rich.pretty import pprint\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b82294f",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7edbbc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Hard Times In New York Town',\n",
       "  'Come you ladies and you gentlemen, a-listen to my song',\n",
       "  'Sing it to you right, but you might think itâ€™s wrong',\n",
       "  'Just a little glimpse of a story Iâ€™ll tell',\n",
       "  'â€™Bout an East Coast city that you all know well',\n",
       "  'Itâ€™s hard times in the city',\n",
       "  'Livinâ€™ down in New York town',\n",
       "  'Old New York City is a friendly old town',\n",
       "  'From Washington Heights to Harlem on down',\n",
       "  'Thereâ€™s a-mighty many people all millinâ€™ all around'],\n",
       " 14318)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset/bob_dylan_lyrics.csv\")\n",
    "lines = []\n",
    "nb_rows = 999999\n",
    "row_id = 0\n",
    "for r in df.iterrows():\n",
    "    # todo: one line is one sentence.\n",
    "    lines.append(r[1][\"title\"])\n",
    "    # sentences.append(r[1][\"title\"] + \"\\n\" + r[1][\"lyrics\"])\n",
    "    lyrics = r[1][\"lyrics\"].split(\"\\n\")\n",
    "    for line in lyrics:\n",
    "        if len(line.strip()) > 0:\n",
    "            lines.append(line.strip())\n",
    "        row_id += 1\n",
    "\n",
    "lines[:10], len(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6bab58",
   "metadata": {},
   "source": [
    "### Simple Custom Tokenizer for Bob Dylan Lyrics\n",
    "\n",
    "Create a simple BPE (Byte-Pair Encoding) tokenizer trained specifically on Dylan's lyrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92266e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDylanTokenizer:\n",
    "    def __init__(self, vocab_size=3000):\n",
    "        vocab_size = vocab_size\n",
    "        tokenizer = None\n",
    "\n",
    "    def train_tokenizer(self, corpus: list[str], save_path: str = \"./simple_dylan_tokenizer\"):\n",
    "        # Initialize simple BPE tokenizer\n",
    "        tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "\n",
    "        # Simple whitespace pre-tokenization\n",
    "        tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "        # Simple trainer\n",
    "        trainer = BpeTrainer(\n",
    "            vocab_size=self.vocab_size, special_tokens=[\"[PAD]\", \"[UNK]\", \"[MASK]\"], min_frequency=2, show_progress=True\n",
    "        )\n",
    "\n",
    "        # Train the tokenizer\n",
    "        tokenizer.train_from_iterator(corpus, trainer)\n",
    "\n",
    "        # Save tokenizer\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        tokenizer.save(f\"{save_path}/tokenizer.json\")\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        print(f\"Tokenizer trained and saved to {save_path}\")\n",
    "\n",
    "        return tokenizer\n",
    "\n",
    "    def load_tokenizer(self, save_path=\"./simple_dylan_tokenizer\"):\n",
    "        \"\"\"Load the trained tokenizer\"\"\"\n",
    "        tokenizer_path = f\"{save_path}/tokenizer.json\"\n",
    "        if os.path.exists(tokenizer_path):\n",
    "            self.tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "            return self.tokenizer\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Tokenizer not found at {tokenizer_path}\")\n",
    "\n",
    "    def get_transformers_tokenizer(self):\n",
    "        \"\"\"Convert to HuggingFace tokenizer for compatibility\"\"\"\n",
    "        if self.tokenizer is None:\n",
    "            raise ValueError(\"Tokenizer not trained or loaded\")\n",
    "\n",
    "        # Create fast tokenizer wrapper\n",
    "        fast_tokenizer = PreTrainedTokenizerFast(\n",
    "            tokenizer_object=self.tokenizer, pad_token=\"[PAD]\", unk_token=\"[UNK]\", mask_token=\"[MASK]\"\n",
    "        )\n",
    "\n",
    "        return fast_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76920799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(tokenizer): 3000\n",
      "ic| tokenizer.special_tokens_map: {'mask_token': '[MASK]', 'pad_token': '[PAD]', 'unk_token': '[UNK]'}\n",
      "| len(tokenizer): 3000\n",
      "ic| tokenizer.special_tokens_map: {'mask_token': '[MASK]', 'pad_token': '[PAD]', 'unk_token': '[UNK]'}\n",
      "ic| phrase: \"The answer my friend is blowin' in the wind\"\n",
      "ic| decoded:ic| phrase: \"The answer my friend is blowin' in the wind\"\n",
      "ic| decoded:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Tokenizer trained and saved to ./simple_dylan_tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \"The answer my friend is blowin ' in the wind\"\n",
      "ic| token_strs: ['The', 'answer',\"The answer my friend is blowin ' in the wind\"\n",
      "ic| token_strs: ['The', 'answer', 'my', 'friend', 'is', 'blowin', \"'\", 'in', 'the', 'wind']\n",
      " 'my', 'friend', 'is', 'blowin', \"'\", 'in', 'the', 'wind']\n"
     ]
    }
   ],
   "source": [
    "# Initialize simple Dylan tokenizer\n",
    "dylan_tokenizer = SimpleDylanTokenizer(vocab_size=3000)\n",
    "\n",
    "# Train the tokenizer on Dylan lyrics\n",
    "dylan_tokenizer.train_tokenizer(corpus=lines, save_path=\"./simple_dylan_tokenizer\")\n",
    "\n",
    "# Convert to HuggingFace format for compatibility\n",
    "tokenizer = dylan_tokenizer.get_transformers_tokenizer()\n",
    "\n",
    "ic(len(tokenizer))\n",
    "ic(tokenizer.special_tokens_map)\n",
    "\n",
    "\n",
    "phrase = \"The answer my friend is blowin' in the wind\"\n",
    "\n",
    "tokens = tokenizer.encode(phrase, add_special_tokens=False)\n",
    "decoded = tokenizer.decode(tokens, skip_special_tokens=False)\n",
    "token_strs = tokenizer.convert_ids_to_tokens(tokens)\n",
    "ic(phrase)\n",
    "ic(decoded)\n",
    "ic(token_strs);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a50552a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(dataset): 14318\n",
      "ic| seq_len: 20\n",
      "ic| len(tokenizer): 3000\n",
      "ic| len(dataset): 14318\n",
      "ic| seq_len: 20\n",
      "ic| len(tokenizer): 3000\n",
      "ic| sample_batch.shape: torch.Size([8, 20])\n",
      "ic| tokenizer.decode(sample_batch[0].tolist(), skip_special_tokens=False): ('He â€™ s eat in â€™ ch it lin s [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "| sample_batch.shape: torch.Size([8, 20])\n",
      "ic| tokenizer.decode(sample_batch[0].tolist(), skip_special_tokens=False): ('He â€™ s eat in â€™ ch it lin s [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
      "                                                                            '[PAD] [PAD]')                                                                            '[PAD] [PAD]')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length in dataset: 41\n"
     ]
    }
   ],
   "source": [
    "class SimpleDylanDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, seq_len=128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "        self.examples = []\n",
    "        max_seq_len = 0\n",
    "\n",
    "        for line in texts:\n",
    "            # Simple tokenization - no structure tokens\n",
    "            tokens = tokenizer.encode(line.strip(), add_special_tokens=False)\n",
    "            token_nb = len(tokens)\n",
    "            max_seq_len = max(max_seq_len, token_nb)\n",
    "            # Truncate if too long\n",
    "\n",
    "            if token_nb > seq_len:\n",
    "                tokens = tokens[:seq_len]\n",
    "\n",
    "            if token_nb > 0:  # Skip empty sequences\n",
    "                self.examples.append(tokens)\n",
    "        print(f\"Max sequence length in dataset: {max_seq_len}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.examples[idx]\n",
    "        pad_id = self.tokenizer.pad_token_id if hasattr(self.tokenizer, \"pad_token_id\") else 0\n",
    "\n",
    "        # Pad to sequence length\n",
    "        padded = tokens + [pad_id] * (self.seq_len - len(tokens))\n",
    "        return torch.tensor(padded[: self.seq_len], dtype=torch.long)\n",
    "\n",
    "\n",
    "seq_len = 20  # Keep shorter sequences for memory efficiency\n",
    "batch_size = 8\n",
    "\n",
    "# Create dataset with selected tokenizer\n",
    "dataset = SimpleDylanDataset(lines, tokenizer, seq_len=seq_len)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "ic(len(dataset))\n",
    "ic(seq_len)\n",
    "ic(len(tokenizer))\n",
    "\n",
    "# Test the dataset\n",
    "sample_batch = next(iter(dataloader))\n",
    "ic(sample_batch.shape)\n",
    "ic(tokenizer.decode(sample_batch[0].tolist(), skip_special_tokens=False));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af94d38b",
   "metadata": {},
   "source": [
    "## Diffusion model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "54f5a9a5",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Timeline:  xâ‚€ â”€â”€â”€â”€â†’ xâ‚ â”€â”€â”€â”€â†’ xâ‚‚ â”€â”€â”€â”€â†’ xâ‚ƒ\n",
    "          clean   noisy   noisier  noisiest\n",
    "           â†‘        â†‘        â†‘        â†‘\n",
    "         \"hello\"  \"h[M]lo\" \"[M][M]o\" \"[M][M][M]\"\n",
    "\n",
    "Forward process q(x_t | x_{t-1}):\n",
    "- q(xâ‚|xâ‚€): \"hello\" â†’ \"h[M]lo\" (add some noise)\n",
    "- q(xâ‚‚|xâ‚): \"h[M]lo\" â†’ \"[M][M]o\" (add more noise)\n",
    "\n",
    "Posterior q(x_{t-1} | x_t, xâ‚€):\n",
    "- q(xâ‚|xâ‚‚, xâ‚€): Given \"[M][M]o\" and knowing original was \"hello\", \n",
    "                 what was xâ‚? Answer: probably \"h[M]lo\"\n",
    "- q(xâ‚€|xâ‚, xâ‚€): Given \"h[M]lo\" and knowing original was \"hello\",\n",
    "                 what was xâ‚€? Answer: definitely \"hello\"\n",
    "\n",
    "\n",
    "# The KL loss compares:\n",
    "KL[q(x_{t-1}|x_t,x_0) || p_Î¸(x_{t-1}|x_t)]\n",
    "   â†‘                    â†‘\n",
    "   True denoising       Model's denoising\n",
    "   (uses ground truth) (learned)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beb72e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformScheduler(nn.Module):\n",
    "    \"\"\"Simple uniform transition scheduler with linear noise schedule.\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int, num_timesteps: int, beta_start: float = 0.0001, beta_end: float = 0.02):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "\n",
    "        # Create schedule and transition matrices\n",
    "        betas = self._create_linear_schedule()\n",
    "        # so they are put to device automatically\n",
    "        self.register_buffer(\"betas\", betas)\n",
    "        Q_t = self._create_transition_matrices()\n",
    "        self.register_buffer(\"Q_t\", Q_t)\n",
    "        Q_bar_t = self._create_cumulative_matrices()\n",
    "        self.register_buffer(\"Q_bar_t\", Q_bar_t)\n",
    "\n",
    "    def _create_linear_schedule(self) -> torch.Tensor:\n",
    "        \"\"\"Create linear beta schedule: Î²_t increases linearly from beta_start to beta_end.\"\"\"\n",
    "        return torch.linspace(self.beta_start, self.beta_end, self.num_timesteps)\n",
    "\n",
    "    def _create_transition_matrices(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Create uniform transition matrices: Q_t = (1-Î²_t)I + Î²_t/K * 11^T\n",
    "\n",
    "        This means:\n",
    "        - Stay in same state with probability (1-Î²_t)\n",
    "        - Transition to any state (including same) with probability Î²_t/K each\n",
    "        \"\"\"\n",
    "        Q_matrices = torch.zeros(self.num_timesteps, self.num_classes, self.num_classes)\n",
    "\n",
    "        for t in range(self.num_timesteps):\n",
    "            beta_t = self.betas[t].item()\n",
    "\n",
    "            # Diagonal: probability of staying in same state\n",
    "            Q_t = (1 - beta_t) * torch.eye(self.num_classes)\n",
    "\n",
    "            # Off-diagonal: uniform probability of transitioning to any state\n",
    "            Q_t += beta_t / self.num_classes * torch.ones(self.num_classes, self.num_classes)\n",
    "\n",
    "            Q_matrices[t] = Q_t\n",
    "\n",
    "        return Q_matrices\n",
    "\n",
    "    def _create_cumulative_matrices(self) -> torch.Tensor:\n",
    "        \"\"\"Create cumulative matrices: QÌ„_t = Q_1 * Q_2 * ... * Q_t\"\"\"\n",
    "        Q_bar_matrices = torch.zeros(self.num_timesteps, self.num_classes, self.num_classes)\n",
    "        Q_bar_matrices[0] = self.Q_t[0]\n",
    "\n",
    "        for t in range(1, self.num_timesteps):\n",
    "            Q_bar_matrices[t] = torch.matmul(Q_bar_matrices[t - 1], self.Q_t[t])\n",
    "\n",
    "        return Q_bar_matrices\n",
    "\n",
    "    def add_noise(self, x_0: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Apply forward diffusion: sample from q(x_t | x_0).\n",
    "\n",
    "        For uniform transitions, this uses the cumulative matrix QÌ„_t.\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x_0.shape\n",
    "        device = x_0.device\n",
    "\n",
    "        # Clamp x_0 to valid token range to prevent out-of-bounds errors\n",
    "        x_0_clamped = torch.clamp(x_0, 0, self.num_classes - 1)\n",
    "\n",
    "        # Convert to one-hot encoding\n",
    "        x_0_onehot = F.one_hot(x_0_clamped, self.num_classes).to(device).float()  # [B, L, K]\n",
    "\n",
    "        x_t = torch.zeros_like(x_0).to(device)  # [B, L]\n",
    "        self.Q_bar_t = self.Q_bar_t.to(device)  # Ensure matrices are on the correct device\n",
    "        for i in range(batch_size):\n",
    "            # Get cumulative transition matrix for this timestep\n",
    "            t_val = t[i].item()\n",
    "\n",
    "            # Add bounds checking to prevent IndexError\n",
    "            t_val = max(0, min(t_val, self.num_timesteps - 1))\n",
    "\n",
    "            Q_bar = self.Q_bar_t[t_val].to(device)  # [K, K]\n",
    "\n",
    "            # Compute transition probabilities: x_0 @ QÌ„_t\n",
    "            # This gives probability distribution over x_t for each position\n",
    "            probs = torch.matmul(x_0_onehot[i], Q_bar)  # [L, K]\n",
    "\n",
    "            # Add numerical stability: ensure probabilities are non-negative and sum to 1\n",
    "            probs = torch.clamp(probs, min=1e-8)  # Ensure non-negative\n",
    "            probs = probs / probs.sum(dim=-1, keepdim=True)  # Normalize\n",
    "\n",
    "            # Sample from categorical distribution\n",
    "            flat_probs = probs.view(-1, self.num_classes)  # [L, K]\n",
    "\n",
    "            # Additional safety check for multinomial\n",
    "            prob_sums = flat_probs.sum(dim=-1)\n",
    "            if (prob_sums <= 0).any():\n",
    "                print(f\"Warning: Invalid probability distribution detected\")\n",
    "                print(f\"prob_sums: {prob_sums}\")\n",
    "                print(f\"flat_probs sample: {flat_probs[0]}\")\n",
    "                # Fallback to uniform distribution\n",
    "                flat_probs = torch.ones_like(flat_probs) / self.num_classes\n",
    "\n",
    "            flat_samples = torch.multinomial(flat_probs, 1).squeeze(-1)  # [L]\n",
    "            x_t[i] = flat_samples\n",
    "\n",
    "        return x_t\n",
    "\n",
    "    def get_posterior_params(self, x_t: torch.Tensor, x_0: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute true posterior q(x_{t-1} | x_t, x_0) using Equation 3.\n",
    "\n",
    "        From the paper: q(x_{t-1}|x_t,x_0) = Cat(x_{t-1}; p = x_t Q_t^T âŠ™ x_0 QÌ„_{t-1} / (x_0 QÌ„_t x_t^T))\n",
    "\n",
    "        This tells us: given we observe x_t at time t and know the original was x_0,\n",
    "        what's the probability distribution over what x_{t-1} could have been?\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x_t.shape\n",
    "        device = x_t.device\n",
    "\n",
    "        # Clamp token indices to valid range\n",
    "        x_t_clamped = torch.clamp(x_t, 0, self.num_classes - 1)\n",
    "        x_0_clamped = torch.clamp(x_0, 0, self.num_classes - 1)\n",
    "\n",
    "        posteriors = torch.zeros(batch_size, seq_len, self.num_classes, device=device)\n",
    "\n",
    "        for i, t_val in enumerate(t):\n",
    "            # Add bounds checking here too\n",
    "            t_val = max(0, min(t_val.item(), self.num_timesteps - 1))\n",
    "\n",
    "            if t_val == 0:\n",
    "                # Special case: t=0 means we're asking for q(x_{-1}|x_0, x_0)\n",
    "                # This doesn't make physical sense, so return uniform or x_0\n",
    "                # In practice, this case shouldn't occur in training\n",
    "                posteriors[i] = F.one_hot(x_0_clamped[i], self.num_classes).float()\n",
    "                continue\n",
    "\n",
    "            # Get transition matrices\n",
    "            Q_t = self.Q_t[t_val].to(device)  # [K, K] - single step t\n",
    "            Q_bar_t_minus_1 = self.Q_bar_t[t_val - 1].to(device)  # [K, K] - cumulative to t-1\n",
    "            Q_bar_t = self.Q_bar_t[t_val].to(device)  # [K, K] - cumulative to t\n",
    "\n",
    "            # For each position in sequence\n",
    "            for pos in range(seq_len):\n",
    "                x_0_idx = x_0_clamped[i, pos].item()  # Original token index (clamped)\n",
    "                x_t_idx = x_t_clamped[i, pos].item()  # Current token index (clamped)\n",
    "\n",
    "                # Compute posterior using Bayes rule:\n",
    "                # q(x_{t-1}|x_t,x_0) âˆ q(x_t|x_{t-1},x_0) * q(x_{t-1}|x_0)\n",
    "                #                    = q(x_t|x_{t-1}) * q(x_{t-1}|x_0)  [Markov property]\n",
    "\n",
    "                posterior = torch.zeros(self.num_classes, device=device)\n",
    "\n",
    "                # For each possible value of x_{t-1}\n",
    "                for x_prev_idx in range(self.num_classes):\n",
    "                    # q(x_{t-1}|x_0): probability that x_{t-1} = x_prev_idx given x_0\n",
    "                    q_prev_given_x0 = Q_bar_t_minus_1[x_0_idx, x_prev_idx]\n",
    "\n",
    "                    # q(x_t|x_{t-1}): probability that x_t = x_t_idx given x_{t-1} = x_prev_idx\n",
    "                    q_curr_given_prev = Q_t[x_prev_idx, x_t_idx]\n",
    "\n",
    "                    # Joint probability\n",
    "                    posterior[x_prev_idx] = q_curr_given_prev * q_prev_given_x0\n",
    "\n",
    "                # Normalize to get proper probability distribution\n",
    "                posterior_sum = posterior.sum()\n",
    "                if posterior_sum > 1e-8:\n",
    "                    posterior = posterior / posterior_sum\n",
    "                else:\n",
    "                    # Fallback to uniform if numerical issues\n",
    "                    posterior = torch.ones(self.num_classes, device=device) / self.num_classes\n",
    "\n",
    "                posteriors[i, pos] = posterior\n",
    "\n",
    "        return posteriors\n",
    "\n",
    "    def compute_kl_divergence(self, true_posterior: torch.Tensor, pred_posterior: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute KL[q(x_{t-1}|x_t,x_0) || p_Î¸(x_{t-1}|x_t)]\"\"\"\n",
    "        kl = torch.sum(true_posterior * (torch.log(true_posterior + 1e-8) - torch.log(pred_posterior + 1e-8)), dim=-1)\n",
    "        return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d24517b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=1: x_0: [42, 15, 73], x_t: [42, 15, 73], true x_{t-1}: [42, 15, 73],\n",
      "equals x_0: True\n",
      "t=10: x_0: [42, 15, 73], x_t: [42, 15, 73], true x_{t-1}: [42, 15, 73],\n",
      "equals x_0: True\n",
      "t=50: x_0: [42, 15, 73], x_t: [42, 15, 73], true x_{t-1}: [42, 15, 73],\n",
      "equals x_0: True\n",
      "t=100: x_0: [42, 15, 73], x_t: [42, 15, 73], true x_{t-1}: [42, 15, 73],\n",
      "equals x_0: True\n",
      "t=500: x_0: [42, 15, 73], x_t: [37, 94, 41], true x_{t-1}: [37, 94, 41],\n",
      "equals x_0: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler = UniformScheduler(num_classes=100, num_timesteps=1000).to(device)\n",
    "\n",
    "x_0 = torch.tensor([[42, 15, 73]])  # Original tokens\n",
    "\n",
    "# Check at different timesteps\n",
    "for t_val in [1, 10, 50, 100, 500]:\n",
    "    t = torch.tensor([t_val])\n",
    "    x_t = scheduler.add_noise(x_0, t)\n",
    "\n",
    "    true_posterior = scheduler.get_posterior_params(x_t, x_0, t)\n",
    "    true_prev = true_posterior.argmax(dim=-1)\n",
    "\n",
    "    print(\n",
    "        f\"t={t_val}: x_0: {x_0[0].tolist()}, x_t: {x_t[0].tolist()}, true x_{{t-1}}: {true_prev[0].tolist()},\\nequals x_0: {true_prev[0].equal(x_0[0])}\"\n",
    "    )\n",
    "scheduler.Q_t.device, scheduler.Q_bar_t.device\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac5fd249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing posterior evolution...\n",
      "Evolution of posterior q(x_{t-1} | x_t, x_0) as t increases:\n",
      "(Shows probability of each token being x_{t-1})\n",
      "\n",
      "t=1, x_0=1, x_t=1,  P(x_{t-1} = k): ['0.001', '0.996', '0.001', '0.001', '0.001'],Most likely x_{t-1}: 1\n",
      "t=2, x_0=1, x_t=2,  P(x_{t-1} = k): ['0.032', '0.461', '0.444', '0.032', '0.032'],Most likely x_{t-1}: 1\n",
      "t=3, x_0=1, x_t=1,  P(x_{t-1} = k): ['0.015', '0.941', '0.015', '0.015', '0.015'],Most likely x_{t-1}: 1\n",
      "t=4, x_0=1, x_t=0,  P(x_{t-1} = k): ['0.517', '0.260', '0.074', '0.074', '0.074'],Most likely x_{t-1}: 0\n",
      "t=5, x_0=1, x_t=4,  P(x_{t-1} = k): ['0.097', '0.205', '0.097', '0.097', '0.504'],Most likely x_{t-1}: 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test that posterior evolves correctly as we move through timesteps.\"\"\"\n",
    "print(\"Testing posterior evolution...\")\n",
    "\n",
    "vocab_size = 5  # Very small for clear visualization\n",
    "scheduler = UniformScheduler(num_classes=vocab_size, num_timesteps=10, beta_start=0.1, beta_end=0.9).to(device)\n",
    "\n",
    "x_0 = torch.tensor([[1]])  # Single token, original = 1\n",
    "\n",
    "print(\"Evolution of posterior q(x_{t-1} | x_t, x_0) as t increases:\")\n",
    "print(\"(Shows probability of each token being x_{t-1})\")\n",
    "print()\n",
    "\n",
    "for t_val in range(1, 6):\n",
    "    t = torch.tensor([t_val])\n",
    "    x_t = scheduler.add_noise(x_0, t)\n",
    "    posterior = scheduler.get_posterior_params(x_t, x_0, t)\n",
    "    true_prev = posterior.argmax(dim=-1)\n",
    "\n",
    "    print(\n",
    "        f\"t={t_val}, x_0=1, x_t={x_t[0, 0].item()},  P(x_{{t-1}} = k): {[f'{p:.3f}' for p in posterior[0, 0].tolist()]},Most likely x_{{t-1}}: {posterior[0, 0].argmax().item()}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f727c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| inp.shape: torch.Size([8, 20])\n",
      "| inp.shape: torch.Size([8, 20])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes , here â€™ s the story of the H ur rican e [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Yes , here â€™ s the story of the H ur rican e [PAD] [PAD] [PAD] rag [PAD] [PAD] [PAD]\n",
      "Yes Seen here vent s the story Mu the H desert rican such [PAD] [PAD] feels [PAD] [PAD] [PAD] wherever\n",
      "Yes , walls â€™ s ft story of the H ur rican e [PAD] rs [PAD] [PAD] [PAD] [PAD] carry\n"
     ]
    }
   ],
   "source": [
    "# Generate some noisy sentences\n",
    "inp = next(iter(dataloader)).to(device)\n",
    "ic(inp.shape)\n",
    "\n",
    "ds_scheduler = UniformScheduler(num_classes=len(tokenizer), num_timesteps=30)\n",
    "\n",
    "\n",
    "def demo_noise(inp, line_nb, step):\n",
    "    src_line = tokenizer.decode(inp[line_nb].cpu().numpy())\n",
    "    noisy_inp = ds_scheduler.add_noise(inp[line_nb : line_nb + 1], torch.tensor([step]).to(device))\n",
    "    noisy_line = tokenizer.decode(noisy_inp[0].cpu().numpy())\n",
    "    return src_line, noisy_line\n",
    "\n",
    "\n",
    "ic.disable()\n",
    "ic.enable()\n",
    "sent_nb = 4\n",
    "print(demo_noise(inp, sent_nb, 0)[1])\n",
    "print(demo_noise(inp, sent_nb, 12)[1])\n",
    "print(demo_noise(inp, sent_nb, 20)[1])\n",
    "print(demo_noise(inp, sent_nb, 29)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4de9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleD3PMModel(nn.Module):\n",
    "    \"\"\"Simple transformer model for D3PM.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        max_seq_len: int,\n",
    "        d_model: int = 256,\n",
    "        num_heads: int = 8,\n",
    "        num_layers: int = 4,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Embeddings\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_embedding = nn.Embedding(max_seq_len, d_model)\n",
    "\n",
    "        # Time embedding for diffusion timestep\n",
    "        self.time_embedding = nn.Sequential(nn.Linear(d_model, d_model), nn.GELU(), nn.Linear(d_model, d_model))\n",
    "\n",
    "        # Transformer layers\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=4 * d_model,\n",
    "            dropout=dropout,\n",
    "            activation=\"gelu\",\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "\n",
    "        # Output head to predict xâ‚€\n",
    "        self.output_head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, vocab_size))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def _get_time_embedding(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Create sinusoidal time embeddings like in original Transformer.\"\"\"\n",
    "        half_dim = self.d_model // 2\n",
    "\n",
    "        # Create the frequency ratios\n",
    "        freqs = torch.exp(\n",
    "            -math.log(10000.0) * torch.arange(0, half_dim, dtype=torch.float32, device=t.device) / half_dim\n",
    "        )\n",
    "\n",
    "        # Expand dims to enable broadcasting: t is [batch_size], freqs is [half_dim]\n",
    "        time_freqs = t.float()[:, None] * freqs[None, :]  # [batch_size, half_dim]\n",
    "\n",
    "        # Create sin and cos components\n",
    "        emb = torch.cat([torch.sin(time_freqs), torch.cos(time_freqs)], dim=1)  # [batch_size, d_model]\n",
    "\n",
    "        if self.d_model % 2 == 1:  # Handle odd d_model\n",
    "            emb = torch.cat([emb, torch.zeros_like(emb[:, :1])], dim=1)\n",
    "\n",
    "        return self.time_embedding(emb)\n",
    "\n",
    "    def forward(self, x_t: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass: predict xâ‚€ from x_t.\n",
    "\n",
    "        Args:\n",
    "            x_t: Noisy tokens, shape [batch_size, seq_len]\n",
    "            t: Timesteps, shape [batch_size]\n",
    "\n",
    "        Returns:\n",
    "            x0_logits: Predicted xâ‚€ logits, shape [batch_size, seq_len, vocab_size]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x_t.shape\n",
    "        device = x_t.device\n",
    "\n",
    "        # Token embeddings\n",
    "        token_emb = self.token_embedding(x_t)  # [B, L, D]\n",
    "\n",
    "        # Position embeddings\n",
    "        positions = torch.arange(seq_len, device=device).unsqueeze(0).expand(batch_size, -1)\n",
    "        pos_emb = self.position_embedding(positions)  # [B, L, D]\n",
    "\n",
    "        # Time embeddings\n",
    "        time_emb = self._get_time_embedding(t)  # [B, D]\n",
    "        time_emb = time_emb.unsqueeze(1).expand(-1, seq_len, -1)  # [B, L, D]\n",
    "\n",
    "        # Combine all embeddings\n",
    "        x = self.dropout(token_emb + pos_emb + time_emb)  # [B, L, D]\n",
    "\n",
    "        # Transformer processing\n",
    "        x = self.transformer(x)  # [B, L, D]\n",
    "\n",
    "        # Predict xâ‚€ logits\n",
    "        x0_logits = self.output_head(x)  # [B, L, vocab_size]\n",
    "\n",
    "        return x0_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0a19a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x_t.shape: torch.Size([8, 20])\n",
      "    x0_logits.shape: torch.Size([8, 20, 1000])\n",
      "    t.shape: torch.Size([8])\n",
      "| x_t.shape: torch.Size([8, 20])\n",
      "    x0_logits.shape: torch.Size([8, 20, 1000])\n",
      "    t.shape: torch.Size([8])\n",
      "ic| scheduler.Q_t.shape: torch.Size([50, 1000, 1000])\n",
      "    scheduler.Q_bar_t.shape: torch.Size([50, 1000, 1000])\n",
      "ic| scheduler.Q_t.shape: torch.Size([50, 1000, 1000])\n",
      "    scheduler.Q_bar_t.shape: torch.Size([50, 1000, 1000])\n"
     ]
    }
   ],
   "source": [
    "def compute_predicted_posterior(\n",
    "    scheduler: UniformScheduler, x0_logits: torch.Tensor, x_t: torch.Tensor, t: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute p_Î¸(x_{t-1}|x_t) using xâ‚€-parameterization.\n",
    "\n",
    "    From Equation 4: p_Î¸(x_{t-1}|x_t) âˆ Î£ q(x_{t-1},x_t|xÌƒâ‚€) pÌƒ_Î¸(xÌƒâ‚€|x_t)\n",
    "\n",
    "    The true posterior is: q(x_{t-1}|x_t,xâ‚€) âˆ q(x_t|x_{t-1}) q(x_{t-1}|xâ‚€)\n",
    "\n",
    "    This is a fully vectorized implementation with no loops.\n",
    "    \"\"\"\n",
    "    batch_size, seq_len = x_t.shape\n",
    "    device = x_t.device\n",
    "    num_classes = scheduler.num_classes\n",
    "\n",
    "    # Convert model logits to probabilities\n",
    "    p_x0_given_xt = F.softmax(x0_logits, dim=-1)  # [B, L, K]\n",
    "\n",
    "    # Initialize result tensor\n",
    "    pred_posteriors = torch.zeros(batch_size, seq_len, num_classes, device=device)\n",
    "\n",
    "    # Handle t=0 case separately (early return for efficiency)\n",
    "    t_zero_mask = t == 0\n",
    "    if t_zero_mask.any():\n",
    "        # For t=0 cases, return softmax of x0_logits\n",
    "        pred_posteriors[t_zero_mask] = p_x0_given_xt[t_zero_mask]\n",
    "\n",
    "        # If all timesteps are 0, return early\n",
    "        if t_zero_mask.all():\n",
    "            return pred_posteriors\n",
    "\n",
    "    # Process non-zero timesteps\n",
    "    non_zero_mask = ~t_zero_mask\n",
    "    if not non_zero_mask.any():\n",
    "        return pred_posteriors\n",
    "\n",
    "    # Get indices for non-zero timesteps\n",
    "    t_non_zero = t[non_zero_mask]  # [N] where N = number of non-zero timesteps\n",
    "\n",
    "    # Get transition matrices for all non-zero timesteps\n",
    "    # Stack Q_t and Q_{t-1} matrices for vectorized operations\n",
    "    Q_t_stack = torch.stack([scheduler.Q_t[t_val] for t_val in t_non_zero])  # [N, K, K]\n",
    "    Q_t_minus_1_stack = torch.stack([scheduler.Q_t[t_val - 1] for t_val in t_non_zero])  # [N, K, K]\n",
    "\n",
    "    # Get relevant data for non-zero timesteps\n",
    "    x_t_non_zero = x_t[non_zero_mask]  # [N, L]\n",
    "    p_x0_non_zero = p_x0_given_xt[non_zero_mask]  # [N, L, K]\n",
    "\n",
    "    # Vectorized computation of posterior for all positions and timesteps\n",
    "    # We need to compute: Î£_{x0} p(x0|xt) * q(x_{t-1}|xt,x0)\n",
    "    # where q(x_{t-1}|xt,x0) âˆ q(xt|x_{t-1}) * q(x_{t-1}|x0)\n",
    "\n",
    "    # Create index tensors for gathering\n",
    "    batch_indices = torch.arange(len(t_non_zero), device=device)[:, None]  # [N, 1]\n",
    "    x_t_indices = x_t_non_zero  # [N, L] - current token indices\n",
    "\n",
    "    # For each possible x_{t-1} value, compute the posterior probability\n",
    "    pred_posterior_non_zero = torch.zeros(len(t_non_zero), seq_len, num_classes, device=device)\n",
    "\n",
    "    for x_prev in range(num_classes):\n",
    "        # For this x_{t-1} value, compute contribution from all possible x0 values\n",
    "\n",
    "        # q(x_t|x_{t-1}): transition probability from x_prev to current tokens\n",
    "        # Shape operations: Q_t_stack[batch_indices, x_prev, x_t_indices]\n",
    "        q_xt_given_xprev = Q_t_stack[batch_indices, x_prev, x_t_indices]  # [N, L]\n",
    "\n",
    "        # Avoid division by zero\n",
    "        Q_t_minus_1_vals = Q_t_minus_1_stack[batch_indices, x_prev, x_t_indices]  # [N, L]\n",
    "        q_xt_given_xprev = q_xt_given_xprev / (Q_t_minus_1_vals + 1e-8)\n",
    "\n",
    "        # q(x_{t-1}|x0): probability of being at x_prev given each possible x0\n",
    "        # Q_t_minus_1_stack[:, x0_indices, x_prev] for all x0_indices\n",
    "        q_xprev_given_x0 = Q_t_minus_1_stack[:, :, x_prev]  # [N, K]\n",
    "\n",
    "        # Expand dimensions for broadcasting\n",
    "        q_xt_given_xprev_expanded = q_xt_given_xprev[:, :, None]  # [N, L, 1]\n",
    "        q_xprev_given_x0_expanded = q_xprev_given_x0[:, None, :]  # [N, 1, K]\n",
    "\n",
    "        # Compute unnormalized posterior contribution for this x_{t-1}\n",
    "        # Shape: [N, L, K] = [N, L, 1] * [N, 1, K] * [N, L, K]\n",
    "        unnorm_contrib = q_xt_given_xprev_expanded * q_xprev_given_x0_expanded * p_x0_non_zero\n",
    "\n",
    "        # Sum over all possible x0 values (marginalization)\n",
    "        pred_posterior_non_zero[:, :, x_prev] = unnorm_contrib.sum(dim=-1)  # [N, L]\n",
    "\n",
    "    # Normalize the posterior distributions\n",
    "    pred_posterior_non_zero = pred_posterior_non_zero / (pred_posterior_non_zero.sum(dim=-1, keepdim=True) + 1e-8)\n",
    "\n",
    "    # Place results back into the full tensor\n",
    "    pred_posteriors[non_zero_mask] = pred_posterior_non_zero\n",
    "\n",
    "    return pred_posteriors\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "vocab_size = 1000\n",
    "seq_len = 20\n",
    "num_timesteps = 50  # Total number of timesteps\n",
    "t = torch.randint(0, num_timesteps, (batch_size,), device=device)\n",
    "x_t = torch.randint(0, vocab_size, (batch_size, seq_len), device=device)  # Simulated noisy input\n",
    "x0_logits = torch.randn(batch_size, seq_len, vocab_size, device=device)  # Simulated model output\n",
    "ic(x_t.shape, x0_logits.shape, t.shape)\n",
    "\n",
    "scheduler = UniformScheduler(num_classes=vocab_size, num_timesteps=num_timesteps).to(device)\n",
    "ic(scheduler.Q_t.shape, scheduler.Q_bar_t.shape)\n",
    "pred_posterior = compute_predicted_posterior(scheduler=scheduler, x0_logits=x0_logits, x_t=x_t, t=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43db492b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¨ Visual demonstration of compute_predicted_posterior...\n",
      "\n",
      "ðŸ” Timestep t = 0:\n",
      "   Input x_t: [[0, 1, 2], [2, 0, 1]],  Predicted x0 (argmax): [[0, 1, 2], [3, 0, 1]]\n",
      "   Posterior p(x_{t-1}|x_t) for each position:\n",
      "     Batch 0, Pos 0: most likely x_{t-1} = 0 (prob=0.980)full distribution: ['0.980', '0.007', '0.007', '0.007']\n",
      "     Batch 0, Pos 1: most likely x_{t-1} = 1 (prob=0.980)full distribution: ['0.007', '0.980', '0.007', '0.007']\n",
      "     Batch 0, Pos 2: most likely x_{t-1} = 2 (prob=0.980)full distribution: ['0.007', '0.007', '0.980', '0.007']\n",
      "     Batch 1, Pos 0: most likely x_{t-1} = 3 (prob=0.980)full distribution: ['0.007', '0.007', '0.007', '0.980']\n",
      "     Batch 1, Pos 1: most likely x_{t-1} = 0 (prob=0.980)full distribution: ['0.980', '0.007', '0.007', '0.007']\n",
      "     Batch 1, Pos 2: most likely x_{t-1} = 1 (prob=0.980)full distribution: ['0.007', '0.980', '0.007', '0.007']\n",
      "   Entropy (uncertainty): [[0.11907892674207687, 0.11907892674207687, 0.11907892674207687], [0.11907892674207687, 0.11907892674207687, 0.11907892674207687]]\n",
      "\n",
      "ðŸ” Timestep t = 1:\n",
      "   Input x_t: [[0, 1, 2], [2, 0, 1]],  Predicted x0 (argmax): [[0, 1, 2], [3, 0, 1]]\n",
      "   Posterior p(x_{t-1}|x_t) for each position:\n",
      "     Batch 0, Pos 0: most likely x_{t-1} = 0 (prob=0.492)full distribution: ['0.492', '0.169', '0.169', '0.169']\n",
      "     Batch 0, Pos 1: most likely x_{t-1} = 1 (prob=0.492)full distribution: ['0.169', '0.492', '0.169', '0.169']\n",
      "     Batch 0, Pos 2: most likely x_{t-1} = 2 (prob=0.492)full distribution: ['0.169', '0.169', '0.492', '0.169']\n",
      "     Batch 1, Pos 0: most likely x_{t-1} = 3 (prob=0.987)full distribution: ['0.007', '0.007', '0.000', '0.987']\n",
      "     Batch 1, Pos 1: most likely x_{t-1} = 0 (prob=0.492)full distribution: ['0.492', '0.169', '0.169', '0.169']\n",
      "     Batch 1, Pos 2: most likely x_{t-1} = 1 (prob=0.492)full distribution: ['0.169', '0.492', '0.169', '0.169']\n",
      "   Entropy (uncertainty): [[1.2512774467468262, 1.2512774467468262, 1.2512774467468262], [0.08140797913074493, 1.2512774467468262, 1.2512774467468262]]\n",
      "\n",
      "ðŸ” Timestep t = 3:\n",
      "   Input x_t: [[0, 1, 2], [2, 0, 1]],  Predicted x0 (argmax): [[0, 1, 2], [3, 0, 1]]\n",
      "   Posterior p(x_{t-1}|x_t) for each position:\n",
      "     Batch 0, Pos 0: most likely x_{t-1} = 0 (prob=0.960)full distribution: ['0.960', '0.013', '0.013', '0.013']\n",
      "     Batch 0, Pos 1: most likely x_{t-1} = 1 (prob=0.960)full distribution: ['0.013', '0.960', '0.013', '0.013']\n",
      "     Batch 0, Pos 2: most likely x_{t-1} = 2 (prob=0.960)full distribution: ['0.013', '0.013', '0.960', '0.013']\n",
      "     Batch 1, Pos 0: most likely x_{t-1} = 3 (prob=0.976)full distribution: ['0.009', '0.009', '0.006', '0.976']\n",
      "     Batch 1, Pos 1: most likely x_{t-1} = 0 (prob=0.960)full distribution: ['0.960', '0.013', '0.013', '0.013']\n",
      "     Batch 1, Pos 2: most likely x_{t-1} = 1 (prob=0.960)full distribution: ['0.013', '0.960', '0.013', '0.013']\n",
      "   Entropy (uncertainty): [[0.21273937821388245, 0.21273937821388245, 0.21273937821388245], [0.14017626643180847, 0.21273937821388245, 0.21273937821388245]]\n",
      "\n",
      "ðŸ“Š Summary insights:\n",
      "   â€¢ At t=0: Returns exact softmax of model predictions\n",
      "   â€¢ At t>0: Incorporates diffusion process uncertainty\n",
      "   â€¢ Higher t â†’ more uncertainty (higher entropy)\n",
      "   â€¢ Function respects probability constraints (sum=1, non-negative)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Visual demonstration of compute_predicted_posterior function behavior.\n",
    "\"\"\"\n",
    "print(\"ðŸŽ¨ Visual demonstration of compute_predicted_posterior...\")\n",
    "\n",
    "# Use a very small example for clarity\n",
    "demo_vocab_size = 4\n",
    "demo_num_timesteps = 5\n",
    "demo_scheduler = UniformScheduler(num_classes=demo_vocab_size, num_timesteps=demo_num_timesteps).to(device)\n",
    "batch_size, seq_len = 2, 3\n",
    "\n",
    "# Test different timesteps\n",
    "for t_val in [0, 1, 3]:\n",
    "    print(f\"\\nðŸ” Timestep t = {t_val}:\")\n",
    "\n",
    "    t = torch.tensor([t_val, t_val], device=device)\n",
    "    x_t = torch.tensor([[0, 1, 2], [2, 0, 1]], device=device)\n",
    "\n",
    "    # Create logits that strongly prefer certain tokens\n",
    "    x0_logits = torch.zeros(batch_size, seq_len, demo_vocab_size, device=device)\n",
    "    x0_logits[0, 0, 0] = 5.0  # Strongly predict token 0 for position 0\n",
    "    x0_logits[0, 1, 1] = 5.0  # Strongly predict token 1 for position 1\n",
    "    x0_logits[0, 2, 2] = 5.0  # Strongly predict token 2 for position 2\n",
    "    x0_logits[1, 0, 3] = 5.0  # Strongly predict token 3 for position 0\n",
    "    x0_logits[1, 1, 0] = 5.0  # Strongly predict token 0 for position 1\n",
    "    x0_logits[1, 2, 1] = 5.0  # Strongly predict token 1 for position 2\n",
    "\n",
    "    result = compute_predicted_posterior(demo_scheduler, x0_logits, x_t, t)\n",
    "\n",
    "    print(\n",
    "        f\"   Input x_t: {x_t.tolist()},  Predicted x0 (argmax): {F.softmax(x0_logits, dim=-1).argmax(dim=-1).tolist()}\"\n",
    "    )\n",
    "    print(f\"   Posterior p(x_{{t-1}}|x_t) for each position:\")\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        for pos in range(seq_len):\n",
    "            posterior = result[b, pos]\n",
    "            max_prob_token = posterior.argmax().item()\n",
    "            max_prob = posterior.max().item()\n",
    "            print(\n",
    "                f\"     Batch {b}, Pos {pos}: most likely x_{{t-1}} = {max_prob_token} (prob={max_prob:.3f})\"\n",
    "                f\"full distribution: {[f'{p:.3f}' for p in posterior.tolist()]}\"\n",
    "            )\n",
    "\n",
    "    # Show entropy (measure of uncertainty)\n",
    "    entropy = -(result * torch.log(result + 1e-8)).sum(dim=-1)\n",
    "    print(f\"   Entropy (uncertainty): {entropy.tolist()}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Summary insights:\")\n",
    "print(f\"   â€¢ At t=0: Returns exact softmax of model predictions\")\n",
    "print(f\"   â€¢ At t>0: Incorporates diffusion process uncertainty\")\n",
    "print(f\"   â€¢ Higher t â†’ more uncertainty (higher entropy)\")\n",
    "print(f\"   â€¢ Function respects probability constraints (sum=1, non-negative)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5fb805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Tokenizer trained and saved to ./simple_1000_dylan_tokenizer\n",
      "Max sequence length in dataset: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x_0.shape: torch.Size([32, 3])\n",
      "| x_0.shape: torch.Size([32, 3])\n",
      "ic| x_t.shape: torch.Size([32, 3])\n",
      "ic| x_t.shape: torch.Size([32, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before training step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| x0_logits.shape: torch.Size([32, 3, 1000])\n",
      "| x0_logits.shape: torch.Size([32, 3, 1000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training step\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Training step on a single batch. \"\"\"\n",
    "\n",
    "\n",
    "def training_step(\n",
    "    scheduler: UniformScheduler, model: SimpleD3PMModel, x_0: torch.Tensor, t: torch.Tensor\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    x_t = scheduler.add_noise(x_0, t)\n",
    "    ic(x_t.shape)\n",
    "    x0_logits = model(x_t, t)\n",
    "    ic(x0_logits.shape)\n",
    "    true_posterior = scheduler.get_posterior_params(x_t, x_0, t)\n",
    "    # ic(true_posterior.shape)\n",
    "\n",
    "    pred_posterior = compute_predicted_posterior(scheduler=scheduler, x0_logits=x0_logits, x_t=x_t, t=t)\n",
    "    # ic(pred_posterior.shape)\n",
    "\n",
    "    kl_terms = scheduler.compute_kl_divergence(true_posterior, pred_posterior)\n",
    "    # ic(kl_terms.shape)\n",
    "    return x0_logits, kl_terms\n",
    "\n",
    "\n",
    "num_timesteps = 50\n",
    "max_seq_len = 22\n",
    "batch_size = 32\n",
    "vocab_size = 1000\n",
    "dylan_tokenizer = SimpleDylanTokenizer(vocab_size=1000)\n",
    "dylan_tokenizer.train_tokenizer(corpus=lines, save_path=f\"./simple_{vocab_size}_dylan_tokenizer\")\n",
    "tokenizer = dylan_tokenizer.get_transformers_tokenizer()\n",
    "sm_dataset = SimpleDylanDataset(lines[:100], tokenizer, seq_len=seq_len)\n",
    "sm_dataloader = DataLoader(sm_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "scheduler = UniformScheduler(num_classes=vocab_size, num_timesteps=num_timesteps, beta_start=0.0001, beta_end=0.02).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "model = SimpleD3PMModel(vocab_size=vocab_size, max_seq_len=max_seq_len, d_model=128, num_heads=2, num_layers=1).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "t = torch.randint(0, num_timesteps, (batch_size,), device=device)  # Changed from (batch_size, 1) to (batch_size,)\n",
    "x_0 = next(iter(sm_dataloader))  # Get a batch from the small dataset\n",
    "x_0 = x_0.to(device)\n",
    "ic(x_0.shape)  # Should be [batch_size, seq_len]\n",
    "# Forward pass\n",
    "print(\"before training step\")\n",
    "x0_logits, kl_terms = training_step(scheduler=scheduler, model=model, x_0=x_0, t=t)\n",
    "print(\"after training step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa7e5584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and scheduler created successfully!\n",
      "Model parameters: 3,809,256\n",
      "Vocab size: 1000\n",
      "Num timesteps: 50\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming SimpleD3PMModel and UniformScheduler are defined elsewhere\n",
    "# from your_model_definition import SimpleD3PMModel, UniformScheduler\n",
    "\n",
    "# Simple model and scheduler setup for training\n",
    "seq_len = 20\n",
    "vocab_size = len(tokenizer)\n",
    "num_timesteps = 50\n",
    "\n",
    "# Create model and scheduler\n",
    "model = SimpleD3PMModel(vocab_size=vocab_size, max_seq_len=seq_len).to(device)\n",
    "scheduler = UniformScheduler(num_classes=vocab_size, num_timesteps=num_timesteps, beta_start=0.0001, beta_end=0.02).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "\n",
    "# Simple loss function\n",
    "def d3pm_loss(\n",
    "    x0_logits: torch.Tensor, kl_terms: torch.Tensor, x_0: torch.Tensor, lambda_weight: float = 0.001\n",
    ") -> tuple[torch.Tensor, dict]:\n",
    "    # VB loss: average KL terms\n",
    "    vb_loss = kl_terms.mean()\n",
    "\n",
    "    # Auxiliary loss: cross entropy between predicted x0 and true x0\n",
    "    flat_logits = x0_logits.view(-1, vocab_size)\n",
    "    flat_targets = x_0.view(-1)\n",
    "    aux_loss = F.cross_entropy(flat_logits, flat_targets)\n",
    "\n",
    "    # Total loss\n",
    "    total_loss = vb_loss + lambda_weight * aux_loss\n",
    "\n",
    "    return total_loss, {\"total\": total_loss, \"vb\": vb_loss, \"aux\": aux_loss}\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "print(\"Model and scheduler created successfully!\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Vocab size: {vocab_size}\")\n",
    "print(f\"Num timesteps: {num_timesteps}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4c66f1",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "211eecdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Tokenizer trained and saved to ./simple_3000_dylan_tokenizer\n",
      "Max sequence length in dataset: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| num_batches: 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0b64afab51483582f87235dc7e4431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 1/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed. Average Loss: 7.2473\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1215e36119654bf09b9c9f7afd865c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 2/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Average Loss: 6.1325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0357ca6776d04231a86462f5fb63d059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 3/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed. Average Loss: 5.5623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2029cf6f81624893aa43020c199bd8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 4/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed. Average Loss: 5.3558\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d844e440ac96496295409712805bb2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 5/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed. Average Loss: 4.9889\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15cd099957e418a89f6a0a712d1c4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 6/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed. Average Loss: 4.7647\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff897b6e5dfc4f80b4349e86f2d84133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 7/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 completed. Average Loss: 4.6485\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759443c525ba4ac0bfdf3d84cd2a2fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 8/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed. Average Loss: 4.5514\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69375fe3f9cd4b8791377afbf8e3a683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 9/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 completed. Average Loss: 4.2550\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bcbcc81a11549419b4fc6e5c82eec25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 10/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 completed. Average Loss: 4.1262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0815cf6634495daf8ab98bad5b2143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 11/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 completed. Average Loss: 4.1539\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f21097ab0cc453486c795f8eb6b5207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 12/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 completed. Average Loss: 4.0826\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741b6df192dd4931993c49c6a63c913f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 13/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 completed. Average Loss: 3.9104\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c2b56c345842c98a03f90f06b66942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 14/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 completed. Average Loss: 3.7726\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615265b734624ee3894983dfaaffed27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 15/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 completed. Average Loss: 3.7265\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcda14bb06694b488687b1214bdb493e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 16/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 completed. Average Loss: 3.6785\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9820e686b3454db62a23003f2ca5b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 17/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 completed. Average Loss: 3.6063\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be67e6e309c4a48b058ff67772f16c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 18/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 completed. Average Loss: 3.4987\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5f00f2bbe24e64a91a2995eeae947e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 19/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 completed. Average Loss: 3.3408\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca623c44a6548cfbbf1e7de23e4530c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 20/20:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 completed. Average Loss: 3.2602\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Training loop working correctly! IndexError has been fixed.\n"
     ]
    }
   ],
   "source": [
    "from my_transformer import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "\n",
    "vocab_size = 3000\n",
    "num_timesteps = 100\n",
    "max_seq_len = 20\n",
    "batch_size = 16\n",
    "\n",
    "sm_lines = lines[:512]  # Use a smaller subset for testing\n",
    "dylan_tokenizer = SimpleDylanTokenizer(vocab_size=vocab_size)\n",
    "dylan_tokenizer.train_tokenizer(corpus=sm_lines, save_path=f\"./simple_{vocab_size}_dylan_tokenizer\")\n",
    "tokenizer = dylan_tokenizer.get_transformers_tokenizer()\n",
    "sm_dataset = SimpleDylanDataset(sm_lines, tokenizer, seq_len=seq_len)\n",
    "sm_dataloader = DataLoader(sm_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloader = sm_dataloader\n",
    "\n",
    "model = SimpleD3PMModel(vocab_size=vocab_size, max_seq_len=max_seq_len, d_model=128, num_heads=2, num_layers=1).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "scheduler = UniformScheduler(num_classes=vocab_size, num_timesteps=num_timesteps, beta_start=0.0001, beta_end=0.02).to(\n",
    "    device\n",
    ")\n",
    "do_train = True\n",
    "if do_train:\n",
    "    # optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "    learning_rate = 1e-4\n",
    "    weight_decay = 1e-5  # Added weight decay\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    # Adaptive learning rate scheduler\n",
    "    lr_scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=3, T_mult=2, eta_min=1e-6)\n",
    "    train_losses = []\n",
    "    learning_rates = []\n",
    "    model.train()\n",
    "\n",
    "    # Training loop - IndexError fixed!\n",
    "    num_epochs = 20\n",
    "\n",
    "    model_name = \"d3pm\"\n",
    "    model_version = \"1.0\"\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_dir = f\"../runs/{model_name}_{model_version}_training_{timestamp}\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    global_step = 0\n",
    "    num_batches = len(dataloader)\n",
    "    ic(num_batches)\n",
    "\n",
    "    ic.disable()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        pbar = tqdm(dataloader, desc=f\"epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        for b, x_0 in enumerate(pbar):\n",
    "            if b >= num_batches:\n",
    "                break\n",
    "\n",
    "            x_0 = x_0.to(device)\n",
    "            batch_size = x_0.shape[0]\n",
    "\n",
    "            # Sample random timesteps\n",
    "            t = torch.randint(0, num_timesteps, (batch_size,), device=device)\n",
    "\n",
    "            # Training step\n",
    "            x0_logits, kl_terms = training_step(scheduler=scheduler, model=model, x_0=x_0, t=t)\n",
    "            loss, loss_dict = d3pm_loss(x0_logits, kl_terms, x_0)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            global_step += 1\n",
    "            current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "            avg_epoch_loss = epoch_loss / num_batches\n",
    "\n",
    "            if global_step % 2 == 0:\n",
    "                writer.add_scalar(\"Loss/Batch\", loss.item(), global_step)\n",
    "                writer.add_scalar(\"Learning_Rate\", current_lr, global_step)\n",
    "                writer.add_scalar(\n",
    "                    \"Gradient_Norm\",\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=float(\"inf\")),\n",
    "                    global_step,\n",
    "                )\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\", \"LR\": f\"{current_lr:.2e}\", \"Step\": global_step})\n",
    "\n",
    "            # Memory cleanup\n",
    "            if b % 5 == 0:\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                elif torch.backends.mps.is_available():\n",
    "                    torch.mps.empty_cache()\n",
    "\n",
    "        train_losses.append(avg_epoch_loss)\n",
    "        learning_rates.append(current_lr)\n",
    "\n",
    "        utils.save_model(model, model_name=model_name, model_version=model_version, iter=epoch)\n",
    "        print(f\"Epoch {epoch} completed. Average Loss: {epoch_loss / num_batches:.4f}\")\n",
    "\n",
    "    # Plot training curves\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # Loss curve\n",
    "    ax1.plot(train_losses)\n",
    "    ax1.set_title(\"Training Loss\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Learning rate curve\n",
    "    ax2.plot(learning_rates)\n",
    "    ax2.set_title(\"Learning Rate Schedule\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Learning Rate\")\n",
    "    ax2.set_yscale(\"log\")\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(\"../plots\", exist_ok=True)\n",
    "    plt.savefig(f\"../plots/training_curves_{timestamp}.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    writer.close()\n",
    "    print(\"\\nâœ… Training loop working correctly! IndexError has been fixed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9cb73b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e67b34",
   "metadata": {},
   "source": [
    "## Sampling output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fbff1b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = utils.load_model(model_name=model_name, model_version=model_version, iter=num_epochs - 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b6db84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| prompt_txt: 'How does it feel'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] Ha I age . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n",
      "ic| output_txt: 'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'\n"
     ]
    }
   ],
   "source": [
    "ic.enable()\n",
    "prompt_txt = \"How does it feel\"\n",
    "prompt = torch.Tensor(tokenizer.encode(prompt_txt, add_special_tokens=True)).unsqueeze(0).to(device)\n",
    "ic(prompt_txt)\n",
    "temperature = 0.1\n",
    "\n",
    "num_steps = 1\n",
    "\n",
    "# Handle prompt\n",
    "prompt_len = prompt.shape[1]\n",
    "\n",
    "if prompt_len >= seq_len:\n",
    "    # If prompt is longer than desired sequence, just return prompt\n",
    "    raise ValueError(\"Prompt length exceeds sequence length.\")\n",
    "\n",
    "# Start from uniform random tokens\n",
    "x = torch.randint(0, model.vocab_size, (1, seq_len), device=device)\n",
    "x[:, :prompt_len] = prompt\n",
    "\n",
    "# Create mask for which positions to generate (non-prompt positions)\n",
    "generation_mask = torch.ones(seq_len, dtype=torch.bool, device=device)\n",
    "generation_mask[:prompt_len] = False\n",
    "\n",
    "# Reverse diffusion process\n",
    "timesteps = torch.linspace(scheduler.num_timesteps - 1, 0, scheduler.num_timesteps, dtype=torch.long, device=device)\n",
    "\n",
    "model.eval()\n",
    "for i, t_val in enumerate(timesteps):\n",
    "    t = torch.full((batch_size,), t_val, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Predict xâ‚€\n",
    "        x0_logits = model(x, t)\n",
    "\n",
    "        if i == len(timesteps) - 1:\n",
    "            # Final step: use xâ‚€ prediction directly\n",
    "            new_x = torch.argmax(x0_logits, dim=-1)\n",
    "        else:\n",
    "            # Sample from xâ‚€ prediction with temperature and top-k\n",
    "            x0_probs = F.softmax(x0_logits / temperature, dim=-1)\n",
    "\n",
    "            # Sample\n",
    "            flat_probs = x0_probs.view(-1, model.vocab_size)\n",
    "            flat_samples = torch.multinomial(flat_probs, 1).squeeze(-1)\n",
    "            new_x = flat_samples.view(batch_size, seq_len)\n",
    "\n",
    "        # Only update non-prompt positions\n",
    "        x = torch.where(generation_mask.unsqueeze(0), new_x, x)\n",
    "\n",
    "        # ic(x.shape)\n",
    "        output_txt = tokenizer.decode(x[0].cpu().numpy(), skip_special_tokens=False)\n",
    "        ic(output_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "46cdb63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How do es it feel . t down t in [PAD] a [PAD] [PAD] [PAD] the I s . t'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6861a479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-implementations (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
