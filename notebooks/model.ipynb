{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "# | default_exp model\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "\n",
    "from typing import Optional\n",
    "import math\n",
    "import os\n",
    "from transformers import GPT2TokenizerFast\n",
    "from my_transformer.attention import unidirectional_mask, MultiHeadAttention, LayerNormalization\n",
    "from my_transformer.utils import save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, model_size: int, mlp_factor: int = 4, dropout: float = 0.1) -> None:\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(model_size, mlp_factor * model_size),\n",
    "            nn.RELU(),\n",
    "            nn.Linear(mlp_factor * model_size, model_size),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.net(x)\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self, model_size: int, nb_heads: int = 1, dropout: float = 0.0, bias: bool = True, mlp_factor=4\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.layer_norm1 = LayerNormalization(model_size)  # LayerNormalization(model_size)\n",
    "        self.attn = MultiHeadAttention(d=model_size, h=nb_heads, dropout=dropout, bias=bias)\n",
    "        self.mlp1 = nn.Linear(model_size, mlp_factor * model_size, bias=bias)\n",
    "        self.mlp2 = nn.Linear(mlp_factor * model_size, model_size, bias=bias)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer_norm2 = LayerNormalization(model_size)  # LayerNormalization(model_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        b, l, d = x.size()\n",
    "        norm_x = self.layer_norm1(x)\n",
    "        attn_x = x + self.attn(norm_x, z=None, mask=mask)[0]\n",
    "\n",
    "        norm_attn_x = self.layer_norm2(attn_x)\n",
    "        lin1 = self.activation(self.mlp1(norm_attn_x))\n",
    "        x = x + self.dropout(self.mlp2(lin1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAAGdCAYAAAAL5n9KAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHMRJREFUeJzt3X9QVPf5L/D37pplNQLREBZ/bILNtDWKigFhkCa3mW7ltomN9047NrGRblvSGkjUnfYqbYRaq6ttyjCTUGlsSbwzEuk3rZNMtOSm26LjFb8k0HSSmRZqrXGvfneBSQsEw67uOfcP49bNgnI4Z/fzWc77NXP+8Hh+PKiPz/P5nF8WVVVVEJEQVtEBEJkZE5BIICYgkUBMQCKBmIBEAjEBiQRiAhIJxAQkEmhGqk+oKAouXryIzMxMWCyWVJ+epkhVVYyMjGD+/PmwWpP3//bY2BgikYghx7Lb7XA4HIYcK1lSnoAXL16Ey+VK9WnJIIFAAAsXLkzKscfGxrDortkI9kcNOV5eXh7+8Y9/SJ2EKU/AzMxMAMCJ/8zB7NnydMD/a83/FB1Cgg8X54kOIebKlTH85/G9sb+/ZIhEIgj2R/GP7ruQlanv38bwiIJFRe8hEokwAa93re2cPduK2Tr/kI00w5ohOoQEM2bI9w8nFcOGrEyr7gRMFylPQKKbiaoKojofEYiqijHBJBkTkKSjQIUCfRmod/9UYQKSdBQo0Fu/9B8hNczRaBNJihWQpBNVVUR1Pieud/9UYQKSdMw0BmQLSiQQKyBJR4GKqEkqIBOQpMMWlIhSghWQpGOmWdApVcCmpibk5+fD4XCgtLQUXV1dRsdFJqYYtKQDzQnY1tYGr9eL+vp69PT0YMWKFaioqEB/f38y4iOa1jQnYENDA6qqquDxeLBkyRI0Nzdj1qxZaGlpSUZ8ZELRj2ZB9S7pQNMYMBKJoLu7G7W1tbF1VqsVbrcbnZ2d4+4TDocRDodjvx4eHp5iqGQWURUGPA1hTCzJpqkCDg4OIhqNwul0xq13Op0IBoPj7uPz+ZCdnR1b+DQ83QzHgAaqra3F0NBQbAkEAsk+JVHa0NSC5uTkwGazIRQKxa0PhULIyxv/9QkZGRnIyJDvaXOSlwILotD35L2ic/9U0VQB7XY7ioqK4Pf7Y+sURYHf70dZWZnhwZE5KaoxSzrQfCHe6/WisrISxcXFKCkpQWNjI0ZHR+HxeJIRH9G0pjkB169fj4GBAdTV1SEYDKKwsBDt7e0JEzNEUxU1oAXVu3+qTOlWtJqaGtTU1BgdCxEAcyUgb8YmEog3Y5N0FNUCRdU5C6pz/1RhApJ02IISUUqwApJ0orAiqrM2GPN5l+RjApJ0VAPGgCrHgERTwzEgEaUEKyBJJ6paEVV1jgGn672gRMmmwAJFZ3PG1xIS0U0Jq4DepWWYYblF1OkT/O255Hz3XI9Z/88mOoSYaFgB/DffzpBzmWgShi0oSceYMSBbUCK6CVZAks7VSRhzvJKCCUjSUQy4FY2zoER0U6yAJB0zTcIwAUk6CqymuRDPBCTpRFULojqfZtC7f6pwDEgkECsgSceYB3LZghJNiaJaoeichFHSZBKGLSiRQKyAJB22oEQCKdA/i8nvAxKlmaamJuTn58PhcKC0tBRdXV033L6xsRGf/vSnMXPmTLhcLmzduhVjY2OazskKSNIx5kK8tv3b2trg9XrR3NyM0tJSNDY2oqKiAr29vcjNzU3YvrW1Fdu3b0dLSwtWr16Nvr4+fP3rX4fFYkFDQ8Okz8sKSNK5diua3kWLhoYGVFVVwePxYMmSJWhubsasWbPQ0tIy7vanTp1CeXk5Hn30UeTn52PNmjV45JFHblo1P44JSKYXiUTQ3d0Nt9sdW2e1WuF2u9HZ2TnuPqtXr0Z3d3cs4c6ePYtjx47hi1/8oqZzswUl6Rj5PODw8HDc+vE+mT44OIhoNJrwjUun04m//vWv4x7/0UcfxeDgID7zmc9AVVVcuXIF3/nOd/D9739fU5ysgCQdI1tQl8uF7Ozs2OLz+QyJsaOjA3v27MHPf/5z9PT04Le//S2OHj2KXbt2aToOKyBJx5jrgFf3DwQCyMrKiq3/ePUDgJycHNhsNoRCobj1oVAIeXl54x5/x44deOyxx/Ctb30LALBs2TKMjo7i8ccfxw9+8ANYrZOLnxWQprWsrKy4ZbwEtNvtKCoqgt//79e+KYoCv9+PsrKycY976dKlhCSz2a6+xU7VcBscKyBJR8QHOr1eLyorK1FcXIySkhI0NjZidHQUHo8HALBx40YsWLAg1sKuXbsWDQ0NWLlyJUpLS3HmzBns2LEDa9eujSXiZDABSTrGvBNG2/7r16/HwMAA6urqEAwGUVhYiPb29tjEzPnz5+Mq3tNPPw2LxYKnn34aFy5cwB133IG1a9di9+7dms5rUbXUSwMMDw8jOzsbn8XDkr2Yt1R0CAnkejHvGPoavo+hoaG4MZWRrv3b2Pvmf4Njtr7aMPbBFWxfdTyp8RqBFZCkY8zjSOkxvcEEJOmY6dX06fHfBNE0xQpI0mELSiRQFPpbyKgxoSRdevw3QTRNsQKSdNiCEglkzKvpmYBEU6Ia8DiSyssQRHQzrIAkHbagKfDfu/6l+34/I7Xsl+e+y2uGPinPy/WUD1MXi4inIURJj/8miKYpeUoQ0UeMfCJedkxAkg5bUCJKCVZAko6IN2OLwgQk6fAT1USUEqyAJB0zTcIwAUk6qgFPQ6i8E4ZoavhOGCJKCVZAko6i6h/DKenxiXgmIMnHTE/Ep0eURNOUpgT0+XxYtWoVMjMzkZubi3Xr1qG3tzdZsZFJXftAp94lHWhKwOPHj6O6uhqnT5/GG2+8gcuXL2PNmjUYHR1NVnxkQtfuhNG7pANNY8D29va4X7/44ovIzc1Fd3c37r//fkMDIzIDXZMwQ0NDAIC5c+dOuE04HEY4HI79+uPf7Cb6OE7CTIKiKNiyZQvKy8tRUFAw4XY+ny/uG90ul2uqpySTUGCJ3Y425WU6jgGvV11djXfffReHDx++4Xa1tbUYGhqKLYFAYKqnJJp2ptSC1tTU4LXXXsOJEyewcOHCG26bkZEx7ne5iSZipveCakpAVVXx5JNP4siRI+jo6MCiRYuSFReZGJ+GmEB1dTVaW1vxyiuvIDMzE8FgEACQnZ2NmTNnJiVAMh9Owkxg//79GBoawmc/+1nMmzcvtrS1tSUrPqJpTXMLSpRsbEGJBDLiVrJpfxmCiPRjBSTpsAUlEshMCcgWlEggVkCSjpkqIBOQpGOmBGQLSiQQKyBJR4X+63jpcssIE5CkY6YWlAlI0mECpsC3bwsgK1OeIejx9X2iQ0iwNOu/RIcQE/7gMn4qOohpiBWQpMMKSCSQmRJQnh6QyIRYAUk6qmqBqrOC6d0/VZiAJB0+D0hEKcEKSNIx0yQME5CkY6YxIFtQIoFYAUk6bEGJBDJTC8oEJOmoBlTAdElAjgGJBGIFJOmoAPS+hJ0P5BJNkQILLLwThoiSjRWQpMNZUCKBFNUCi0muA7IFJRKIFZCko6oGzIKmyTQoE5CkY6YxIFtQIoGYgCSdaxVQ76JVU1MT8vPz4XA4UFpaiq6urhtu/69//QvV1dWYN28eMjIy8KlPfQrHjh3TdE62oCQdEbOgbW1t8Hq9aG5uRmlpKRobG1FRUYHe3l7k5uYmbB+JRPD5z38eubm5ePnll7FgwQK89957uO222zSdlwlI0hExCdPQ0ICqqip4PB4AQHNzM44ePYqWlhZs3749YfuWlha8//77OHXqFG655RYAQH5+vuY42YLStDY8PBy3hMPhhG0ikQi6u7vhdrtj66xWK9xuNzo7O8c97quvvoqysjJUV1fD6XSioKAAe/bsQTQa1RQfE5Ckc7UC6h0DXj2Wy+VCdnZ2bPH5fAnnGxwcRDQahdPpjFvvdDoRDAbHjfHs2bN4+eWXEY1GcezYMezYsQM/+9nP8OMf/1jTz8oWlKRj5GWIQCCArKys2PqMjAxdx71GURTk5ubi+eefh81mQ1FRES5cuICf/vSnqK+vn/RxmIA0rWVlZcUl4HhycnJgs9kQCoXi1odCIeTl5Y27z7x583DLLbfAZrPF1t1zzz0IBoOIRCKw2+2Tio8tKElHNWiZLLvdjqKiIvj9/tg6RVHg9/tRVlY27j7l5eU4c+YMFEWJrevr68O8efMmnXwAE5AkJOI6oNfrxYEDB3Dw4EH85S9/waZNmzA6OhqbFd24cSNqa2tj22/atAnvv/8+Nm/ejL6+Phw9ehR79uxBdXW1pvOyBSUCsH79egwMDKCurg7BYBCFhYVob2+PTcycP38eVuu/65XL5cLrr7+OrVu3Yvny5ViwYAE2b96Mbdu2aTovE5Dko7WHnOgYGtXU1KCmpmbc3+vo6EhYV1ZWhtOnT2s/0XWYgCQfA2ZBkSY3YzMBSTpmehyJkzBEAgmrgCW/+BZsGQ5Rp0/wds2zokNIsPTEN0SHEKNcGgOg7U7/qTLT84BsQUk+qkX/GC5NEpAtKJFArIAkHTNNwjABST6CrgOKwBaUSCBWQJIOZ0GJREuTFlIvtqBEArECknTYghKJZKJZUCYgScjy0aL3GPLjGJBIIFZAkg9bUCKBTJSAulrQvXv3wmKxYMuWLQaFQ2QuU66Ab775Jn7xi19g+fLlRsZDxMeRbuaDDz7Ahg0bcODAAcyZM8fomMjkrj0NoXdJB1NKwOrqajz44INxH7OYSDgcTvhABhFdpbkFPXz4MHp6evDmm29Oanufz4edO3dqDoxMjJMw4wsEAti8eTMOHToEh2Ny73Opra3F0NBQbAkEAlMKlEzk2hhQ75IGNFXA7u5u9Pf34957742ti0ajOHHiBJ577jmEw+G4j1UAV79GY9QXaYimG00J+LnPfQ7vvPNO3DqPx4PFixdj27ZtCclHNBUW9eqi9xjpQFMCZmZmoqCgIG7drbfeittvvz1hPdGUmWgMyDthSD4mug6oOwHH+2gFEU0OKyDJhy0okUAmSkA+D0gkECsgycdEFZAJSPIx0SwoW1AigVgBSTq8E4ZIJBONAdmCEgnEBCQSiC0oSccCA8aAhkSSfMIS8Nb/UmGzy9Ooryv/H6JDSOA99nvRIcR8+MEVfDdVJ+NlCCJKBbagJB8TzYIyAUk+JkpAtqBEArECknR4JwyRSGxBiSgVWAFJPiaqgExAko6ZxoBsQYkEYgUk+ZjoVjQmIMmHY0AicTgGJKKUYAUk+bAFJRLIgBY0XRKQLSiRQKyAJB+2oEQCmSgB2YISCcQKSNLhdUAiSgkmIJFAbEFJPiaahGECknTMNAZkApKc0iSB9OIYkEggVkCSD8eAROKYaQzIFpRIICYgyUc1aNGoqakJ+fn5cDgcKC0tRVdX16T2O3z4MCwWC9atW6f5nExAks61FlTvokVbWxu8Xi/q6+vR09ODFStWoKKiAv39/Tfc79y5c/jud7+L++67b0o/KxOQCEBDQwOqqqrg8XiwZMkSNDc3Y9asWWhpaZlwn2g0ig0bNmDnzp34xCc+MaXzMgFJPga2oMPDw3FLOBxOOF0kEkF3dzfcbndsndVqhdvtRmdn54Rh/uhHP0Jubi6++c1vTvlHZQKSfAxMQJfLhezs7Nji8/kSTjc4OIhoNAqn0xm33ul0IhgMjhviyZMn8atf/QoHDhzQ9aPyMgRNa4FAAFlZWbFfZ2Rk6D7myMgIHnvsMRw4cAA5OTm6jiUsAYcXATaHqLMnWv3URdEhJGj8j4dFhxATHRsD8H9Tci4jrwNmZWXFJeB4cnJyYLPZEAqF4taHQiHk5eUlbP/3v/8d586dw9q1a2PrFEUBAMyYMQO9vb24++67JxUnW1CST4ovQ9jtdhQVFcHv98fWKYoCv9+PsrKyhO0XL16Md955B2+//XZs+dKXvoQHHngAb7/9Nlwu16TPzRaU5CPgVjSv14vKykoUFxejpKQEjY2NGB0dhcfjAQBs3LgRCxYsgM/ng8PhQEFBQdz+t912GwAkrL8ZJiARgPXr12NgYAB1dXUIBoMoLCxEe3t7bGLm/PnzsFqNbxiZgCQdUfeC1tTUoKamZtzf6+jouOG+L774ovYTgglIMjLR0xCchCESiBWQpGOmx5GYgCQftqBElAqsgCQfE1VAJiBJx/LRovcY6YAtKJFArIAkH7agROKY6TKE5hb0woUL+NrXvobbb78dM2fOxLJly/DWW28lIzYyK0EvZRJBUwX85z//ifLycjzwwAP43e9+hzvuuAN/+9vfMGfOnGTFRzStaUrAffv2weVy4YUXXoitW7RokeFBEaVLBdNLUwv66quvori4GF/5yleQm5uLlStX3vSdGOFwOOHFOEQ3IuK1hKJoSsCzZ89i//79+OQnP4nXX38dmzZtwlNPPYWDBw9OuI/P54t7KY6Wp4WJpjtNCagoCu69917s2bMHK1euxOOPP46qqio0NzdPuE9tbS2GhoZiSyAQ0B00TXOchBnfvHnzsGTJkrh199xzD37zm99MuE9GRoYhb6Ii8+BliAmUl5ejt7c3bl1fXx/uuusuQ4MiMgtNCbh161acPn0ae/bswZkzZ9Da2ornn38e1dXVyYqPzMhELaimBFy1ahWOHDmCl156CQUFBdi1axcaGxuxYcOGZMVHJmSmWVDNt6I99NBDeOihh5IRC5Hp8F5Qkg9vxiYSiAlIJA4vQxBRSrACknzYghKJY1FVWFR9GaR3/1RhC0okECsgyYctKJE4nAUlopRgBST5sAVNvkVNf8UMi13U6RP8nyWLRYeQYO+j/1t0CDGXRqJ4bE9qzsUWlIhSgi0oyYctKJE4ZmpBmYAkHxNVQI4BiQRiBSQppUsLqRcTkOSjqlcXvcdIA2xBiQRiBSTpcBaUSCTOghJRKrACknQsytVF7zHSAROQ5MMWlIhSgRWQpMNZUCKRTHQhnglI0jFTBeQYkEggVkCSj4lmQZmAJB22oESUEqyAJB/OghKJwxaUiFKCFZDkw1lQInHYghJRSrACknwU9eqi9xhpgAlI8uEYkEgcCwwYAxoSSfJxDEgkECsgyYd3whCJw8sQRJQSrIAkH86CEoljUVVYdI7h9O6fKsISMNC0ALZZGaJOnyB/+4eiQ0jg3bxBdAgxyodjAN4RHca0wzEgyUcxaNGoqakJ+fn5cDgcKC0tRVdX14TbHjhwAPfddx/mzJmDOXPmwO1233D7iTABSTrXWlC9ixZtbW3wer2or69HT08PVqxYgYqKCvT394+7fUdHBx555BH88Y9/RGdnJ1wuF9asWYMLFy5oOi8TkAhAQ0MDqqqq4PF4sGTJEjQ3N2PWrFloaWkZd/tDhw7hiSeeQGFhIRYvXoxf/vKXUBQFfr9f03mZgCQf1aAFwPDwcNwSDocTTheJRNDd3Q232x1bZ7Va4Xa70dnZOamQL126hMuXL2Pu3LmaflQmIMnn2p0wehcALpcL2dnZscXn8yWcbnBwENFoFE6nM2690+lEMBicVMjbtm3D/Pnz45J4MngZgqRj5J0wgUAAWVlZsfUZGcbPvO/duxeHDx9GR0cHHA6Hpn2ZgDStZWVlxSXgeHJycmCz2RAKheLWh0Ih5OXl3XDfZ555Bnv37sXvf/97LF++XHN8bEFJPga2oJNht9tRVFQUN4FybUKlrKxswv1+8pOfYNeuXWhvb0dxcfGUflRWQJKOiC/ker1eVFZWori4GCUlJWhsbMTo6Cg8Hg8AYOPGjViwYEFsDLlv3z7U1dWhtbUV+fn5sbHi7NmzMXv27EmflwlIBGD9+vUYGBhAXV0dgsEgCgsL0d7eHpuYOX/+PKzWfzeM+/fvRyQSwZe//OW449TX1+OHP/zhpM/LBCT5CHoesKamBjU1NeP+XkdHR9yvz507N4WgEjEBST4mehqCkzBEArECknTM9DiSpgoYjUaxY8cOLFq0CDNnzsTdd9+NXbt2QU2TH5bSRIovQ4ikqQLu27cP+/fvx8GDB7F06VK89dZb8Hg8yM7OxlNPPZWsGImmLU0JeOrUKTz88MN48MEHAQD5+fl46aWXpvQcFNGEVEzpeb6EY6QBTS3o6tWr4ff70dfXBwD485//jJMnT+ILX/jChPuEw+GEO9KJbkTE84CiaKqA27dvx/DwMBYvXgybzYZoNIrdu3djw4aJX53g8/mwc+dO3YGSiagw4DqgIZEknaYK+Otf/xqHDh1Ca2srenp6cPDgQTzzzDM4ePDghPvU1tZiaGgotgQCAd1BE00Xmirg9773PWzfvh1f/epXAQDLli3De++9B5/Ph8rKynH3ycjISMojIDSN8c3Y47t06VLc/XAAYLPZoCh6R8xE11Gg/+sqafJPUlMCrl27Frt378add96JpUuX4k9/+hMaGhrwjW98I1nxEU1rmhLw2WefxY4dO/DEE0+gv78f8+fPx7e//W3U1dUlKz4yITPdCaMpATMzM9HY2IjGxsYkhUMEU40BeTM2kUC8GZvkY6IKyAQk+ZgoAdmCEgnECkjy4XVAInF4GYJIJI4BiSgVWAFJPooBH4dQ0qMCMgFJPmxBiSgVhFXAfQUv49ZMm6jTJzjxH4tFh5DA8vDdokOIuaKEkbpHqY14q1l6VEC2oCQftqBElAqsgCQfxYCPQ3AWlGiKVOXqovcYaYAtKJFArIAkHxNNwjABST4cAxIJZKIKyDEgkUCsgCQfE30bgglI8mELSkSpwApI8lEU6H6pS5p8r4QJSPJhC0pEqcAKSPIxUQVkApJ8THQnDFtQIoFYAUk6qqpA1fk4kd79U4UJSPJRVf0tJMeARFOkGjAGTJME5BiQSCBWQJKPogAWc7ySgglI8mELSkSpwApI0lEVBarOFpSXIYimii0oEaUCKyDJx4jvA6ZJBWQCknxUFbofyE2TBGQLSiQQKyBJR1VUqDpbUDVNKiATkOSjGvBOGF6GIJoaM1VAjgGJBEp5Bbz2P9OlD+RqEcKjl0WHkOCKEhYdQswVJQIgNZXlihrW3UJegXx/n+NJeQKOjIwAADaUn031qW/ijOgA0sLIyAiys7OTcmy73Y68vDycDB4z5Hh5eXmw2+2GHCtZLGqKm2VFUXDx4kVkZmbCYrFM+TjDw8NwuVwIBALIysoyMMLpxag/J1VVMTIygvnz58NqTd7IZWxsDJFIxJBj2e12OBwOQ46VLCmvgFarFQsXLjTseFlZWUzASTDizylZle96DodD+qQxEidhiARiAhIJlLYJmJGRgfr6emRkZIgORWr8c5JbyidhiOjf0rYCEk0HTEAigZiARAIxAYkEStsEbGpqQn5+PhwOB0pLS9HV1SU6JKn4fD6sWrUKmZmZyM3Nxbp169Db2ys6LPqYtEzAtrY2eL1e1NfXo6enBytWrEBFRQX6+/tFhyaN48ePo7q6GqdPn8Ybb7yBy5cvY82aNRgdHRUdGl0nLS9DlJaWYtWqVXjuuecAXL2/1OVy4cknn8T27dsFRyengYEB5Obm4vjx47j//vtFh0MfSbsKGIlE0N3dDbfbHVtntVrhdrvR2dkpMDK5DQ0NAQDmzp0rOBK6Xtol4ODgIKLRKJxOZ9x6p9OJYDAoKCq5KYqCLVu2oLy8HAUFBaLDoevwlRQmUF1djXfffRcnT54UHQp9TNolYE5ODmw2G0KhUNz6UCiEvLw8QVHJq6amBq+99hpOnDhh6GNgZIy0a0HtdjuKiorg9/tj6xRFgd/vR1lZmcDI5KKqKmpqanDkyBH84Q9/wKJFi0SHRONIuwoIAF6vF5WVlSguLkZJSQkaGxsxOjoKj8cjOjRpVFdXo7W1Fa+88goyMzNj4+Ps7GzMnDlTcHQUo6apZ599Vr3zzjtVu92ulpSUqKdPnxYdklRw9fNCCcsLL7wgOjS6TlpeBySaLtJuDEg0nTABiQRiAhIJxAQkEogJSCQQE5BIICYgkUBMQCKBmIBEAjEBiQRiAhIJxAQkEuj/A0bw6Irit+ZMAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAAGdCAYAAADzBoS9AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIWRJREFUeJzt3X9wVOXZN/Dv7kJ2QbIBDNkArgapChh+JpA3pFodt8SKtMzb8qBGwZTGDmYVTeuYKCRoHlhpaSatUlKpUeYtkbT1oXWExqGxkaEEo4k40qFQqkgGugl50CSGshv3nPcPyOp274RsztnsfTbfz8z5Iyfnx5XAleu673P2HJOqqiqISHrmWAdARIPDZCUyCCYrkUEwWYkMgslKZBBMViKDYLISGQSTlcggRg33CRVFwdmzZ5GYmAiTyTTcp6chUlUV3d3dmDJlCszm6P2Nv3jxIvx+vy7HSkhIgM1m0+VYMhj2ZD179iycTudwn5Z00traimuuuSYqx7548SKmXTcO3vaALsdLTU3Fxx9/HDcJO+zJmpiYCACoPngjxo6zDPfp+1U178ZYhxCma+XCWIcQFOi9iA/+57+D/37R4Pf74W0P4OPm62BP1Fa9u7oVTMv4BH6/n8k6VH2t79hxFoxNlCdZR5lGxzqEMJYE+f6TDcfQxZ5o1pys8WjYk5XoSgKqgoDGj5cEVEWfYCTCZCXpKFChQFu2at1fRkxWko4CBVrrovYjyIcDAyKDYGUl6QRUFQGNz0TQur+MmKwkHY5ZxdgGExkEKytJR4GKACtrGCYrSYdtsBjbYCKDYGUl6XA2WGxIlXXbtm1IS0uDzWZDVlYWmpqa9I6LRjBFpyXeRJystbW1KCoqQllZGVpaWjB37lzk5uaivb09GvER0WURJ2tFRQUKCgqQn5+PWbNmoaqqCmPHjkV1dXU04qMRKHB5NljrEm8iGrP6/X40NzejpKQkuM5sNsPlcqGxsVG4j8/ng8/nC37d1dU1xFBppAio0OFTN/rEIpOIKmtHRwcCgQAcDkfIeofDAa/XK9zH4/EgKSkpuPApEXQlHLOKRf3STUlJCTo7O4NLa2trtE9JFJciaoOTk5NhsVjQ1tYWsr6trQ2pqanCfaxWK6xW69AjpBFHgQkBaHsihaJxfxlFVFkTEhKQkZGB+vr64DpFUVBfX4/s7Gzdg6ORSVH1WeJNxDdFFBUVYfXq1cjMzMSiRYtQWVmJnp4e5OfnRyM+Iros4mRduXIlzp07h9LSUni9XsybNw91dXVhk05EQxXQoQ3Wur+MhnS7odvthtvt1jsWIgBM1v7wRn4ig+CN/CQdRTVBUTXOBmvcX0ZMVpIO22AxtsFEBsHKStIJwIyAxjqiz6ut5MJkJemoOoxZVY5ZiaKPY1YxjlmJDIKVlaQTUM0IqBrHrHF4bzArK0lHgQkKzBqXyNvgSJ8tVllZiZtuugljxoyB0+nE448/josXLw71x74iJisRIn+2WE1NDYqLi1FWVoZjx47hpZdeQm1tLZ566qmoxRizNvj5H63EqFHyvNm79//K8xb2Pv87R55JEuWiCagdnnPFYoLpq88WA4Cqqirs3bsX1dXVKC4uDtv+0KFDyMnJwX333QcASEtLw7333ot33nlHU9wDYWUl6fSNWbUuwKVnfn11+erzwPr0PVvM5XIF113p2WKLFy9Gc3NzsFX+6KOPsG/fPtx1111R+I1cjilqRyaSgNPpDHkGmMfjCdtmKM8Wu++++/Dss8/i61//OkaPHo3p06fjtttui882mKg/lyaY9HmsS2trK+x2e3C9Xo8YamhowObNm/HLX/4SWVlZOHnyJNatW4fy8nJs2LBBl3P8JyYrSUfR4XbDvhdT2e32kGQVGcqzxTZs2IAHHngAP/jBDwAAs2fPRk9PDx566CE8/fTTMJv1b1rZBtOIN5Rni124cCEsIS2WS5OUapTes8PKStLR56aIyBLmSs8WW7VqFaZOnRoc8y5btgwVFRWYP39+sA3esGEDli1bFkxavTFZSTp9NzZoO0ZkyXqlZ4udPn06pJKuX78eJpMJ69evx5kzZzBp0iQsW7YMmzZt0hT3QExqtGp2P7q6upCUlIScOzbKdZ11nHzXWb3/R55RinLxIk5teBqdnZ1XHAMOVd//jf/3/myMTdT273GhO4AH5n8Y1XiHmzz/G4hoQGyDSTr6fPg8/u7kZ7KSdBTVDEXjBJPCN58TUaywspJ02AaLMVlJOgqAgNbnBusTilTYBhMZBCsrSUefmyLirw4xWUk6+txuGH/JGn8/EVGcYmUl6ej5edZ4wmQl6bANFmOyknT0uc4af8kafz8RUZxiZSXp8GXKYkxWko4+z2CKv6Yx/n4iojjFykrS0ecjcvFXh5isJB2+n1Us/v78EMUpVlaSDttgMSYrSScA7W1sQJ9QpBJ/f36I4hQrK0mHbbAYk5Wkwxv5xZisJB1Vh4/Iqbx0Q0SxwspK0mEbLBazZF1c3gTruNGxOn2YhvU5sQ4hjDJanmffKoHhi4WfuhGLvz8/RHGKbTBJh0+KEGOyknTYBovF358fojjFykrS4RP5xZisJJ2AatL8Yiqt+8so/v78EMUpVlaSDieYxJisJB1Vh0/dqLyDiSj6+Awmsfj780MUp1hZSTqKqn3MqchzW7VumKwkHT4pQiz+fiKiOBVRsno8HixcuBCJiYlISUnB8uXLcfz48WjFRiNU38uUtS7xJqJkffvtt1FYWIjDhw9j//796O3txZIlS9DT0xOt+GgE6ruDSesSbyIas9bV1YV8/corryAlJQXNzc249dZbdQ2MiEJpmmDq7OwEAEycOLHfbXw+H3w+X/Drrq4uLaekEYATTGJD/okURcFjjz2GnJwcpKen97udx+NBUlJScHE6nUM9JY0QCkzBWw6HvIz0MetXFRYW4ujRo9i9e/eA25WUlKCzszO4tLa2DvWURFG1bds2pKWlwWazISsrC01NTQNu/9lnn6GwsBCTJ0+G1WrFjTfeiH379kUtviG1wW63G2+88QYOHDiAa665ZsBtrVYrrFbrkIKjkSkWzw2ura1FUVERqqqqkJWVhcrKSuTm5uL48eNISUkJ297v9+Ob3/wmUlJS8Pvf/x5Tp07FJ598gvHjx2uKeyARJauqqnjkkUewZ88eNDQ0YNq0adGKi0awWHzqpqKiAgUFBcjPzwcAVFVVYe/evaiurkZxcXHY9tXV1Th//jwOHTqE0aMvPaUzLS1NU8xXElEbXFhYiN/85jeoqalBYmIivF4vvF4v/v3vf0crPhqB+iaYtC6D5ff70dzcDJfLFVxnNpvhcrnQ2Ngo3Of1119HdnY2CgsL4XA4kJ6ejs2bNyMQiN776yKqrNu3bwcA3HbbbSHrX375ZTz44IN6xUSkm/+8+iAalnV0dCAQCMDhcISsdzgc+Pvf/y487kcffYS33noLeXl52LdvH06ePImHH34Yvb29KCsr0/eHuCziNpgo2vRsg//z6kNZWRk2btyo6djApashKSkpePHFF2GxWJCRkYEzZ87gpz/9qRzJSjQc9LhdsG//1tZW2O324HrRZGdycjIsFgva2tpC1re1tSE1NVV4/MmTJ2P06NGwWCzBdTNnzoTX64Xf70dCQoKm+EXi78ox0VfY7faQRZSsCQkJyMjIQH19fXCdoiior69Hdna28Lg5OTk4efIkFEUJrjtx4gQmT54clUQFmKwkIc03RAyhjS4qKsKOHTuwc+dOHDt2DGvXrkVPT09wdnjVqlUoKSkJbr927VqcP38e69atw4kTJ7B3715s3rwZhYWFuv4uvoptMEknFpduVq5ciXPnzqG0tBRerxfz5s1DXV1dcNLp9OnTMJu/rG1OpxNvvvkmHn/8ccyZMwdTp07FunXr8OSTT2qKeyBMVqLL3G433G638HsNDQ1h67Kzs3H48OEoR/UlJitJh48iFWOyknSYrGKcYCIyCFZWko4K6HAjf/xhspJ02AaLMVlJOkxWsZgl692JH2BcojxD5l0SPkNqbsbJWIcQ1Nvjx+lYBzHCsbKSdFhZxZisJB0mq5g8fSgRDYiVlaSjqiaoGiuj1v1lxGQl6ej5edZ4wjaYyCBYWUk6nGASY7KSdDhmFWMbTGQQrKwkHbbBYkxWkg7bYDEmK0lH1aGyxmOycsxKZBCsrCQdFYDWlz/ww+dEw0CBCSbewRSGbTCRQbCyknQ4GyzGZCXpKKoJJl5nDcM2mMggWFlJOqqqw2xwHE4HM1lJOhyzirENJjIIVlaSDiurGJOVpMPZYDEmK0mHE0xiHLMSGQQrK0nnUmXVOmbVKRiJMFlJOpxgEmMbTGQQrKwkHRXaP48ah10wk5XkwzZYjG0wkUGwspJ82AcLMVlJPjq0wYjDNpjJStLhHUxiHLMSGUTMKmvRiRWwXGWN1enDjLogX9s07ar/jXUIQT61d9jOxdlgMbbBJB/VpH3MGYfJyjaYyCBYWUk6nGASY7KSfHidVYhtMJFBMFlJOn2zwVqXSG3btg1paWmw2WzIyspCU1PToPbbvXs3TCYTli9fHvE5I8FkJTmpGpcI1dbWoqioCGVlZWhpacHcuXORm5uL9vb2Afc7deoUfvzjH+OWW26J/KQRYrISAaioqEBBQQHy8/Mxa9YsVFVVYezYsaiuru53n0AggLy8PDzzzDO4/vrrox4jk5Wko2cb3NXVFbL4fL6w8/n9fjQ3N8PlcgXXmc1muFwuNDY29hvns88+i5SUFKxZs0b/X4IAk5Xko7UF/kor7HQ6kZSUFFw8Hk/Y6To6OhAIBOBwOELWOxwOeL1eYYgHDx7ESy+9hB07dmj9aQeNl25IQqbLi9ZjAK2trbDb7cG1Vqv2W1y7u7vxwAMPYMeOHUhOTtZ8vMFislJcs9vtIckqkpycDIvFgra2tpD1bW1tSE1NDdv+n//8J06dOoVly5YF1ymKAgAYNWoUjh8/junTp+sQfSi2wSQfHdvgwUhISEBGRgbq6+uD6xRFQX19PbKzs8O2nzFjBj788EMcOXIkuHz729/G7bffjiNHjsDpdA7hh74yVlaSTwzuYCoqKsLq1auRmZmJRYsWobKyEj09PcjPzwcArFq1ClOnToXH44HNZkN6enrI/uPHjweAsPV60lRZn3vuOZhMJjz22GM6hUMUGytXrsTWrVtRWlqKefPm4ciRI6irqwtOOp0+fRr/+te/YhrjkCvru+++i1/96leYM2eOnvEQxewjcm63G263W/i9hoaGAfd95ZVXIj5fpIZUWT///HPk5eVhx44dmDBhgt4x0QjX96kbrUu8GVKyFhYWYunSpSEXkfvj8/nCLkwTUeQiboN3796NlpYWvPvuu4Pa3uPx4Jlnnok4MBrB+BE5oYgqa2trK9atW4ddu3bBZrMNap+SkhJ0dnYGl9bW1iEFSiNI35hV6xJnIqqszc3NaG9vx4IFC4LrAoEADhw4gBdeeAE+nw8WiyVkH6vVqstdI0QjXUTJescdd+DDDz8MWZefn48ZM2bgySefDEtUoqEwqZcWrceINxEla2JiYthF36uuugpXX311VC8G0wjDMasQ72Ai+fBRpEKak/VKF4uJSB+srCQftsFCTFaSD5NViB+RIzIIVlaSDyurEJOV5MPZYCG2wUQGwcpK0uEdTGJMVpIPx6xCbIOJDILJSmQQbINJOiboMGbVJRK5xCxZO44nwzzID7APBxn/agUkanyU4YyFl26E5PnfQEQDkrGg0EjH2WAhJivJh8kqxDaYyCBYWUk6vINJjMlK8mEbLMQ2mMggWFlJPqysQkxWkg7HrGJsg4kMgpWV5MPbDYWYrCQfjlmFmKwkHY5ZxThmJTIIVlaSD9tgISYryUeHNjgek5VtMJFBsLKSfNgGCzFZST5MViG2wUQGwcpK0uF1VjFWViKDYLISGQTbYJIPJ5iEmKwkHY5ZxZisJKc4TDatOGYlMghWVpIPx6xCrKwknb4xq9YlUtu2bUNaWhpsNhuysrLQ1NTU77Y7duzALbfcggkTJmDChAlwuVwDbq8HJisRgNraWhQVFaGsrAwtLS2YO3cucnNz0d7eLty+oaEB9957L/7yl7+gsbERTqcTS5YswZkzZ6IWI5OV5KPqtESgoqICBQUFyM/Px6xZs1BVVYWxY8eiurpauP2uXbvw8MMPY968eZgxYwZ+/etfQ1EU1NfXR/7zDhKTlaSjZxvc1dUVsvh8vrDz+f1+NDc3w+VyBdeZzWa4XC40NjYOKuYLFy6gt7cXEydO1OV3IMJkpbjmdDqRlJQUXDweT9g2HR0dCAQCcDgcIesdDge8Xu+gzvPkk09iypQpIQmvN84Gk3x0nA1ubW2F3W4PrrZarRoPHO65557D7t270dDQAJvNpvvx+zBZST46Jqvdbg9JVpHk5GRYLBa0tbWFrG9ra0NqauqA+27duhXPPfcc/vznP2POnDmaQr4StsE04iUkJCAjIyNkcqhvsig7O7vf/X7yk5+gvLwcdXV1yMzMjHqcMaus42/4FJax+rckQ2X6/dWxDiHM/lM3xTqEoMCF8ImZaInFvcFFRUVYvXo1MjMzsWjRIlRWVqKnpwf5+fkAgFWrVmHq1KnBMe+WLVtQWlqKmpoapKWlBce248aNw7hx47QF3w+2wSSfGNzBtHLlSpw7dw6lpaXwer2YN28e6urqgpNOp0+fhtn8ZSO6fft2+P1+fO973ws5TllZGTZu3KgxeDEmK8knRrcbut1uuN1u4fcaGhpCvj516lTkJ9CIY1Yig2BlJenw86xiTFaSDz91I8Q2mMggWFlJOmyDxZisJB+2wUJsg4kMgpWV5MPKKsRkJemYLi9ajxFv2AYTGQQrK8mHbbAQk5Wkw0s3YhG3wWfOnMH999+Pq6++GmPGjMHs2bPx3nvvRSM2Gqli8MA0I4iosn766afIycnB7bffjj/96U+YNGkS/vGPf2DChAnRio+ILosoWbds2QKn04mXX345uG7atGm6B0UUj5VRq4ja4Ndffx2ZmZlYsWIFUlJSMH/+fOzYsWPAfXw+X9jjIIkGEqsn8ssuomT96KOPsH37dtxwww148803sXbtWjz66KPYuXNnv/t4PJ6QR0E6nU7NQRONRBElq6IoWLBgATZv3oz58+fjoYceQkFBAaqqqvrdp6SkBJ2dncGltbVVc9AU5zjBJBTRmHXy5MmYNWtWyLqZM2fitdde63cfq9UalWe1UvzipRuxiCprTk4Ojh8/HrLuxIkTuO6663QNiojCRZSsjz/+OA4fPozNmzfj5MmTqKmpwYsvvojCwsJoxUcjEdtgoYiSdeHChdizZw9effVVpKeno7y8HJWVlcjLy4tWfDQCcTZYLOLbDe+++27cfffd0YiFiAbAe4NJPryRX4jJSvJhsgoxWUk6vHQjxg+fExkEKyvJh22wEJOVpGNSVZhUbdmmdX8ZsQ0mMghWVpIP22AhJitJh7PBYmyDiQyClZXkwzZYKGbJatozEaYEW6xOH2Z+4ZFYhxDGafs01iEEXfy8F55hOhfbYDG2wUQGwTaY5MM2WIjJStJhGyzGZCX5sLIKccxKZBCsrCSleGxjtWKyknxU9dKi9Rhxhm0wkUGwspJ0OBssxmQl+XA2WIhtMJFBsLKSdEzKpUXrMeINk5XkwzZYiG0wkUEwWUk6sXrXzbZt25CWlgabzYasrCw0NTUNuP3vfvc7zJgxAzabDbNnz8a+ffuG+BMPDpOV5NN3U4TWJQK1tbUoKipCWVkZWlpaMHfuXOTm5qK9vV24/aFDh3DvvfdizZo1eP/997F8+XIsX74cR48e1eM3IMRkJenEorJWVFSgoKAA+fn5mDVrFqqqqjB27FhUV1cLt//5z3+OO++8E0888QRmzpyJ8vJyLFiwAC+88IIOvwExJivFta6urpDF5/OFbeP3+9Hc3AyXyxVcZzab4XK50NjYKDxuY2NjyPYAkJub2+/2emCyknwGekFyJAsAp9OJpKSk4OLxhD+cpqOjA4FAAA6HI2S9w+GA1+sVhuj1eiPaXg+8dEPS0fN2w9bWVtjt9uB6q9Wq7cAxxGSluGa320OSVSQ5ORkWiwVtbW0h69va2pCamircJzU1NaLt9cA2mOQzzLPBCQkJyMjIQH19fXCdoiior69Hdna2cJ/s7OyQ7QFg//79/W6vB1ZWkk4sPnVTVFSE1atXIzMzE4sWLUJlZSV6enqQn58PAFi1ahWmTp0aHPOuW7cO3/jGN/Czn/0MS5cuxe7du/Hee+/hxRdf1Bb4AJisRABWrlyJc+fOobS0FF6vF/PmzUNdXV1wEun06dMwm79sRBcvXoyamhqsX78eTz31FG644Qb84Q9/QHp6etRiZLKSfGJ0b7Db7Ybb7RZ+r6GhIWzdihUrsGLFishPNERMVpIOP3wuxgkmIoNgZSX5KOqlResx4gyTleTDz7MKMVlJOiboMGbVJRK5cMxKZBCsrCQfPuRbiMlK0uGlGzG2wUQGwcpK8uFssBCTlaRjUlWYNI45te4vo5gl65j/8mLUVfJ8EPjo1rmxDiHM/pxYR/Al5d8XAbwZ6zBGNFZWko9yedF6jDjDZCXpsA0W42wwkUGwspJ8OBssxGQl+fAOJiEmK0mHdzCJccxKZBCsrCQftsFCTFaSDt98LsY2mMggWFlJPmyDhZisJB9eZxViG0xkEKysJB3eGywWUWUNBALYsGEDpk2bhjFjxmD69OkoLy+HGoe/GIqhYX6LnFFEVFm3bNmC7du3Y+fOnbj55pvx3nvvIT8/H0lJSXj00UejFSMRIcJkPXToEL7zne9g6dKlAIC0tDS8+uqraGpqikpwNEKp0P551PgrrJG1wYsXL0Z9fT1OnDgBAPjggw9w8OBBfOtb3+p3H5/Ph66urpCFaCB9Y1atS7yJqLIWFxejq6sLM2bMgMViQSAQwKZNm5CXl9fvPh6PB88884zmQGkEUaHDdVZdIpFKRJX1t7/9LXbt2oWamhq0tLRg586d2Lp1K3bu3NnvPiUlJejs7Awura2tmoMmGokiqqxPPPEEiouLcc899wAAZs+ejU8++QQejwerV68W7mO1WmG1yvNgNDIA3sEkFFGyXrhwIeRV7QBgsVigKHF41zTFjgLtb5aKw/+SESXrsmXLsGnTJlx77bW4+eab8f7776OiogLf//73oxUfEV0WUbI+//zz2LBhAx5++GG0t7djypQp+OEPf4jS0tJoxUcjEO9gEosoWRMTE1FZWYnKysoohUMEjln7wRv5iQyCN/KTfFhZhZisJB8mqxDbYCKDYGUl+fA6qxCTlaTDSzdiTFaSD8esQhyzEhkEKyvJR9HhZTdK/FVWJivJh22wENtgIoOIWWXdN2sv7Iny/K1YOG5trEMIM+4Trdcv9BPwDee/lR5PJ2RlJYo+yR9Fev78eeTl5cFut2P8+PFYs2YNPv/88wG3f+SRR3DTTTdhzJgxuPbaa/Hoo4+is7MzovMyWYkilJeXh7/97W/Yv38/3njjDRw4cAAPPfRQv9ufPXsWZ8+exdatW3H06FG88sorqKurw5o1ayI6LyeYSD6KDi+7idJs8LFjx1BXV4d3330XmZmZAC59zvuuu+7C1q1bMWXKlLB90tPT8dprrwW/nj59OjZt2oT7778fX3zxBUaNGlwasrKSfFRFnwUIewyuz+fTFFpjYyPGjx8fTFQAcLlcMJvNeOeddwZ9nM7OTtjt9kEnKsBkpTjndDqRlJQUXDwej6bjeb1epKSkhKwbNWoUJk6cCK/XO6hjdHR0oLy8fMDWWYRtMMlHx+usra2tsNvtwdX9PWmzuLgYW7ZsGfCQx44d0xYTLlX6pUuXYtasWdi4cWNE+zJZST46jlntdntIsvbnRz/6ER588MEBt7n++uuRmpqK9vb2kPVffPEFzp8/j9TU1AH37+7uxp133onExETs2bMHo0ePvmJcX8VkJfnE4A6mSZMmYdKkSVfcLjs7G5999hmam5uRkZEBAHjrrbegKAqysrL63a+rqwu5ubmwWq14/fXXYbPZIooP4JiVKCIzZ87EnXfeiYKCAjQ1NeGvf/0r3G437rnnnuBM8JkzZzBjxozgC9u6urqwZMkS9PT04KWXXkJXVxe8Xi+8Xi8CgcCgz83KSvKR/F03u3btgtvtxh133AGz2Yzvfve7+MUvfhH8fm9vL44fP44LFy4AAFpaWoIzxV/72tdCjvXxxx8jLS1tUOdlspJ8JL+Rf+LEiaipqen3+2lpaSEvGL/tttt0eeE422Aig2BlJfkoCjQ/RCkO37/EZCX5SN4GxwrbYCKDYGUl+bCyCjFZST4Sf+omltgGExkEKytJR1UVqKq22Vyt+8uIyUryUVXtbSzHrETDQNVhzBqHycoxK5FBsLKSfBQFMGkcc3LMSjQM2AYLsQ0mMghWVpKOqihQNbbBvHRDNBzYBguxDSYyCFZWko8e72eNw8rKZCX5qCo0f/g8DpOVbTCRQbCyknRURYWqsQ3W4wFlsmGyknxUHZ7BxEs3RNHHyirGMSuRQQx7Ze37i9f1uVxtSsB/MdYhhAn4TLEOIajv9zMcFesL1ae5jf0CvTpFI49hT9bu7m4AwHULTg33qa/g6VgHYAjd3d1ISkqKyrETEhKQmpqKg959uhwvNTUVCQkJuhxLBiZ1mJt7RVFw9uxZJCYmwmQaeuXo6uqC0+kMe/8mhdLr96SqKrq7uzFlyhSYzdEbPV28eBF+v1+XYyUkJAzpbW2yGvbKajabcc011+h2vMG+f3Ok0+P3FK2K+lU2my2uEkxPnGAiMggmK5FBGDZZrVYrysrKYLVaYx2K1Ph7ih/DPsFERENj2MpKNNIwWYkMgslKZBBMViKDMGyybtu2DWlpabDZbMjKykJTU1OsQ5KKx+PBwoULkZiYiJSUFCxfvhzHjx+PdVikgSGTtba2FkVFRSgrK0NLSwvmzp2L3NxctLe3xzo0abz99tsoLCzE4cOHsX//fvT29mLJkiXo6emJdWg0RIa8dJOVlYWFCxfihRdeAHDpfmOn04lHHnkExcXFMY5OTufOnUNKSgrefvtt3HrrrbEOh4bAcJXV7/ejubkZLpcruM5sNsPlcqGxsTGGkcmts7MTADBx4sQYR0JDZbhk7ejoQCAQgMPhCFnvcDjg9XpjFJXcFEXBY489hpycHKSnp8c6HBoiPtZlBCgsLMTRo0dx8ODBWIdCGhguWZOTk2GxWNDW1hayvq2tDampqTGKSl5utxtvvPEGDhw4oOtHE2n4Ga4NTkhIQEZGBurr64PrFEVBfX09srOzYxiZXFRVhdvtxp49e/DWW29h2rRpsQ6JNDJcZQWAoqIirF69GpmZmVi0aBEqKyvR09OD/Pz8WIcmjcLCQtTU1OCPf/wjEhMTg+P5pKQkjBkzJsbR0ZCoBvX888+r1157rZqQkKAuWrRIPXz4cKxDkgouvYYtbHn55ZdjHRoNkSGvsxKNRIYbsxKNVExWIoNgshIZBJOVyCCYrEQGwWQlMggmK5FBMFmJDILJSmQQTFYig2CyEhkEk5XIIP4/8cDLCnSndCMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 10\n",
    "embedding_dim = 3\n",
    "x = torch.rand((batch_size, seq_len, embedding_dim)).to(device)\n",
    "dl = DecoderLayer(embedding_dim, nb_heads=1, dropout=0.1).to(device)\n",
    "mask = unidirectional_mask(seq_len=seq_len).to(device)\n",
    "dlo = dl(x, mask=mask)\n",
    "\n",
    "plt.imshow(x[0].cpu().detach())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(dlo[0].cpu().detach())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class DecoderTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        max_seq_len: int,\n",
    "        model_size: int,\n",
    "        nb_heads: int = 1,\n",
    "        nb_layers: int = 1,\n",
    "        dropout: float = 0.0,\n",
    "        bias: bool = True,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.tok_emb = nn.Embedding(vocab_size, embedding_dim=model_size)\n",
    "        self.pos_emb = torch.nn.Embedding(max_seq_len, embedding_dim=model_size)\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            *[\n",
    "                DecoderLayer(model_size=model_size, nb_heads=nb_heads, dropout=dropout, bias=bias)\n",
    "                for i in range(nb_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.layer_norm = LayerNormalization(model_size)\n",
    "        self.unembedding = nn.Linear(model_size, vocab_size)\n",
    "\n",
    "    def get_device(self):\n",
    "        # Check the device of parameters or buffers\n",
    "        if next(self.parameters(), None) is not None:\n",
    "            return next(self.parameters()).device\n",
    "        elif next(self.buffers(), None) is not None:\n",
    "            return next(self.buffers()).device\n",
    "        else:\n",
    "            return None  # No parameters or buffers in this module\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, L = x.size()\n",
    "        tok_emb = self.tok_emb(x)\n",
    "        device = self.get_device()\n",
    "        pos_emb = self.pos_emb(torch.arange(L, device=device))\n",
    "        mask = unidirectional_mask(seq_len=L).to(device)\n",
    "        x = tok_emb + pos_emb\n",
    "        # x = self.layers(x, mask)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        x = self.layer_norm(x)\n",
    "        logits = self.unembedding(x)\n",
    "        return logits\n",
    "\n",
    "    def generate(self, x: torch.Tensor, max_new_tokens: int):\n",
    "        with torch.no_grad():\n",
    "            for i in range(max_new_tokens):\n",
    "                # we take at most max_seq_len tokens\n",
    "                x_block = x[:, -self.max_seq_len :]\n",
    "                logits = self(x_block)\n",
    "                # we take the logit for last token, used to predict token.\n",
    "                logits = logits[:, -1, :]\n",
    "                probs = F.softmax(logits, dim=-1)\n",
    "                tok_next = torch.multinomial(probs, num_samples=1)\n",
    "                x = torch.cat((x, tok_next), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| sum(p.numel() for p in model.parameters()) / 1e6: 0.001526\n",
      "    \"M parameters\": 'M parameters'\n",
      "ic| y_hat.shape: torch.Size([2, 5, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 5, 3, 0, 0]], device='mps:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_model_size(model: nn.Module):\n",
    "    ic(sum(p.numel() for p in model.parameters()) / 1e6, \"M parameters\")\n",
    "\n",
    "\n",
    "model = DecoderTransformer(vocab_size=6, max_seq_len=5, model_size=10, nb_heads=1).to(device)\n",
    "print_model_size(model)\n",
    "x = torch.tensor([[0, 1, 2, 3, 4], [1, 2, 3, 4, 5]], dtype=torch.int, device=device)\n",
    "y_hat = model(x)\n",
    "ic(y_hat.shape)\n",
    "model.generate(torch.tensor([[0, 1]], dtype=torch.long, device=device), max_new_tokens=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dataset/shakespeare.txt\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "\n",
    "words = text.split(\" \")\n",
    "train_pos = math.ceil(len(words) * 0.8)\n",
    "train_words = words[:train_pos]\n",
    "test_words = words[train_pos:]\n",
    "train_txt = \" \".join(train_words[:])\n",
    "test_txt = \" \".join(test_words[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "\n",
    "GPT2 use a byte-level BPE (byte pair encoding) tokenizer. First we train a tokenizer to create a vocabulary and merge file that is required by GPT2.\n",
    "GPT-2 expects:\n",
    "- A fixed vocabulary size (e.g., 50,257 tokens).\n",
    "- Specific special tokens (<|endoftext|>).\n",
    "- Byte-level encoding to handle all possible text inputs (including non-standard characters).\n",
    "\n",
    "So GPT2TokenizerFast enrich trained tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='./shakespare_tok', vocab_size=1000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t1000: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_tokenizer = ByteLevelBPETokenizer()\n",
    "trained_tokenizer.train_from_iterator([train_txt], vocab_size=1000)\n",
    "tok_dir = \"./shakespare_tok\"\n",
    "os.makedirs(tok_dir, exist_ok=True)\n",
    "trained_tokenizer.save_model(tok_dir)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(tok_dir)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(tokenizer.encode(train_txt)) <= len(train_txt): True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[257, 273, 78]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(len(tokenizer.encode(train_txt)) <= len(train_txt))\n",
    "tokenizer.encode(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPEDataset(Dataset):\n",
    "    def __init__(self, text: str, tokenizer: Tokenizer, seq_len: int = 20, device: str = \"cpu\"):\n",
    "        self.device = device\n",
    "        self.seq_len = seq_len\n",
    "        self.text = text\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.encoded = torch.tensor(self.tokenizer.encode(self.text), dtype=torch.long, device=device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded) // self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_len = len(self.encoded)\n",
    "        i = idx * self.seq_len\n",
    "        if i >= data_len:\n",
    "            raise ValueError(f\"idx {idx} bigger than data length {data_len}\")\n",
    "        x = self.encoded[i : i + self.seq_len]\n",
    "        y = self.encoded[i + 1 : i + self.seq_len + 1]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = BPEDataset(train_txt, tokenizer=tokenizer, seq_len=10, device=device)\n",
    "train_dl = DataLoader(train_ds, batch_size=5)\n",
    "assert next(iter(train_dl))[0].size() == (5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 times batch (45): 100%|██████████| 45/45 [00:07<00:00,  6.10batch/s, epoch=0, train_loss=8.6516, test_loss=8.6559]\n"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class EpochTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        # model: nn.Module,\n",
    "        get_new_model: callable,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        train_dl: DataLoader,\n",
    "        test_dl: DataLoader,\n",
    "        model_version: str,\n",
    "        model_name: str,\n",
    "        nb_epochs: int = 100,\n",
    "        loss_fn=F.cross_entropy,\n",
    "        do_save_model: bool = True,\n",
    "        save_every_epoch_nb: int = 20,\n",
    "        device: str = \"cpu\",\n",
    "    ) -> None:\n",
    "        self.model = get_new_model()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.train_dl = train_dl\n",
    "        self.test_dl = test_dl\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.do_save_model = do_save_model\n",
    "        self.save_every_epoch_nb = save_every_epoch_nb\n",
    "        self.model_name = model_name\n",
    "        self.model_version = model_version\n",
    "        self.device = device\n",
    "        self.writer = None\n",
    "\n",
    "    def compute_loss(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B * T, C)\n",
    "        targets = targets.view(B * T)\n",
    "        loss = self.loss_fn(logits, targets)\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def estimate_loss(self, i: int):\n",
    "        out = {}\n",
    "        self.model.eval()\n",
    "        for split in [\"train\", \"test\"]:\n",
    "            dl = self.train_dl if split == \"train\" else self.test_dl\n",
    "            if dl is not None:\n",
    "                losses = []\n",
    "                for x, y in dl:\n",
    "                    logits = self.model(x)\n",
    "                    loss = self.compute_loss(logits, y)\n",
    "                    losses.append(loss.item())\n",
    "                loss_mean = torch.tensor(losses).mean()\n",
    "                out[split] = loss_mean\n",
    "                self.writer.add_scalar(f\"{split} loss\", loss_mean, i)\n",
    "        self.model.train()\n",
    "        return out\n",
    "\n",
    "    def train(self, from_epoch: int = 0):\n",
    "        self.writer = SummaryWriter(\n",
    "            f\"../runs/{self.model_name}_{self.model_version}/{datetime.now().strftime('%m-%d-%Y_%H:%M:%S')}\"\n",
    "        )\n",
    "        ex_x, ex_y = next(iter(self.train_dl))\n",
    "        self.writer.add_graph(self.model, (ex_x), use_strict_trace=False)\n",
    "        self.writer.flush()\n",
    "        if from_epoch > 0:\n",
    "            epoch_start_nb = from_epoch + 1\n",
    "        else:\n",
    "            epoch_start_nb = 0\n",
    "        nb_epochs_computed = self.nb_epochs - epoch_start_nb\n",
    "        with tqdm(\n",
    "            total=len(self.train_dl) * nb_epochs_computed,\n",
    "            desc=f\"Epoch {nb_epochs_computed} times batch ({len(self.train_dl)})\",\n",
    "            unit=\"batch\",\n",
    "        ) as pbar:\n",
    "            for curr_epoch in range(epoch_start_nb, self.nb_epochs):\n",
    "                for b, (xb, yb) in enumerate(self.train_dl):\n",
    "                    if device == \"mps\":\n",
    "                        logits = self.model(xb)\n",
    "                        loss = self.compute_loss(logits, yb)\n",
    "                    else:\n",
    "                        # use bf16 when possible based on autocast rules. bf16 is same range than float32, but less precision.\n",
    "                        with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "                            logits = self.model(xb)\n",
    "                            loss = self.compute_loss(logits, yb)\n",
    "                    self.optimizer.zero_grad(set_to_none=True)\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    pbar.update(1)\n",
    "\n",
    "                losses = self.estimate_loss(curr_epoch)\n",
    "                pbar.set_postfix(\n",
    "                    {\n",
    "                        \"epoch\": curr_epoch,\n",
    "                        \"train_loss\": f\"{losses.get('train',torch.inf):.4f}\",\n",
    "                        \"test_loss\": f\"{losses.get('test', torch.inf):.4f}\",\n",
    "                    }\n",
    "                )\n",
    "                # print(f\"epoch {curr_epoch}: train loss {losses.get('train',torch.inf):.4f}, val loss {losses.get('test', torch.inf):.4f}\")\n",
    "                for name, weight in self.model.named_parameters():\n",
    "                    self.writer.add_histogram(name, weight, curr_epoch)\n",
    "\n",
    "                # every once in a while evaluate the loss on train and val sets\n",
    "                if self.do_save_model:\n",
    "                    if curr_epoch % self.save_every_epoch_nb == 0:\n",
    "                        save_model(self.model, self.model_name, self.model_version, curr_epoch)\n",
    "\n",
    "        if self.do_save_model:\n",
    "            save_model(self.model, self.model_name, self.model_version, curr_epoch)\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "batch_size = 64  # how many independent sequences will we process in parallel?\n",
    "seq_len = 128  # what is the maximum context length for predictions?\n",
    "vocab_size = 5000\n",
    "model_size = 384\n",
    "num_heads = 1\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "nb_epoch = 1\n",
    "last_epoch_nb = 0\n",
    "model_name = \"gpt2\"\n",
    "model_version = f\"t{vocab_size}_0.1\"\n",
    "\n",
    "train_ds = BPEDataset(train_txt, tokenizer=tokenizer, seq_len=seq_len, device=device)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size)\n",
    "test_ds = BPEDataset(test_txt, tokenizer=tokenizer, seq_len=seq_len, device=device)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "\n",
    "tr = EpochTrainer(\n",
    "    get_new_model=lambda: DecoderTransformer(\n",
    "        vocab_size=vocab_size,\n",
    "        max_seq_len=seq_len,\n",
    "        model_size=model_size,\n",
    "        nb_heads=num_heads,\n",
    "        nb_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "    ).to(device),\n",
    "    optimizer=torch.optim.AdamW(model.parameters(), lr=3e-4),\n",
    "    train_dl=train_dl,\n",
    "    test_dl=test_dl,\n",
    "    loss_fn=F.cross_entropy,\n",
    "    nb_epochs=nb_epoch,\n",
    "    do_save_model=True,\n",
    "    save_every_epoch_nb=20,\n",
    "    model_name=model_name,\n",
    "    model_version=model_version,\n",
    "    device=device,\n",
    ")\n",
    "tr.train(from_epoch=last_epoch_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-implementations-urBBcPaT-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
